{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 2 7B Model - GGML \n",
    "## 8 Bit Quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f58ff61d9ca47ed9346cab226d6489f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fae7dd708764c53b9be036a9b796346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = AutoModelForCausalLM.from_pretrained('TheBloke/Llama-2-7B-Chat-GGML', model_file='llama-2-7b-chat.ggmlv3.q8_0.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Llama 2 7B Parameter\n",
      "QUantization: 8 Bit Quantization\n",
      "CPU: Intel i5 11th Gen\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Prompt: 'What is life?'\n"
     ]
    }
   ],
   "source": [
    "print(\"Model: Llama 2 7B Parameter\")\n",
    "print(\"QUantization: 8 Bit Quantization\")\n",
    "print(\"CPU: Intel i5 11th Gen\")\n",
    "print(\"\\n\\n\\n\\n\",\"Prompt: 'What is life?'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "Here are five words that start with the letter R and end with the letter F:\n",
      "\n",
      "1. Roof\n",
      "2. River\n",
      "3. Road\n",
      "4. Rain\n",
      "5. Forest\n",
      "\n",
      "\n",
      "\n",
      "Time Taken to respond:  11.936085224151611\n"
     ]
    }
   ],
   "source": [
    "st_time = time.time()\n",
    "print(llm('give me 5 words starting with letter R and ending with letter F'))\n",
    "end_time = time.time()\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"Time Taken to respond: \",end_time-st_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama 2 7B Model - GGML \n",
    "## 4 Bit Quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed063f4f31c6429c9a3f242feb0778aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ccdee52f40440fba5dc34fad0746e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = AutoModelForCausalLM.from_pretrained('TheBloke/Llama-2-7B-Chat-GGML', model_file='llama-2-7b-chat.ggmlv3.q4_K_S.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Llama 2 7B Parameter\n",
      "QUantization: 4 Bit Quantization\n",
      "CPU: Intel i5 11th Gen\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Prompt: 'What is life?'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model: Llama 2 7B Parameter\")\n",
    "print(\"QUantization: 4 Bit Quantization\")\n",
    "print(\"CPU: Intel i5 11th Gen\")\n",
    "print(\"\\n\\n\\n\\n\",\"Prompt: 'What is life?'\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What is the meaning of life? These are questions that have puzzled philosophers, scientists, and thinkers for centuries. While there is no definitive answer to these questions, here are some possible perspectives on what life is and its meaning:\n",
      "1. Biological perspective: From a biological perspective, life is the characteristic that distinguishes living beings from non-living matter. Life is the ability to grow, reproduce, maintain homeostasis, respond to stimuli, and adapt to changes in the environment.\n",
      "2. Psychological perspective: From a psychological perspective, life is about finding meaning and purpose. According to this view, the meaning of life is subjective and can vary from person to person. Some may find meaning in relationships, others in personal achievements, and still, others in spirituality or religion.\n",
      "3. Philosophical perspective: Philosophers have long grappled with the question of the meaning of life. Some argue that life has no inherent meaning, but rather it is up to individuals to create their own purpose and meaning. Others believe that life has a predetermined purpose or that it is part of a larger cosmic plan.\n",
      "4. Religious perspective: Many religious traditions\n",
      "\n",
      "\n",
      "\n",
      "Time Taken to respond:  44.3754198551178\n"
     ]
    }
   ],
   "source": [
    "st_time = time.time()\n",
    "print(llm('What is life?'))\n",
    "end_time = time.time()\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "print(\"Time Taken to respond: \",end_time-st_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
