{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA3JdiZYe0C7",
        "outputId": "c07b2b3a-69a7-4443-ad72-dd4047cd92e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Collecting peft\n",
            "  Using cached peft-0.11.1-py3-none-any.whl (251 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.3.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.4)\n",
            "Collecting accelerate>=0.21.0 (from peft)\n",
            "  Using cached accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.23.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->peft)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate, peft\n",
            "Successfully installed accelerate-0.32.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 peft-0.11.1\n",
            "Collecting bitsandbytes\n",
            "  Using cached bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.1\n"
          ]
        }
      ],
      "source": [
        "%pip install transformers\n",
        "%pip install datasets\n",
        "%pip install peft\n",
        "%pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "_Zmnx4mxeAG9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import  DataLoader,TensorDataset\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BlenderbotForCausalLM,AutoTokenizer,AdamW\n",
        "from datasets import Dataset,DatasetDict\n",
        "from peft import LoraConfig,TaskType,get_peft_model\n",
        "# from google.colab import drive\n",
        "import bitsandbytes as bnb\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msiddiqmoideen07\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.17.5 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>t:\\OpenSourceContribution\\aXtrStuff\\neuroLang\\demoStuff\\modelTraining\\casual\\wandb\\run-20240721_223954-i3old2v6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/siddiqmoideen07/QLoRA-Small-BlenderBot-Model-Casual-FineTuning/runs/i3old2v6' target=\"_blank\">misunderstood-deluge-1</a></strong> to <a href='https://wandb.ai/siddiqmoideen07/QLoRA-Small-BlenderBot-Model-Casual-FineTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/siddiqmoideen07/QLoRA-Small-BlenderBot-Model-Casual-FineTuning' target=\"_blank\">https://wandb.ai/siddiqmoideen07/QLoRA-Small-BlenderBot-Model-Casual-FineTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/siddiqmoideen07/QLoRA-Small-BlenderBot-Model-Casual-FineTuning/runs/i3old2v6' target=\"_blank\">https://wandb.ai/siddiqmoideen07/QLoRA-Small-BlenderBot-Model-Casual-FineTuning/runs/i3old2v6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/siddiqmoideen07/QLoRA-Small-BlenderBot-Model-Casual-FineTuning/runs/i3old2v6?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x22dbd1f3070>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(project=\"QLoRA-Small-BlenderBot-Model-Casual-FineTuning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wCdCn3AeE2Y",
        "outputId": "38843cc3-71e8-4b10-f56f-0c35befe8d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "vC7iE0rOeAHC"
      },
      "outputs": [],
      "source": [
        "with open('T:\\\\OpenSourceContribution\\\\aXtrStuff\\\\neuroLang\\\\demoStuff\\\\dataStuff\\\\bookStuff\\\\osBookDoc.txt','r',encoding='utf-8', errors='ignore') as p:\n",
        "    s=p.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd8NNtMEeAHC",
        "outputId": "ab84acc5-2e0c-46dc-f46f-6340b1aeab3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'OPERATING SYSTEM CONCEPTS\\n',\n",
              " 'NINTH EDITION\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'OPERATING SYSTEM CONCEPTS\\n',\n",
              " 'ABRAHAM SILBERSCHATZ\\n',\n",
              " 'Yale University\\n',\n",
              " '\\n',\n",
              " 'PETER BAER GALVIN\\n',\n",
              " '\\n',\n",
              " 'Vice President and Executive Publisher\\tDon Fowley\\n',\n",
              " 'Executive Editor\\tBeth Lang Golub\\n',\n",
              " 'Editorial Assistant\\tKatherine Willis\\n',\n",
              " 'Executive Marketing Manager\\tChristopher Ruel\\n',\n",
              " 'Senior Production Editor\\tKen Santor\\n',\n",
              " 'Cover and title page illustrations\\tSusan Cyr\\n',\n",
              " 'Cover Designer\\tMadelyn Lesure\\n',\n",
              " 'Text Designer\\tJudy Allan\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'This book was set in Palatino by the author using LaTeX and printed and bound by Courier- Kendallville. The cover was printed by Courier.\\n',\n",
              " '\\n',\n",
              " 'Copyright  2013, 2012, 2008 John Wiley & Sons, Inc. All rights reserved.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'No part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or by any means, electronic, mechanical, photocopying, recording, scanning or otherwise, except as permitted under Sections 107 or 108 of the 1976 United States Copyright Act, without either the prior written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to the Copyright Clearance Center, Inc. 222 Rosewood Drive, Danvers, MA 01923, (978)750-8400, fax (978)750-4470. Requests to the Publisher for permission should be addressed to the Permissions Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030 (201)748-6011, fax (201)748-6008, E-Mail: PERMREQ@WILEY.COM.\\n',\n",
              " '\\n',\n",
              " 'Evaluation copies are provided to qualified academics and professionals for review purposes only, for use in their courses during the next academic year. These copies are licensed and may not be sold or transferred to a third party. Upon completion of the review period, please return the evaluation copy to Wiley. Return instructions and a free-of-charge return shipping label are available at www.wiley.com/go/evalreturn. Outside of the United States, please contact your local representative.\\n',\n",
              " '\\n',\n",
              " 'Founded in 1807, John Wiley & Sons, Inc. has been a valued source of knowledge and understanding for more than 200 years, helping people around the world meet their needs and fulfill their aspirations. Our company is built on a foundation of principles that include responsibility to the communities we serve and where we live and work. In 2008, we launched a Corporate Citizenship Initiative, a global effort to address the environmental, social, economic, and ethical challenges we face in our business. Among the issues we are addressing are carbon impact, paper specifications and procurement, ethical conduct within our business and among our vendors, and community and charitable support. For more information, please visit our website: www.wiley.com/go/citizenship.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'ISBN: 978-1-118-06333-0\\n',\n",
              " 'ISBN BRV:     978-1-118-12938-8\\n',\n",
              " '\\n',\n",
              " 'Printed in the United States of America 10 9 8 7 6 5 4 3 2 1\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'To my children, Lemor, Sivan, and Aaron and my Nicolette\\n',\n",
              " 'Avi Silberschatz\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'To Brendan and Ellen,\\n',\n",
              " 'and Barbara, Anne and Harold, and Walter and Rebecca\\n',\n",
              " 'Peter Baer Galvin\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'To my Mom and Dad,\\n',\n",
              " 'Greg Gagne\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Preface\\n',\n",
              " '\\n',\n",
              " 'Operating systems are an essential part of any computer system. Similarly, a course on operating systems is an essential part of any computer science education. This field is undergoing rapid change, as computers are now prevalent in virtually every arena of day-to-day life from embedded devices in automobiles through the most sophisticated planning tools for governments and multinational firms. Yet the fundamental concepts remain fairly clear, and it is on these that we base this book.\\n',\n",
              " '   We wrote this book as a text for an introductory course in operating systems at the junior or senior undergraduate level or at the first-year graduate level. We hope that practitioners will also find it useful. It provides a clear description of the concepts that underlie operating systems. As prerequisites, we assume that the reader is familiar with basic data structures, computer organization, and a high-level language, such as C or Java. The hardware topics required for an understanding of operating systems are covered in Chapter 1. In that chapter, we also include an overview of the fundamental data structures that are prevalent in most operating systems. For code examples, we use predominantly C, with some Java, but the reader can still understand the algorithms without a thorough knowledge of these languages.\\n',\n",
              " '   Concepts are presented using intuitive descriptions. Important theoretical results are covered, but formal proofs are largely omitted. The bibliographical notes at the end of each chapter contain pointers to research papers in which results were first presented and proved, as well as references to recent material for further reading. In place of proofs, figures and examples are used to suggest why we should expect the result in question to be true.\\n',\n",
              " '   The fundamental concepts and algorithms covered in the book are often based on those used in both commercial and open-source operating systems. Our aim is to present these concepts and algorithms in a general setting that is not tied to one particular operating system. However, we present a large number of examples that pertain to the most popular and the most innovative operating systems, including Linux, Microsoft Windows, Apple Mac OS X, and Solaris. We also include examples of both Android and iOS, currently the two dominant mobile operating systems.\\n',\n",
              " '   The organization of the text reflects our many years of teaching courses on operating systems, as well as curriculum guidelines published by the IEEE\\n',\n",
              " '\\n',\n",
              " 'vii\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Computing Society and the Association for Computing Machinery (ACM). Consideration was also given to the feedback provided by the reviewers of the text, along with the many comments and suggestions we received from readers of our previous editions and from our current and former students.\\n',\n",
              " '\\n',\n",
              " 'Content of This Book\\n',\n",
              " 'The text is organized in eight major parts:\\n',\n",
              " ' Overview. Chapters 1 and 2 explain what operating systems are, what they do, and how they are designed and constructed. These chapters discuss what the common features of an operating system are and what an operating system does for the user. We include coverage of both traditional PC and server operating systems, as well as operating systems for mobile devices. The presentation is motivational and explanatory in nature. We have avoided a discussion of how things are done internally in these chapters. Therefore, they are suitable for individual readers or for students in lower-level classes who want to learn what an operating system is without getting into the details of the internal algorithms.\\n',\n",
              " ' Process management. Chapters 3 through 7 describe the process concept and concurrency as the heart of modern operating systems. A process is the unit of work in a system. Such a system consists of a collection of concurrently executing processes, some of which are operating-system processes (those that execute system code) and the rest of which are user processes (those that execute user code). These chapters cover methods for process scheduling, interprocess communication, process synchronization, and deadlock handling. Also included is a discussion of threads, as well as an examination of issues related to multicore systems and parallel programming.\\n',\n",
              " ' Memory management. Chapters 8 and 9 deal with the management of main memory during the execution of a process. To improve both the utilization of the CPU and the speed of its response to its users, the computer must keep several processes in memory. There are many different memory-management schemes, reflecting various approaches to memory management, and the effectiveness of a particular algorithm depends on the situation.\\n',\n",
              " ' Storage management. Chapters 10 through 13 describe how mass storage, the file system, and I/O are handled in a modern computer system. The file system provides the mechanism for on-line storage of and access to both data and programs. We describe the classic internal algorithms and structures of storage management and provide a firm practical understanding of the algorithms used their properties, advantages, and disadvantages. Since the I/O devices that attach to a computer vary widely, the operating system needs to provide a wide range of functionality to applications to allow them to control all aspects of these devices. We discuss system I/O in depth, including I/O system design, interfaces, and internal system structures and functions. In many ways, I/O devices are the slowest major components of the computer. Because they represent a\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'performance bottleneck, we also examine performance issues associated with I/O devices.\\n',\n",
              " ' Protection and security. Chapters 14 and 15 discuss the mechanisms necessary for the protection and security of computer systems. The processes in an operating system must be protected from one anothers activities, and to provide such protection, we must ensure that only processes that have gained proper authorization from the operating system can operate on the files, memory, CPU, and other resources of the system. Protection is a mechanism for controlling the access of programs, processes, or users to computer-system resources. This mechanism must provide a means of specifying the controls to be imposed, as well as a means of enforcement. Security protects the integrity of the information stored in the system (both data and code), as well as the physical resources of the system, from unauthorized access, malicious destruction or alteration, and accidental introduction of inconsistency.\\n',\n",
              " ' Advanced topics. Chapters 16 and 17 discuss virtual machines and distributed systems. Chapter 16 is a new chapter that provides an overview of virtual machines and their relationship to contemporary operating systems. Included is an overview of the hardware and software techniques that make virtualization possible. Chapter 17 condenses and updates the three chapters on distributed computing from the previous edition. This change is meant to make it easier for instructors to cover the material in the limited time available during a semester and for students to gain an understanding of the core ideas of distributed computing more quickly.\\n',\n",
              " ' Case studies. Chapters 18 and 19 in the text, along with Appendices A and B (which are available on (http://www.os-book.com), present  detailed case studies of real operating systems, including Linux, Windows 7, FreeBSD, and Mach. Coverage of both Linux and Windows 7 are presented throughout this text; however, the case studies provide much more detail. It is especially interesting to compare and contrast the design of these two very different systems. Chapter 20 briefly describes a few other influential operating systems.\\n',\n",
              " '\\n',\n",
              " 'The Ninth Edition\\n',\n",
              " 'As we wrote this Ninth Edition of Operating System Concepts, we were guided by the recent growth in three fundamental areas that affect operating systems:\\n',\n",
              " '1. Multicore systems\\n',\n",
              " '2. Mobile computing\\n',\n",
              " '3. Virtualization\\n',\n",
              " 'To emphasize these topics, we have integrated relevant coverage throughout this new edition and, in the case of virtualization, have written an entirely new chapter. Additionally, we have rewritten material in almost every chapter by bringing older material up to date and removing material that is no longer interesting or relevant.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '   We have also made substantial organizational changes. For example, we have eliminated the chapter on real-time systems and instead have integrated appropriate coverage of these systems throughout the text. We have reordered the chapters on storage management and have moved up the presentation of process synchronization so that it appears before process scheduling. Most of these organizational changes are based on our experiences while teaching courses on operating systems.\\n',\n",
              " '   Below, we provide a brief outline of the major changes to the various chapters:\\n',\n",
              " ' Chapter 1, Introduction, includes updated coverage of multiprocessor and multicore systems, as well as a new section on kernel data structures. Additionally, the coverage of computing environments now includes mobile systems and cloud computing. We also have incorporated an overview of real-time systems.\\n',\n",
              " ' Chapter 2, Operating-System Structures, provides new coverage of user interfaces for mobile devices, including discussions of iOS and Android, and expanded coverage of Mac OS X as a type of hybrid system.\\n',\n",
              " ' Chapter 3, Processes, now includes coverage of multitasking in mobile operating systems, support for the multiprocess model in Googles Chrome web browser, and zombie and orphan processes in UNIX.\\n',\n",
              " ' Chapter 4, Threads, supplies expanded coverage of parallelism and Amdahls law. It also provides a new section on implicit threading, including OpenMP and Apples Grand Central Dispatch.\\n',\n",
              " ' Chapter 5, Process Synchronization (previously Chapter 6), adds a new section on mutex locks as well as coverage of synchronization using OpenMP, as well as functional languages.\\n',\n",
              " ' Chapter 6, CPU Scheduling (previously Chapter 5), contains new coverage of the Linux CFS scheduler and Windows user-mode scheduling. Coverage of real-time scheduling algorithms has also been integrated into this chapter.\\n',\n",
              " ' Chapter 7, Deadlocks, has no major changes.\\n',\n",
              " ' Chapter 8, Main Memory, includes new coverage of swapping on mobile systems and Intel 32- and 64-bit architectures. A new section discusses ARM architecture.\\n',\n",
              " ' Chapter 9, Virtual Memory, updates kernel memory management to include the Linux SLUB and SLOB memory allocators.\\n',\n",
              " ' Chapter 10, Mass-Storage Structure (previously Chapter 12), adds cover- age of solid-state disks.\\n',\n",
              " ' Chapter 11, File-System Interface (previously Chapter 10), is updated with information about current technologies.\\n',\n",
              " ' Chapter 12, File-System Implementation (previously Chapter 11), is updated with coverage of current technologies.\\n',\n",
              " ' Chapter 13, I/O, updates technologies and performance numbers, expands coverage of synchronous/asynchronous and blocking/nonblocking I/O, and adds a section on vectored I/O.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " ' Chapter 14, Protection, has no major changes.\\n',\n",
              " ' Chapter 15, Security, has a revised cryptography section with modern notation and an improved explanation of various encryption methods and their uses. The chapter also includes new coverage of Windows 7 security.\\n',\n",
              " ' Chapter 16, Virtual Machines, is a new chapter that provides an overview of virtualization and how it relates to contemporary operating systems.\\n',\n",
              " ' Chapter 17, Distributed Systems, is a new chapter that combines and updates a selection of materials from previous Chapters 16, 17, and 18.\\n',\n",
              " ' Chapter 18, The Linux System (previously Chapter 21), has been updated to cover the Linux 3.2 kernel.\\n',\n",
              " ' Chapter 19, Windows 7, is a new chapter presenting a case study of Windows 7.\\n',\n",
              " ' Chapter 20, Influential Operating Systems (previously Chapter 23), has no major changes.\\n',\n",
              " '\\n',\n",
              " 'Programming Environments\\n',\n",
              " 'This book uses examples of many real-world operating systems to illustrate fundamental operating-system concepts. Particular attention is paid to Linux and Microsoft Windows, but we also refer to various versions of UNIX (including Solaris, BSD, and Mac OS X).\\n',\n",
              " '   The text also provides several example programs written in C and Java. These programs are intended to run in the following programming environments:\\n',\n",
              " ' POSIX. POSIX (which stands for Portable Operating System Interface) repre- sents a set of standards implemented primarily for UNIX-based operating systems. Although Windows systems can also run certain POSIX programs, our coverage of POSIX focuses on UNIX and Linux systems. POSIX-compliant systems must implement the POSIX core standard (POSIX.1); Linux, Solaris, and Mac OS X are examples of POSIX-compliant systems. POSIX also defines several extensions to the standards, including real-time extensions (POSIX1.b) and an extension for a threads library (POSIX1.c, better known as Pthreads). We provide several programming examples written in C illustrating the POSIX base API, as well as Pthreads and the extensions for real-time programming. These example programs were tested on Linux 2.6 and 3.2 systems, Mac OS X 10.7, and Solaris 10 using the gcc 4.0 compiler.\\n',\n",
              " ' Java. Java is a widely used programming language with a rich API and built-in language support for thread creation and management. Java programs run on any operating system supporting a Java virtual machine (or JVM). We illustrate various operating-system and networking concepts with Java programs tested using the Java 1.6 JVM.\\n',\n",
              " ' Windows systems. The primary programming environment for Windows systems is the Windows API, which provides a comprehensive set of func- tions for managing processes, threads, memory, and peripheral devices. We supply several C programs illustrating the use of this API. Programs were tested on systems running Windows XP and Windows 7.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '   We have chosen these three programming environments because we believe that they best represent the two most popular operating-system models\\n',\n",
              " ' Windows and UNIX/Linux along with the widely used Java environment. Most programming examples are written in C, and we expect readers to be comfortable with this language. Readers familiar with both the C and Java languages should easily understand most programs provided in this text.\\n',\n",
              " '    In some instances  such as thread creation  we illustrate a specific concept using all three programming environments, allowing the reader to contrast the three different libraries as they address the same task. In other situations, we may use just one of the APIs to demonstrate a concept. For example, we illustrate shared memory using just the POSIX API; socket programming in TCP/IP is highlighted using the Java API.\\n',\n",
              " '\\n',\n",
              " 'Linux Virtual Machine\\n',\n",
              " 'To help students gain a better understanding of the Linux system, we provide a Linux  virtual  machine,  including  the  Linux  source  code, that is available for download  from  the  the  website  supporting  this text  (http://www.os-book.com).   This   virtual   machine   also   includes   a gcc development environment with compilers and editors. Most of the programming assignments in the book can be completed on this virtual machine, with the exception of assignments that require Java or the Windows API.\\n',\n",
              " '   We also provide three programming assignments that modify the Linux kernel through kernel modules:\\n',\n",
              " '1. Adding a basic kernel module to the Linux kernel.\\n',\n",
              " '2. Adding a kernel module that uses various kernel data structures.\\n',\n",
              " '3. Adding a kernel module that iterates over tasks in a running Linux system.\\n',\n",
              " '\\n',\n",
              " 'Over time it is our intention to add additional kernel module assignments on the supporting website.\\n',\n",
              " '\\n',\n",
              " 'Supporting Website\\n',\n",
              " 'When you visit the website supporting this text at http://www.os-book.com, you can download the following resources:\\n',\n",
              " ' Linux virtual machine\\n',\n",
              " ' C and Java source code\\n',\n",
              " ' Sample syllabi\\n',\n",
              " ' Set of Powerpoint slides\\n',\n",
              " ' Set of figures and illustrations\\n',\n",
              " ' FreeBSD and Mach case studies\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " ' Solutions to practice exercises\\n',\n",
              " ' Study guide for students\\n',\n",
              " ' Errata\\n',\n",
              " 'Notes to Instructors\\n',\n",
              " 'On the website for this text, we provide several sample syllabi that suggest various approaches for using the text in both introductory and advanced courses. As a general rule, we encourage instructors to progress sequentially through the chapters, as this strategy provides the most thorough study of operating systems. However, by using the sample syllabi, an instructor can select a different ordering of chapters (or subsections of chapters).\\n',\n",
              " '   In this edition, we have added over sixty new written exercises and over twenty new programming problems and projects. Most of the new program- ming assignments involve processes, threads, process synchronization, and memory management. Some involve adding kernel modules to the Linux system which requires using either the Linux virtual machine that accompanies this text or another suitable Linux distribution.\\n',\n",
              " '   Solutions to written exercises and programming assignments are available to instructors who have adopted this text for their operating-system class. To obtain these restricted supplements, contact your local John Wiley & Sons sales representative. You can find your Wiley representative by going to http://www.wiley.com/college and clicking Whos my rep?\\n',\n",
              " '\\n',\n",
              " 'Notes to Students\\n',\n",
              " 'We encourage you to take advantage of the practice exercises that appear at the end of each chapter. Solutions to the practice exercises are available for download from the supporting website http://www.os-book.com. We also encourage you to read through the study guide, which was prepared by one of our students. Finally, for students who are unfamiliar with UNIX and Linux systems, we recommend that you download and install the Linux virtual machine that we include on the supporting website. Not only will this provide you with a new computing experience, but the open-source nature of Linux will allow you to easily examine the inner details of this popular operating system.\\n',\n",
              " 'We wish you the very best of luck in your study of operating systems.\\n',\n",
              " '\\n',\n",
              " 'Contacting Us\\n',\n",
              " 'We have endeavored to eliminate typos, bugs, and the like from the text. But, as in new releases of software, bugs almost surely remain. An up-to-date errata list is accessible from the books website. We would be grateful if you would notify us of any errors or omissions in the book that are not on the current list of errata.\\n',\n",
              " '   We would be glad to receive suggestions on improvements to the book. We also welcome any contributions to the book website that could be of\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'use to other readers, such as programming exercises, project suggestions, on-line labs and tutorials, and teaching tips. E-mail should be addressed to os-book-authors@cs.yale.edu.\\n',\n",
              " '\\n',\n",
              " 'Acknowledgments\\n',\n",
              " 'This book is derived from the previous editions, the first three of which were coauthored by James Peterson. Others who helped us with previous editions include Hamid Arabnia, Rida Bazzi, Randy Bentson, David Black, Joseph Boykin, Jeff Brumfield, Gael Buckley, Roy Campbell, P. C. Capon, John Carpenter, Gil Carrick, Thomas Casavant, Bart Childs, Ajoy Kumar Datta, Joe Deck, Sudarshan K. Dhall, Thomas Doeppner, Caleb Drake, M. Racsit Eskiciog lu, Hans Flack, Robert Fowler, G. Scott Graham, Richard Guy, Max Hailperin, Rebecca Hartman, Wayne Hathaway, Christopher Haynes, Don Heller, Bruce Hillyer, Mark Holliday, Dean Hougen, Michael Huang, Ahmed Kamel, Morty Kewstel, Richard Kieburtz, Carol Kroll, Morty Kwestel, Thomas LeBlanc, John Leggett, Jerrold Leichter, Ted Leung, Gary Lippman, Carolyn Miller, Michael Molloy, Euripides Montagne, Yoichi Muraoka, Jim M. Ng, Banu O zden, Ed Posnak, Boris Putanec, Charles Qualline, John Quarterman, Mike Reiter, Gustavo Rodriguez-Rivera, Carolyn J. C. Schauble, Thomas P. Skinner, Yannis Smaragdakis, Jesse St. Laurent, John Stankovic, Adam Stauffer, Steven Stepanek, John Sterling, Hal Stern, Louis Stevens, Pete Thomas, David Umbaugh, Steve Vinoski, Tommy Wagner, Larry L. Wear, John Werth, James\\n',\n",
              " 'M. Westall, J. S. Weston, and Yang Xiang\\n',\n",
              " '   Robert Love updated both Chapter 18 and the Linux coverage throughout the text, as well as answering many of our Android-related questions. Chapter 19 was written by Dave Probert and was derived from Chapter 22 of the Eighth Edition of Operating System Concepts. Jonathan Katz contributed to Chapter\\n',\n",
              " '15. Richard West provided input into Chapter 16. Salahuddin Khan updated Section 15.9 to provide new coverage of Windows 7 security.\\n',\n",
              " '   Parts of Chapter 17 were derived from a paper by Levy and Silberschatz [1990]. Chapter 18 was derived from an unpublished manuscript by Stephen Tweedie. Cliff Martin helped with updating the UNIX appendix to cover FreeBSD. Some of the exercises and accompanying solutions were supplied by Arvind Krishnamurthy. Andrew DeNicola prepared the student study guide that is available on our website. Some of the the slides were prepeared by Marilyn Turnamian.\\n',\n",
              " '   Mike Shapiro, Bryan Cantrill, and Jim Mauro answered several Solaris- related questions, and Bryan Cantrill from Sun Microsystems helped with the ZFS coverage. Josh Dees and Rob Reynolds contributed coverage of Microsofts NET. The project for POSIX message queues was contributed by John Trono of Saint Michaels College in Colchester, Vermont.\\n',\n",
              " '   Judi Paige helped with generating figures and presentation of slides. Thomas Gagne prepared new artwork for this edition. Owen Galvin helped copy-edit Chapter 16. Mark Wogahn has made sure that the software to produce this book (LATEX and fonts) works properly. Ranjan Kumar Meher rewrote some of the LATEX software used in the production of this new text.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '   Our Executive Editor, Beth Lang Golub, provided expert guidance as we prepared this edition. She was assisted by Katherine Willis, who managed many details of the project smoothly. The Senior Production Editor, Ken Santor, was instrumental in handling all the production details.\\n',\n",
              " '   The cover illustrator was Susan Cyr, and the cover designer was Madelyn Lesure. Beverly Peavler copy-edited the manuscript. The freelance proofreader was Katrina Avery; the freelance indexer was WordCo, Inc.\\n',\n",
              " '\\n',\n",
              " 'Abraham Silberschatz, New Haven, CT, 2012 Peter Baer Galvin, Boston, MA, 2012\\n',\n",
              " 'Greg Gagne, Salt Lake City, UT, 2012\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Contents\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'PART ONE\\tOVERVIEW\\n',\n",
              " '\\n',\n",
              " 'Chapter 1\\tIntroduction\\n',\n",
              " '1.1 What Operating Systems Do 4\\n',\n",
              " '1.2 Computer-System Organization   7\\n',\n",
              " '1.3 Computer-System Architecture   12\\n',\n",
              " '1.4 Operating-System Structure 19\\n',\n",
              " '1.5 Operating-System Operations 21\\n',\n",
              " '1.6 Process Management   24\\n',\n",
              " '1.7 Memory Management   25\\n',\n",
              " '1.8 Storage Management   26\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '1.9 Protection and Security   30\\n',\n",
              " '1.10 Kernel Data Structures   31\\n',\n",
              " '1.11 Computing Environments 35\\n',\n",
              " '1.12 Open-Source Operating Systems 43\\n',\n",
              " '1.13 Summary 47 Exercises 49\\n',\n",
              " 'Bibliographical Notes 52\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Chapter 2\\tOperating-System Structures\\n',\n",
              " '\\n',\n",
              " '2.1 Operating-System Services   55\\n',\n",
              " '2.2 User and Operating-System Interface 58\\n',\n",
              " '2.3 System Calls 62\\n',\n",
              " '2.4 Types of System Calls 66\\n',\n",
              " '2.5 System Programs 74\\n',\n",
              " '2.6 Operating-System Design and Implementation 75\\n',\n",
              " '2.7 \\n',\n",
              " 'Operating-System Structure 78\\n',\n",
              " '2.8 Operating-System Debugging   86\\n',\n",
              " '2.9 Operating-System Generation   91\\n',\n",
              " '2.10 System Boot 92\\n',\n",
              " '2.11 Summary 93 Exercises 94\\n',\n",
              " 'Bibliographical Notes 101\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'PART TWO\\n',\n",
              " 'Chapter 3\\tProcesses\\n',\n",
              " '3.1 Process Concept 105\\n',\n",
              " '\\n',\n",
              " 'PROCESS MANAGEMENT\\n',\n",
              " '\\n',\n",
              " '3.6 Communication in Client \\n',\n",
              " '\\n',\n",
              " '3.2 Process Scheduling 110\\n',\n",
              " '3.3 Operations on Processes 115\\n',\n",
              " '3.4 Interprocess Communication   122\\n',\n",
              " '3.5 Examples of IPC Systems 130\\n',\n",
              " '\\n',\n",
              " 'Server Systems   136\\n',\n",
              " '3.7 Summary 147 Exercises 149\\n',\n",
              " 'Bibliographical Notes 161\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'xvii\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Chapter 4\\tThreads\\n',\n",
              " '\\n',\n",
              " '4.1 Overview 163\\n',\n",
              " '\\n',\n",
              " '4.6\\n',\n",
              " 'Threading Issues 183\\n',\n",
              " '4.2 Multicore Programming\\n',\n",
              " '166\\n',\n",
              " '4.7\\n',\n",
              " 'Operating-System Examples 188\\n',\n",
              " '4.3 Multithreading Models\\n',\n",
              " '169\\n',\n",
              " '4.8\\n',\n",
              " 'Summary 191\\n',\n",
              " '4.4 Thread Libraries 171\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Exercises 191\\n',\n",
              " '4.5 Implicit Threading 177\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Bibliographical Notes 199\\n',\n",
              " '\\n',\n",
              " 'Chapter 5\\tProcess Synchronization\\n',\n",
              " '\\n',\n",
              " '5.1 Background 203\\n',\n",
              " '\\n',\n",
              " '5.8\\n',\n",
              " 'Monitors 223\\n',\n",
              " '5.2 The Critical-Section Problem\\n',\n",
              " '206\\n',\n",
              " '5.9\\n',\n",
              " 'Synchronization Examples 232\\n',\n",
              " '5.3 Petersons Solution 207\\n',\n",
              " '\\n',\n",
              " '5.10\\n',\n",
              " 'Alternative Approaches 238\\n',\n",
              " '5.4 Synchronization Hardware\\n',\n",
              " '209\\n',\n",
              " '5.11\\n',\n",
              " 'Summary 242\\n',\n",
              " '5.5 Mutex Locks 212\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Exercises 242\\n',\n",
              " '5.6 Semaphores 213\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Bibliographical Notes 258\\n',\n",
              " '5.7 Classic Problems of\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Synchronization 219\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Chapter 6\\tCPU Scheduling\\n',\n",
              " '6.1 Basic Concepts 261\\n',\n",
              " '6.2 Scheduling Criteria 265\\n',\n",
              " '6.3 Scheduling Algorithms   266\\n',\n",
              " '6.4 Thread Scheduling   277\\n',\n",
              " '6.5 Multiple-Processor Scheduling   278\\n',\n",
              " '6.6 Real-Time CPU Scheduling 283\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '6.7 Operating-System Examples 290\\n',\n",
              " '6.8 Algorithm Evaluation 300\\n',\n",
              " '6.9 Summary 304 Exercises 305\\n',\n",
              " 'Bibliographical Notes 311\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Chapter 7\\tDeadlocks\\n',\n",
              " '7.1 System Model 315\\n',\n",
              " '7.2 Deadlock Characterization 317\\n',\n",
              " '7.3 Methods for Handling Deadlocks   322\\n',\n",
              " '7.4 Deadlock Prevention   323\\n',\n",
              " '7.5 Deadlock Avoidance   327\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '7.6 Deadlock Detection 333\\n',\n",
              " '7.7 Recovery from Deadlock 337\\n',\n",
              " '7.8 Summary 339 Exercises 339\\n',\n",
              " 'Bibliographical Notes 346\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'PART THREE\\tMEMORY MANAGEMENT\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Chapter 8\\tMain Memory\\n',\n",
              " '8.1 Background 351\\n',\n",
              " '8.2 Swapping 358\\n',\n",
              " '8.3 Contiguous Memory Allocation   360\\n',\n",
              " '8.4 Segmentation 364\\n',\n",
              " '8.5 Paging 366\\n',\n",
              " '8.6 Structure of the Page Table 378\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '8.7 Example: Intel 32 and 64-bit Architectures 383\\n',\n",
              " '8.8 Example: ARM Architecture 388\\n',\n",
              " '8.9 Summary 389 Exercises 390\\n',\n",
              " 'Bibliographical Notes 394\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Chapter 9\\tVirtual Memory\\n',\n",
              " '9.1 Background 397\\n',\n",
              " '9.2 Demand Paging 401\\n',\n",
              " '9.3 Copy-on-Write 408\\n',\n",
              " '9.4 Page Replacement 409\\n',\n",
              " '9.5 Allocation of Frames 421\\n',\n",
              " '9.6 Thrashing 425\\n',\n",
              " '9.7 Memory-Mapped Files 430\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '9.8 Allocating Kernel Memory 436\\n',\n",
              " '9.9 Other Considerations 439\\n',\n",
              " '9.10 Operating-System Examples 445\\n',\n",
              " '9.11 Summary 448 Exercises 449\\n',\n",
              " 'Bibliographical Notes 461\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'PART FOUR\\tSTORAGE MANAGEMENT\\n',\n",
              " '\\n',\n",
              " 'Chapter 10\\tMass-Storage Structure\\n',\n",
              " '\\n',\n",
              " '10.1 Overview of Mass-Storage Structure 467\\n',\n",
              " '10.2 Disk Structure 470\\n',\n",
              " '10.3 Disk Attachment 471\\n',\n",
              " '10.4 Disk Scheduling 472\\n',\n",
              " '10.5 Disk Management 478\\n',\n",
              " '10.6 \\n',\n",
              " 'Swap-Space Management 482\\n',\n",
              " '10.7 RAID Structure 484\\n',\n",
              " '10.8 Stable-Storage Implementation 494\\n',\n",
              " '10.9 \\tSummary 496 Exercises 497\\n',\n",
              " 'Bibliographical Notes 501\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Chapter 11\\tFile-System Interface\\n',\n",
              " '\\n',\n",
              " '11.1 File Concept 503\\n',\n",
              " '11.2 Access Methods 513\\n',\n",
              " '11.3 Directory and Disk Structure   515\\n',\n",
              " '11.4 File-System Mounting 526\\n',\n",
              " '11.5 File Sharing 528\\n',\n",
              " '11.6 \\n',\n",
              " 'Protection 533\\n',\n",
              " '11.7 Summary 538 Exercises 539\\n',\n",
              " 'Bibliographical Notes 541\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Chapter 12\\tFile-System Implementation\\n',\n",
              " '\\n',\n",
              " '12.1 File-System Structure 543\\n',\n",
              " '12.7\\n',\n",
              " 'Recovery 568\\n',\n",
              " '\\n',\n",
              " '12.2 File-System Implementation 546\\n',\n",
              " '12.8\\n',\n",
              " 'NFS 571\\n',\n",
              " '\\n',\n",
              " '12.3 Directory Implementation 552\\n',\n",
              " '12.9\\n',\n",
              " 'Example: The WAFL File System\\n',\n",
              " '577\\n',\n",
              " '12.4 Allocation Methods 553\\n',\n",
              " '12.5 Free-Space Management 561\\n',\n",
              " '12.6 Efficiency and Performance 564\\n',\n",
              " '12.10\\n',\n",
              " 'Summary 580\\n',\n",
              " 'Exercises 581\\n',\n",
              " 'Bibliographical Notes 585\\n',\n",
              " '\\n',\n",
              " 'Chapter 13\\tI/O Systems\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '13.1 Overview 587\\n',\n",
              " '13.6\\n',\n",
              " 'STREAMS 613\\n',\n",
              " '\\n',\n",
              " '13.2 I/O Hardware  588\\n',\n",
              " '13.7\\n',\n",
              " 'Performance 615\\n',\n",
              " '\\n',\n",
              " '13.3 Application I/O Interface   597\\n',\n",
              " '13.4 Kernel I/O Subsystem  604\\n',\n",
              " '13.5 Transforming I/O Requests to\\n',\n",
              " '13.8\\n',\n",
              " 'Summary 618\\n',\n",
              " 'Exercises 619\\n',\n",
              " 'Bibliographical Notes 621\\n',\n",
              " '\\n',\n",
              " 'Hardware Operations 611\\n',\n",
              " '\\n',\n",
              " 'PART FIVE\\tPROTECTION AND SECURITY\\n',\n",
              " '\\n',\n",
              " 'Chapter 14\\tProtection\\n',\n",
              " '\\n',\n",
              " '14.1 Goals of Protection 625\\n',\n",
              " '\\n',\n",
              " '14.7\\n',\n",
              " 'Revocation of Access Rights 640\\n',\n",
              " '14.2 Principles of Protection 626\\n',\n",
              " '\\n',\n",
              " '14.8\\n',\n",
              " 'Capability-Based Systems 641\\n',\n",
              " '14.3 Domain of Protection 627\\n',\n",
              " '\\n',\n",
              " '14.9\\n',\n",
              " 'Language-Based Protection 644\\n',\n",
              " '14.4 Access Matrix 632\\n',\n",
              " '14.5 Implementation of the Access Matrix 636\\n',\n",
              " '14.6 Access Control 639\\n',\n",
              " '\\n',\n",
              " '14.10\\n',\n",
              " 'Summary 649\\n',\n",
              " 'Exercises 650\\n',\n",
              " 'Bibliographical Notes 652\\n',\n",
              " 'Chapter 15\\tSecurity\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '15.1 The Security Problem 657\\n',\n",
              " '15.2 Program Threats 661\\n',\n",
              " '15.3 System and Network Threats   669\\n',\n",
              " '\\n',\n",
              " '15.8\\n',\n",
              " '\\n',\n",
              " '15.9\\n',\n",
              " 'Computer-Security Classifications 698\\n',\n",
              " 'An Example: Windows 7 699\\n',\n",
              " '15.4 Cryptography as a Security Tool\\n',\n",
              " '15.5 User Authentication 685\\n',\n",
              " '15.6 Implementing Security Defenses\\n',\n",
              " '674\\n',\n",
              " '\\n',\n",
              " '689\\n',\n",
              " '15.10\\n',\n",
              " 'Summary 701\\n',\n",
              " 'Exercises 702\\n',\n",
              " 'Bibliographical Notes 704\\n',\n",
              " '15.7 Firewalling to Protect Systems and\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Networks 696\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'PART SIX\\tADVANCED TOPICS\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Chapter 16\\tVirtual Machines\\n',\n",
              " '16.1 Overview   711\\n',\n",
              " '16.2 History 713\\n',\n",
              " '16.3 Benefits and Features 714\\n',\n",
              " '16.4 Building Blocks 717\\n',\n",
              " '16.5 Types of Virtual Machines and Their Implementations 721\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '16.6 Virtualization and Operating-System Components 728\\n',\n",
              " '16.7 Examples 735\\n',\n",
              " '16.8 Summary 737 Exercises 738\\n',\n",
              " 'Bibliographical Notes 739\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Chapter 17\\tDistributed Systems\\n',\n",
              " '17.1 Advantages of Distributed Systems 741\\n',\n",
              " '17.2 Types of Network-\\n',\n",
              " 'based Operating Systems 743\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '17.6 An Example: TCP/IP   760\\n',\n",
              " '17.7 Robustness 762\\n',\n",
              " '17.8 Design Issues 764\\n',\n",
              " '17.9 Distributed File Systems 765\\n',\n",
              " '\\n',\n",
              " '17.3 Network Structure 747\\n',\n",
              " '17.4 Communication Structure   751\\n',\n",
              " '17.5 Communication Protocols   756\\n',\n",
              " '17.10 \\t    773 Exercises    774\\n',\n",
              " 'Bibliographical Notes 777\\n',\n",
              " '\\n',\n",
              " 'PART SEVEN\\tCASE STUDIES\\n',\n",
              " '\\n',\n",
              " 'Chapter 18\\tThe Linux System\\n',\n",
              " '\\n',\n",
              " '18.1 Linux History 781\\n',\n",
              " '18.8\\n',\n",
              " 'Input and Output 815\\n',\n",
              " '\\n',\n",
              " '18.2 Design Principles 786\\n',\n",
              " '18.9\\n',\n",
              " 'Interprocess Communication\\n',\n",
              " '818\\n',\n",
              " '18.3 Kernel Modules 789\\n',\n",
              " '18.10\\n',\n",
              " 'Network Structure 819\\n',\n",
              " '\\n',\n",
              " '18.4 Process Management 792\\n',\n",
              " '18.11\\n',\n",
              " 'Security 821\\n',\n",
              " '\\n',\n",
              " '18.5 Scheduling 795\\n',\n",
              " '18.6 Memory Management 800\\n',\n",
              " '18.7 File Systems 809\\n',\n",
              " '18.12\\n',\n",
              " 'Summary 824\\n',\n",
              " 'Exercises 824\\n',\n",
              " 'Bibliographical Notes 826\\n',\n",
              " '\\n',\n",
              " 'Chapter 19\\tWindows 7\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '19.1 History 829\\n',\n",
              " '19.6\\n',\n",
              " 'Networking 869\\n',\n",
              " '\\n',\n",
              " '19.2 Design Principles 831\\n',\n",
              " '19.7\\n',\n",
              " 'Programmer Interface 874\\n',\n",
              " '\\n',\n",
              " '19.3 System Components 838\\n',\n",
              " '19.4 Terminal Services and Fast User\\n',\n",
              " 'Switching 862\\n',\n",
              " '19.8\\n',\n",
              " 'Summary 883\\n',\n",
              " 'Exercises 883\\n',\n",
              " 'Bibliographical Notes 885\\n',\n",
              " '\\n',\n",
              " '19.5 File System 863\\n',\n",
              " '\\n',\n",
              " 'Chapter 20\\tInfluential Operating Systems\\n',\n",
              " '\\n',\n",
              " '20.1 Feature Migration 887\\n',\n",
              " '20.10\\n',\n",
              " 'TOPS-20 901\\n',\n",
              " '\\n',\n",
              " '20.2 Early Systems 888\\n',\n",
              " '20.11\\n',\n",
              " 'CP/M and MS/DOS\\n',\n",
              " '901\\n',\n",
              " '20.3 Atlas 895\\n',\n",
              " '20.12\\n',\n",
              " 'Macintosh Operating System and\\n',\n",
              " '20.4 XDS-940 896\\n',\n",
              " '\\n',\n",
              " 'Windows 902\\n',\n",
              " '20.5 THE 897\\n',\n",
              " '20.13\\n',\n",
              " 'Mach 902\\n',\n",
              " '20.6 RC 4000 897\\n',\n",
              " '20.14\\n',\n",
              " 'Other Systems 904\\n',\n",
              " '20.7 CTSS 898\\n',\n",
              " '\\n',\n",
              " 'Exercises 904\\n',\n",
              " '20.8 MULTICS 899\\n',\n",
              " '\\n',\n",
              " 'Bibliographical Notes 904\\n',\n",
              " '20.9 IBM OS/360   899\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'PART EIGHT\\tAPPENDICES\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Appendix A\\tBSD UNIX\\n',\n",
              " 'A.1 UNIX History A1\\n',\n",
              " 'A.2 Design Principles A6\\n',\n",
              " 'A.3 Programmer Interface A8\\n',\n",
              " 'A.4 User Interface A15\\n',\n",
              " 'A.5 Process Management A18\\n',\n",
              " 'A.6 Memory Management A22\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'A.7 File System   A24\\n',\n",
              " 'A.8 I/O System   A32\\n',\n",
              " 'A.9 Interprocess Communication A36\\n',\n",
              " 'A.10 Summary A40 Exercises A41\\n',\n",
              " 'Bibliographical Notes A42\\n',\n",
              " '\\n',\n",
              " 'xxii\\tContents\\n',\n",
              " 'Appendix B\\tThe Mach System\\n',\n",
              " 'B.1 History of the Mach System B1\\n',\n",
              " 'B.2 Design Principles B3\\n',\n",
              " 'B.3 System Components   B4\\n',\n",
              " 'B.4 Process Management   B7\\n',\n",
              " 'B.5 Interprocess Communication B13\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'B.6 Memory Management   B18\\n',\n",
              " 'B.7 Programmer Interface   B23\\n',\n",
              " 'B.8 Summary B24 Exercises B25\\n',\n",
              " 'Bibliographical Notes B26\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Part One\\n',\n",
              " 'Overview\\n',\n",
              " 'An operating system acts as an intermediary between the user of a computer and the computer hardware. The purpose of an operating system is to provide an environment in which a user can execute programs in a convenient and efficient manner.\\n',\n",
              " '   An operating system is software that manages the computer hard- ware. The hardware must provide appropriate mechanisms to ensure the correct operation of the computer system and to prevent user programs from interfering with the proper operation of the system.\\n',\n",
              " '   Internally, operating systems vary greatly in their makeup, since they are organized along many different lines. The design of a new operating system is a major task. It is important that the goals of the system be well defined before the design begins. These goals form the basis for choices among various algorithms and strategies.\\n',\n",
              " '   Because an operating system is large and complex, it must be created piece by piece. Each of these pieces should be a well-delineated portion of the system, with carefully defined inputs, outputs, and functions.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Introduction\\n',\n",
              " '\\n',\n",
              " 'An operating system is a program that manages a computers hardware. It also provides a basis for application programs and acts as an intermediary between the computer user and the computer hardware. An amazing aspect of operating systems is how they vary in accomplishing these tasks. Mainframe operating systems are designed primarily to optimize utilization of hardware. Personal computer (PC) operating systems support complex games, business applications, and everything in between. Operating systems for mobile com- puters provide an environment in which a user can easily interface with the computer to execute programs. Thus, some operating systems are designed to be convenient, others to be efflcient, and others to be some combination of the two.\\n',\n",
              " '    Before we can explore the details of computer system operation, we need to know something about system structure. We thus discuss the basic functions of system startup, I/O, and storage early in this chapter. We also describe the basic computer architecture that makes it possible to write a functional operating system.\\n',\n",
              " '   Because an operating system is large and complex, it must be created piece by piece. Each of these pieces should be a well-delineated portion of the system, with carefully defined inputs, outputs, and functions. In this chapter, we provide a general overview of the major components of a contemporary computer system as well as the functions provided by the operating system. Additionally, we cover several other topics to help set the stage for the remainder of this text: data structures used in operating systems, computing environments, and open-source operating systems.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '3\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Figure 1.1 Abstract view of the components of a computer system.\\n',\n",
              " '\\n',\n",
              " '1.1 What Operating Systems Do\\n',\n",
              " 'We begin our discussion by looking at the operating systems role in the overall computer system. A computer system can be divided roughly into four components: the hardware, the operating system, the application programs, and the users (Figure 1.1).\\n',\n",
              " '    The hardware the central processing unit (CPU), the memory, and the input/output (I/O) devices provides the basic computing resources for the system. The application programs such as word processors, spreadsheets, compilers, and Web browsers define the ways in which these resources are used to solve users computing problems. The operating system controls the hardware and coordinates its use among the various application programs for the various users.\\n',\n",
              " '   We can also view a computer system as consisting of hardware, software, and data. The operating system provides the means for proper use of these resources in the operation of the computer system. An operating system is similar to a government. Like a government, it performs no useful function by itself. It simply provides an environment within which other programs can do useful work.\\n',\n",
              " '   To understand more fully the operating systems role, we next explore operating systems from two viewpoints: that of the user and that of the system.\\n',\n",
              " '\\n',\n",
              " '1.1.1 User View\\n',\n",
              " 'The users view of the computer varies according to the interface being used. Most computer users sit in front of a PC, consisting of a monitor, keyboard, mouse, and system unit. Such a system is designed for one user\\n',\n",
              " '\\n',\n",
              " '1.1 What Operating Systems Do\\t5\\n',\n",
              " '\\n',\n",
              " 'to monopolize its resources. The goal is to maximize the work (or play) that the user is performing. In this case, the operating system is designed mostly for ease of use, with some attention paid to performance and none paid to resource utilization  how various hardware and software resources are shared. Performance is, of course, important to the user; but such systems are optimized for the single-user experience rather than the requirements of multiple users.\\n',\n",
              " '   In other cases, a user sits at a terminal connected to a mainframe or a minicomputer. Other users are accessing the same computer through other terminals. These users share resources and may exchange information. The operating system in such cases is designed to maximize resource utilization to assure that all available CPU time, memory, and I/O are used efficiently and that no individual user takes more than her fair share.\\n',\n",
              " '   In still other cases, users sit at workstations connected to networks of other workstations and servers. These users have dedicated resources at their disposal, but they also share resources such as networking and servers, including file, compute, and print servers. Therefore, their operating system is designed to compromise between individual usability and resource utilization. Recently, many varieties of mobile computers, such as smartphones and tablets, have come into fashion. Most mobile computers are standalone units for individual users. Quite often, they are connected to networks through cellular or other wireless technologies. Increasingly, these mobile devices are replacing desktop and laptop computers for people who are primarily interested in using computers for e-mail and web browsing. The user interface for mobile computers generally features a touch screen, where the user interacts with the system by pressing and swiping fingers across the screen rather than using a\\n',\n",
              " 'physical keyboard and mouse.\\n',\n",
              " '   Some computers have little or no user view. For example, embedded computers in home devices and automobiles may have numeric keypads and may turn indicator lights on or off to show status, but they and their operating systems are designed primarily to run without user intervention.\\n',\n",
              " '\\n',\n",
              " '1.1.2 System View\\n',\n",
              " 'From the computers point of view, the operating system is the program most intimately involved with the hardware. In this context, we can view an operating system as a resource allocator. A computer system has many resources that may be required to solve a problem: CPU time, memory space, file-storage space, I/O devices, and so on. The operating system acts as the manager of these resources. Facing numerous and possibly conflicting requests for resources, the operating system must decide how to allocate them to specific programs and users so that it can operate the computer system efficiently and fairly. As we have seen, resource allocation is especially important where many users access the same mainframe or minicomputer.\\n',\n",
              " '   A slightly different view of an operating system emphasizes the need to control the various I/O devices and user programs. An operating system is a control program. A control program manages the execution of user programs to prevent errors and improper use of the computer. It is especially concerned with the operation and control of I/O devices.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '1.1.3 Defining Operating Systems\\n',\n",
              " 'By now, you can probably see that the term operating system covers many roles and functions. That is the case, at least in part, because of the myriad designs and uses of computers. Computers are present within toasters, cars, ships, spacecraft, homes, and businesses. They are the basis for game machines, music players, cable TV tuners, and industrial control systems. Although computers have a relatively short history, they have evolved rapidly. Computing started as an experiment to determine what could be done and quickly moved to fixed-purpose systems for military uses, such as code breaking and trajectory plotting, and governmental uses, such as census calculation. Those early computers evolved into general-purpose, multifunction mainframes, and thats when operating systems were born. In the 1960s, Moores Law predicted that the number of transistors on an integrated circuit would double every eighteen months, and that prediction has held true. Computers gained in functionality and shrunk in size, leading to a vast number of uses and a vast number and variety of operating systems. (See Chapter 20 for more details on the history of operating systems.)\\n',\n",
              " '    How, then, can we define what an operating system is? In general, we have no completely adequate definition of an operating system. Operating systems exist because they offer a reasonable way to solve the problem of creating a usable computing system. The fundamental goal of computer systems is to execute user programs and to make solving user problems easier. Computer hardware is constructed toward this goal. Since bare hardware alone is not particularly easy to use, application programs are developed. These programs require certain common operations, such as those controlling the I/O devices. The common functions of controlling and allocating resources are then brought together into one piece of software: the operating system.\\n',\n",
              " '    In addition, we have no universally accepted definition of what is part of the operating system. A simple viewpoint is that it includes everything a vendor ships when you order the operating system. The features included, however, vary greatly across systems. Some systems take up less than a megabyte of space and lack even a full-screen editor, whereas others require gigabytes of space and are based entirely on graphical windowing systems. A more common definition, and the one that we usually follow, is that the operating system is the one program running at all times on the computer usually called the kernel. (Along with the kernel, there are two other types of programs: system programs, which are associated with the operating system but are not necessarily part of the kernel, and application programs, which include all programs not associated with the operation of the system.)\\n',\n",
              " '   The matter of what constitutes an operating system became increasingly important as personal computers became more widespread and operating systems grew increasingly sophisticated. In 1998, the United States Department of Justice filed suit against Microsoft, in essence claiming that Microsoft included too much functionality in its operating systems and thus prevented application vendors from competing. (For example, a Web browser was an integral part of the operating systems.) As a result, Microsoft was found guilty of using its operating-system monopoly to limit competition.\\n',\n",
              " '   Today, however, if we look at operating systems for mobile devices, we see that once again the number of features constituting the operating system\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'is increasing. Mobile operating systems often include not only a core kernel but also middleware  a set of software frameworks that provide additional services to application developers. For example, each of the two most promi- nent mobile operating systems Apples iOS and Googles Android features a core kernel along with middleware that supports databases, multimedia, and graphics (to name a only few).\\n',\n",
              " '\\n',\n",
              " '1.2 Computer-System Organization\\n',\n",
              " 'Before we can explore the details of how computer systems operate, we need general knowledge of the structure of a computer system. In this section, we look at several parts of this structure. The section is mostly concerned with computer-system organization, so you can skim or skip it if you already understand the concepts.\\n',\n",
              " '\\n',\n",
              " '1.2.1 Computer-System Operation\\n',\n",
              " 'A modern general-purpose computer system consists of one or more CPUs and a number of device controllers connected through a common bus that provides access to shared memory (Figure 1.2). Each device controller is in charge of a specific type of device (for example, disk drives, audio devices, or video displays). The CPU and the device controllers can execute in parallel, competing for memory cycles. To ensure orderly access to the shared memory, a memory controller synchronizes access to the memory.\\n',\n",
              " '   For a computer to start running  for instance, when it is powered up or rebooted  it needs to have an initial program to run. This initial program, or bootstrap program, tends to be simple. Typically, it is stored within the computer hardware in read-only memory (ROM) or electrically erasable programmable read-only memory (EEPROM), known by the general term firmware. It initializes all aspects of the system, from CPU registers to device controllers to memory contents. The bootstrap program must know how to load the operating system and how to start executing that system. To accomplish\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Figure 1.2 A modern computer system.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'CPU\\tuser\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'I\\n',\n",
              " 'd\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '  I/O request\\n',\n",
              " '\\n',\n",
              " 'transfer done\\n',\n",
              " '  \\n',\n",
              " 'I/O request\\n',\n",
              " '\\n',\n",
              " 'transfer done\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Figure 1.3 Interrupt timeline for a single process doing output.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'this goal, the bootstrap program must locate the operating-system kernel and load it into memory.\\n',\n",
              " '   Once the kernel is loaded and executing, it can start providing services to the system and its users. Some services are provided outside of the kernel, by system programs that are loaded into memory at boot time to become system processes, or system daemons that run the entire time the kernel is running. On UNIX, the first system process is init, and it starts many other daemons. Once this phase is complete, the system is fully booted, and the system waits for some event to occur.\\n',\n",
              " '   The occurrence of an event is usually signaled by an interrupt from either the hardware or the software. Hardware may trigger an interrupt at any time by sending a signal to the CPU, usually by way of the system bus. Software may trigger an interrupt by executing a special operation called a system call (also called a monitor call).\\n',\n",
              " '   When the CPU is interrupted, it stops what it is doing and immediately transfers execution to a fixed location. The fixed location usually contains the starting address where the service routine for the interrupt is located. The interrupt service routine executes; on completion, the CPU resumes the interrupted computation. A timeline of this operation is shown in Figure 1.3.\\n',\n",
              " '    Interrupts are an important part of a computer architecture. Each computer design has its own interrupt mechanism, but several functions are common. The interrupt must transfer control to the appropriate interrupt service routine. The straightforward method for handling this transfer would be to invoke a generic routine to examine the interrupt information. The routine, in turn, would call the interrupt-specific handler. However, interrupts must be handled quickly. Since only a predefined number of interrupts is possible, a table of pointers to interrupt routines can be used instead to provide the necessary speed. The interrupt routine is called indirectly through the table, with no intermediate routine needed. Generally, the table of pointers is stored in low memory (the first hundred or so locations). These locations hold the addresses of the interrupt service routines for the various devices. This array, or interrupt vector, of addresses is then indexed by a unique device number, given with the interrupt request, to provide the address of the interrupt service routine for\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'the interrupting device. Operating systems as different as Windows and UNIX\\n',\n",
              " 'dispatch interrupts in this manner.\\n',\n",
              " '   The interrupt architecture must also save the address of the interrupted instruction. Many old designs simply stored the interrupt address in a fixed location or in a location indexed by the device number. More recent architectures store the return address on the system stack. If the interrupt routine needs to modify the processor state for instance, by modifying register values it must explicitly save the current state and then restore that state before returning. After the interrupt is serviced, the saved return address is loaded into the program counter, and the interrupted computation resumes as though the interrupt had not occurred.\\n',\n",
              " '\\n',\n",
              " '1.2.2 Storage Structure\\n',\n",
              " 'The CPU can load instructions only from memory, so any programs to run must be stored there. General-purpose computers run most of their programs from rewritable memory, called main memory (also called random-access memory, or RAM). Main memory commonly is implemented in a semiconductor technology called dynamic random-access memory (DRAM).\\n',\n",
              " '    Computers use other forms of memory as well. We have already mentioned read-only memory, ROM) and electrically erasable programmable read-only memory, EEPROM). Because ROM cannot be changed, only static programs, such as the bootstrap program described earlier, are stored there. The immutability of ROM is of use in game cartridges. EEPROM can be changed but cannot be changed frequently and so contains mostly static programs. For example, smartphones have EEPROM to store their factory-installed programs.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '   All forms of memory provide an array of bytes. Each byte has its own address. Interaction is achieved through a sequence of load or store instructions to specific memory addresses. The load instruction moves a byte or word from main memory to an internal register within the CPU, whereas the store instruction moves the content of a register to main memory. Aside from explicit loads and stores, the CPU automatically loads instructions from main memory for execution.\\n',\n",
              " '    A typical instruction execution cycle, as executed on a system with a von Neumann architecture, first fetches an instruction from memory and stores that instruction in the instruction register. The instruction is then decoded and may cause operands to be fetched from memory and stored in some internal register. After the instruction on the operands has been executed, the result may be stored back in memory. Notice that the memory unit sees only a stream of memory addresses. It does not know how they are generated (by the instruction counter, indexing, indirection, literal addresses, or some other means) or what they are for (instructions or data). Accordingly, we can ignore how a memory address is generated by a program. We are interested only in the sequence of memory addresses generated by the running program.\\n',\n",
              " '   Ideally, we want the programs and data to reside in main memory permanently. This arrangement usually is not possible for the following two reasons:\\n',\n",
              " '1. Main memory is usually too small to store all needed programs and data permanently.\\n',\n",
              " '2. Main memory is a volatile storage device that loses its contents when power is turned off or otherwise lost.\\n',\n",
              " 'Thus, most computer systems provide secondary storage as an extension of main memory. The main requirement for secondary storage is that it be able to hold large quantities of data permanently.\\n',\n",
              " '   The most common secondary-storage device is a magnetic disk, which provides storage for both programs and data. Most programs (system and application) are stored on a disk until they are loaded into memory. Many programs then use the disk as both the source and the destination of their processing. Hence, the proper management of disk storage is of central importance to a computer system, as we discuss in Chapter 10.\\n',\n",
              " '   In a larger sense, however, the storage structure that we have described consisting of registers, main memory, and magnetic disks  is only one of many possible storage systems. Others include cache memory, CD-ROM, magnetic tapes, and so on. Each storage system provides the basic functions of storing a datum and holding that datum until it is retrieved at a later time. The main differences among the various storage systems lie in speed, cost, size, and volatility.\\n',\n",
              " '    The wide variety of storage systems can be organized in a hierarchy (Figure 1.4) according to speed and cost. The higher levels are expensive, but they are fast. As we move down the hierarchy, the cost per bit generally decreases, whereas the access time generally increases. This trade-off is reasonable; if a given storage system were both faster and less expensive than another other properties being the same  then there would be no reason to use the slower, more expensive memory. In fact, many early storage devices, including paper\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Figure 1.4 Storage-device hierarchy.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'tape and core memories, are relegated to museums now that magnetic tape and semiconductor memory have become faster and cheaper. The top four levels of memory in Figure 1.4 may be constructed using semiconductor memory.\\n',\n",
              " '   In addition to differing in speed and cost, the various storage systems are either volatile or nonvolatile. As mentioned earlier, volatile storage loses its contents when the power to the device is removed. In the absence of expensive battery and generator backup systems, data must be written to nonvolatile storage for safekeeping. In the hierarchy shown in Figure 1.4, the storage systems above the solid-state disk are volatile, whereas those including the solid-state disk and below are nonvolatile.\\n',\n",
              " '   Solid-state disks have several variants but in general are faster than magnetic disks and are nonvolatile. One type of solid-state disk stores data in a large DRAM array during normal operation but also contains a hidden magnetic hard disk and a battery for backup power. If external power is interrupted, this solid-state disks controller copies the data from RAM to the magnetic disk. When external power is restored, the controller copies the data back into RAM. Another form of solid-state disk is flash memory, which is popular in cameras and personal digital assistants (PDAs), in robots, and increasingly for storage on general-purpose computers. Flash memory is slower than DRAM but needs no power to retain its contents. Another form of nonvolatile storage is NVRAM, which is DRAM with battery backup power. This memory can be as fast as DRAM and (as long as the battery lasts) is nonvolatile.\\n',\n",
              " '   The design of a complete memory system must balance all the factors just discussed: it must use only as much expensive memory as necessary while providing as much inexpensive, nonvolatile memory as possible. Caches can\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'be installed to improve performance where a large disparity in access time or transfer rate exists between two components.\\n',\n",
              " '\\n',\n",
              " '1.2.3 I/O Structure\\n',\n",
              " 'Storage is only one of many types of I/O devices within a computer. A large portion of operating system code is dedicated to managing I/O, both because of its importance to the reliability and performance of a system and because of the varying nature of the devices. Next, we provide an overview of I/O.\\n',\n",
              " '   A general-purpose computer system consists of CPUs and multiple device controllers that are connected through a common bus. Each device controller is in charge of a specific type of device. Depending on the controller, more than one device may be attached. For instance, seven or more devices can be attached to the small computer-systems interface (SCSI) controller. A device controller maintains some local buffer storage and a set of special-purpose registers. The device controller is responsible for moving the data between the peripheral devices that it controls and its local buffer storage. Typically, operating systems have a device driver for each device controller. This device driver understands the device controller and provides the rest of the operating system with a uniform interface to the device.\\n',\n",
              " '   To start an I/O operation, the device driver loads the appropriate registers within the device controller. The device controller, in turn, examines the contents of these registers to determine what action to take (such as read a character from the keyboard). The controller starts the transfer of data from the device to its local buffer. Once the transfer of data is complete, the device controller informs the device driver via an interrupt that it has finished its operation. The device driver then returns control to the operating system, possibly returning the data or a pointer to the data if the operation was a read. For other operations, the device driver returns status information.\\n',\n",
              " '   This form of interrupt-driven I/O is fine for moving small amounts of data but can produce high overhead when used for bulk data movement such as disk I/O. To solve this problem, direct memory access (DMA) is used. After setting up buffers, pointers, and counters for the I/O device, the device controller transfers an entire block of data directly to or from its own buffer storage to memory, with no intervention by the CPU. Only one interrupt is generated per block, to tell the device driver that the operation has completed, rather than the one interrupt per byte generated for low-speed devices. While the device controller is performing these operations, the CPU is available to accomplish other work.\\n',\n",
              " '   Some high-end systems use switch rather than bus architecture. On these systems, multiple components can talk to other components concurrently, rather than competing for cycles on a shared bus. In this case, DMA is even more effective. Figure 1.5 shows the interplay of all components of a computer system.\\n',\n",
              " '\\n',\n",
              " '1.3 Computer-System Architecture\\n',\n",
              " 'In Section 1.2, we introduced the general structure of a typical computer system. A computer system can be organized in a number of different ways, which we\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'instruction execution cycle\\n',\n",
              " '\\n',\n",
              " 'data movement\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'DMA\\n',\n",
              " '\\t\\n',\n",
              " '\\n',\n",
              " 'Figure 1.5 How a modern computer system works.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'can categorize roughly according to the number of general-purpose processors used.\\n',\n",
              " '\\n',\n",
              " '1.3.1 Single-Processor Systems\\n',\n",
              " 'Until recently, most computer systems used a single processor. On a single- processor system, there is one main CPU capable of executing a general-purpose instruction set, including instructions from user processes. Almost all single- processor systems have other special-purpose processors as well. They may come in the form of device-specific processors, such as disk, keyboard, and graphics controllers; or, on mainframes, they may come in the form of more general-purpose processors, such as I/O processors that move data rapidly among the components of the system.\\n',\n",
              " '   All of these special-purpose processors run a limited instruction set and do not run user processes. Sometimes, they are managed by the operating system, in that the operating system sends them information about their next task and monitors their status. For example, a disk-controller microprocessor receives a sequence of requests from the main CPU and implements its own disk queue and scheduling algorithm. This arrangement relieves the main CPU of the overhead of disk scheduling. PCs contain a microprocessor in the keyboard to convert the keystrokes into codes to be sent to the CPU. In other systems or circumstances, special-purpose processors are low-level components built into the hardware. The operating system cannot communicate with these processors; they do their jobs autonomously. The use of special-purpose microprocessors is common and does not turn a single-processor system into\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'a multiprocessor. If there is only one general-purpose CPU, then the system is a single-processor system.\\n',\n",
              " '\\n',\n",
              " '1.3.2 Multiprocessor Systems\\n',\n",
              " 'Within the past several years, multiprocessor systems (also known as parallel systems or multicore systems) have begun to dominate the landscape of computing. Such systems have two or more processors in close communication, sharing the computer bus and sometimes the clock, memory, and peripheral devices. Multiprocessor systems first appeared prominently appeared in servers and have since migrated to desktop and laptop systems. Recently, multiple processors have appeared on mobile devices such as smartphones and tablet computers.\\n',\n",
              " 'Multiprocessor systems have three main advantages:\\n',\n",
              " '\\n',\n",
              " '1. Increased throughput. By increasing the number of processors, we expect to get more work done in less time. The speed-up ratio with N processors is not N, however; rather, it is less than N. When multiple processors cooperate on a task, a certain amount of overhead is incurred in keeping all the parts working correctly. This overhead, plus contention for shared resources, lowers the expected gain from additional processors. Similarly, N programmers working closely together do not produce N times the amount of work a single programmer would produce.\\n',\n",
              " '2. Economy of scale. Multiprocessor systems can cost less than equivalent multiple single-processor systems, because they can share peripherals, mass storage, and power supplies. If several programs operate on the same set of data, it is cheaper to store those data on one disk and to have all the processors share them than to have many computers with local disks and many copies of the data.\\n',\n",
              " '3. Increased reliability. If functions can be distributed properly among several processors, then the failure of one processor will not halt the system, only slow it down. If we have ten processors and one fails, then each of the remaining nine processors can pick up a share of the work of the failed processor. Thus, the entire system runs only 10 percent slower, rather than failing altogether.\\n',\n",
              " '\\n',\n",
              " '   Increased reliability of a computer system is crucial in many applications. The ability to continue providing service proportional to the level of surviving hardware is called graceful degradation. Some systems go beyond graceful degradation and are called fault tolerant, because they can suffer a failure of any single component and still continue operation. Fault tolerance requires a mechanism to allow the failure to be detected, diagnosed, and, if possible, corrected. The HP NonStop (formerly Tandem) system uses both hardware and software duplication to ensure continued operation despite faults. The system consists of multiple pairs of CPUs, working in lockstep. Both processors in the pair execute each instruction and compare the results. If the results differ, then one CPU of the pair is at fault, and both are halted. The process that was being executed is then moved to another pair of CPUs, and the instruction that failed\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'is restarted. This solution is expensive, since it involves special hardware and considerable hardware duplication.\\n',\n",
              " '   The multiple-processor systems in use today are of two  types. Some systems use asymmetric multiprocessing, in which each processor is assigned a specific task. A boss processor controls the system; the other processors either look to the boss for instruction or have predefined tasks. This scheme defines a boss worker relationship. The boss processor schedules and allocates work to the worker processors.\\n',\n",
              " '   The most common systems use symmetric multiprocessing (SMP), in which each processor performs all tasks within the operating system. SMP means that all processors are peers; no boss worker relationship exists between processors. Figure 1.6 illustrates a typical SMP architecture. Notice that each processor has its own set of registers, as well as a private or local\\n',\n",
              " ' cache. However, all processors share physical memory. An example of an SMP system is AIX, a commercial version of UNIX designed by IBM. An AIX system can be configured to employ dozens of processors. The benefit of this model is that many processes can run simultaneously N processes can run if there are N CPUs without causing performance to deteriorate significantly. However, we must carefully control I/O to ensure that the data reach the appropriate processor. Also, since the CPUs are separate, one may be sitting idle while another is overloaded, resulting in inefficiencies. These inefficiencies can be avoided if the processors share certain data structures. A multiprocessor system of this form will  allow  processes and  resources such as memory to be shared dynamically among the various processors and can lower the variance among the processors. Such a system must be written carefully, as we shall see in Chapter 5. Virtually all modern operating systems including Windows, Mac OS X, and Linux now provide support for SMP.\\n',\n",
              " '   The difference between symmetric and asymmetric multiprocessing may result from either hardware or software. Special hardware can differentiate the multiple processors, or the software can be written to allow only one boss and multiple workers. For instance, Sun Microsystems operating system SunOS Version 4 provided asymmetric multiprocessing, whereas Version 5 (Solaris) is symmetric on the same hardware.\\n',\n",
              " '   Multiprocessing adds CPUs to increase computing power. If the CPU has an integrated memory controller, then adding CPUs can also increase the amount\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Figure 1.6 Symmetric multiprocessing architecture.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'of memory addressable in the system. Either way, multiprocessing can cause a system to change its memory access model from uniform memory access (UMA) to non-uniform memory access (NUMA). UMA is defined as the situation in which access to any RAM from any CPU takes the same amount of time. With NUMA, some parts of memory may take longer to access than other parts, creating a performance penalty. Operating systems can minimize the NUMA penalty through resource management, as discussed in Section 9.5.4.\\n',\n",
              " '   A recent trend in CPU design is to include multiple computing cores on a single chip. Such multiprocessor systems are termed multicore. They can be more efficient than multiple chips with single cores because on-chip communication is faster than between-chip communication. In addition, one chip with multiple cores uses significantly less power than multiple single-core chips.\\n',\n",
              " '   It is important to note that while multicore systems are multiprocessor systems, not all multiprocessor systems are multicore, as we shall see in Section\\n',\n",
              " '1.3.3. In our coverage of multiprocessor systems throughout this text, unless we state otherwise, we generally use the more contemporary term multicore, which excludes some multiprocessor systems.\\n',\n",
              " '   In Figure 1.7, we show a dual-core design with two cores on the same chip. In this design, each core has its own register set as well as its own local cache. Other designs might use a shared cache or a combination of local and shared caches. Aside from architectural considerations, such as cache, memory, and bus contention, these multicore CPUs appear to the operating system as N standard processors. This characteristic puts pressure on operating system designers and application programmers to make use of those processing cores.\\n',\n",
              " '    Finally, blade servers are a relatively recent development in which multiple processor boards, I/O boards, and networking boards are placed in the same chassis. The difference between these and traditional multiprocessor systems is that each blade-processor board boots independently and runs its own operating system. Some blade-server boards are multiprocessor as well, which blurs the lines between types of computers. In essence, these servers consist of multiple independent multiprocessor systems.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Figure 1.7 A dual-core design with two cores placed on the same chip.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '1.3.3 Clustered Systems\\n',\n",
              " 'Another type of multiprocessor system is a clustered system, which gathers together multiple CPUs. Clustered systems differ from the multiprocessor systems described in Section 1.3.2 in that they are composed of two or more individual systems or nodes joined together. Such systems are considered loosely coupled. Each node may be a single processor system or a multicore system. We should note that the definition of clustered is not concrete; many commercial packages wrestle to define a clustered system and why one form is better than another. The generally accepted definition is that clustered computers share storage and are closely linked via a local-area network LAN (as described in Chapter 17) or a faster interconnect, such as InfiniBand.\\n',\n",
              " '    Clustering is usually used to provide high-availability service that is, service will continue even if one or more systems in the cluster fail. Generally, we obtain high availability by adding a level of redundancy in the system. A layer of cluster software runs on the cluster nodes. Each node can monitor one or more of the others (over the LAN). If the monitored machine fails, the monitoring machine can take ownership of its storage and restart the applications that were running on the failed machine. The users and clients of the applications see only a brief interruption of service.\\n',\n",
              " '   Clustering can be structured asymmetrically or symmetrically. In asym- metric clustering, one machine is in hot-standby mode while the other is running the applications. The hot-standby host machine does nothing but monitor the active server. If that server fails, the hot-standby host becomes the active server. In symmetric clustering, two or more hosts are running applications and are monitoring each other. This structure is obviously more efficient, as it uses all of the available hardware. However it does require that more than one application be available to run.\\n',\n",
              " '   Since a cluster consists of several computer systems connected via a network, clusters can also be used to provide high-performance computing environments. Such systems can supply significantly greater computational power than single-processor or even SMP systems because they can run an application concurrently on all computers in the cluster. The application must have been written specifically to take advantage of the cluster, however. This involves a technique known as parallelization, which divides a program into separate components that run in parallel on individual computers in the cluster. Typically, these applications are designed so that once each computing node in the cluster has solved its portion of the problem, the results from all the nodes are combined into a final solution.\\n',\n",
              " '   Other forms of clusters include parallel clusters and clustering over a wide-area network (WAN) (as described in Chapter 17). Parallel clusters allow multiple hosts to access the same data on shared storage. Because most operating systems lack support for simultaneous data access by multiple hosts, parallel clusters usually require the use of special versions of software and special releases of applications. For example, Oracle Real Application Cluster is a version of Oracles database that has been designed to run on a parallel cluster. Each machine runs Oracle, and a layer of software tracks access to the shared disk. Each machine has full access to all data in the database. To provide this shared access, the system must also supply access control and locking to\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'ensure that no conflicting operations occur. This function, commonly known as a distributed lock manager (DLM), is included in some cluster technology. Cluster technology is changing rapidly. Some cluster products support dozens of systems in a cluster, as well as clustered nodes that are separated by miles. Many of these improvements are made possible by storage-area networks (SANs), as described in Section 10.3.3, which allow many systems to attach to a pool of storage. If the applications and their data are stored on the SAN, then the cluster software can assign the application to run on any host that is attached to the SAN. If the host fails, then any other host can take over. In a database cluster, dozens of hosts can share the same database, greatly increasing performance and reliability. Figure 1.8 depicts the general structure\\n',\n",
              " 'of a clustered system.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'interconnect\\tinterconnect\\n',\n",
              " '\\t\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Figure 1.8 General structure of a clustered system.\\n',\n",
              " '\\n',\n",
              " '1.4 Operating-System Structure\\t19\\n',\n",
              " '0\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Max\\n',\n",
              " '\\n',\n",
              " 'Figure 1.9 Memory layout for a multiprogramming system.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '1.4 Operating-System Structure\\n',\n",
              " 'Now that we have discussed basic computer-system organization and archi- tecture, we are ready to talk about operating systems. An operating system provides the environment within which programs are executed. Internally, operating systems vary greatly in their makeup, since they are organized along many different lines. There are, however, many commonalities, which we consider in this section.\\n',\n",
              " '   One of the most important aspects of operating systems is the ability to multiprogram. A single program cannot, in general, keep either the CPU or the I/O devices busy at all times. Single users frequently have multiple programs running. Multiprogramming increases CPU utilization by organizing jobs (code and data) so that the CPU always has one to execute.\\n',\n",
              " '   The idea is as follows: The operating system keeps several jobs in memory simultaneously (Figure 1.9). Since, in general, main memory is too small to accommodate all jobs, the jobs are kept initially on the disk in the job pool. This pool consists of all processes residing on disk awaiting allocation of main memory.\\n',\n",
              " '   The set of jobs in memory can be a subset of the jobs kept in the job pool. The operating system picks and begins to execute one of the jobs in memory. Eventually, the job may have to wait for some task, such as an I/O operation, to complete. In a non-multiprogrammed system, the CPU would sit idle. In a multiprogrammed system, the operating system simply switches to, and executes, another job. When that job needs to wait, the CPU switches to another job, and so on. Eventually, the first job finishes waiting and gets the CPU back. As long as at least one job needs to execute, the CPU is never idle.\\n',\n",
              " '   This idea is common in other life situations. A lawyer does not work for only one client at a time, for example. While one case is waiting to go to trial or have papers typed, the lawyer can work on another case. If he has enough clients, the lawyer will never be idle for lack of work. (Idle lawyers tend to become politicians, so there is a certain social value in keeping lawyers busy.)\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '   Multiprogrammed systems provide an environment in which the various system resources (for example, CPU, memory, and peripheral devices) are utilized effectively, but they do not provide for user interaction with the computer system. Time sharing (or multitasking) is a logical extension of multiprogramming. In time-sharing systems, the CPU executes multiple jobs by switching among them, but the switches occur so frequently that the users can interact with each program while it is running.\\n',\n",
              " '   Time sharing requires an interactive computer system, which provides direct communication between the user and the system. The user gives instructions to the operating system or to a program directly, using a input device such as a keyboard, mouse, touch pad, or touch screen, and waits for immediate results on an output device. Accordingly, the response time should be short  typically less than one second.\\n',\n",
              " '   A time-shared operating system allows many users to share the computer simultaneously. Since each action or command in a time-shared system tends to be short, only a little CPU time is needed for each user. As the system switches rapidly from one user to the next, each user is given the impression that the entire computer system is dedicated to his use, even though it is being shared among many users.\\n',\n",
              " '   A time-shared operating system uses CPU scheduling and multiprogram- ming to provide each user with a small portion of a time-shared computer. Each user has at least one separate program in memory. A program loaded into memory and executing is called a process. When a process executes, it typically executes for only a short time before it either finishes or needs to perform I/O. I/O may be interactive; that is, output goes to a display for the user, and input comes from a user keyboard, mouse, or other device. Since interactive I/O typically runs at people speeds, it may take a long time to complete. Input, for example, may be bounded by the users typing speed; seven characters per second is fast for people but incredibly slow for computers. Rather than let the CPU sit idle as this interactive input takes place, the operating system will rapidly switch the CPU to the program of some other user.\\n',\n",
              " '   Time sharing and multiprogramming require that several jobs be kept simultaneously in memory. If several jobs are ready to be brought into memory, and if there is not enough room for all of them, then the system must choose among them. Making this decision involves job scheduling, which we discuss in Chapter 6. When the operating system selects a job from the job pool, it loads that job into memory for execution. Having several programs in memory at the same time requires some form of memory management, which we cover in Chapters 8 and 9. In addition, if several jobs are ready to run at the same time, the system must choose which job will run first. Making this decision is CPU scheduling, which is also discussed in Chapter 6. Finally, running multiple jobs concurrently requires that their ability to affect one another be limited in all phases of the operating system, including process scheduling, disk storage, and memory management. We discuss these considerations throughout the text.\\n',\n",
              " '   In a time-sharing system, the operating system must ensure reasonable response time. This goal is sometimes accomplished through swapping, whereby processes are swapped in and out of main memory to the disk. A more common method for ensuring reasonable response time is virtual memory, a technique that allows the execution of a process that is not completely in\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'memory (Chapter 9). The main advantage of the virtual-memory scheme is that it enables users to run programs that are larger than actual physical memory. Further, it abstracts main memory into a large, uniform array of storage, separating logical memory as viewed by the user from physical memory. This arrangement frees programmers from concern over memory-storage limitations.\\n',\n",
              " '   A time-sharing system must also provide a file system (Chapters 11 and 12). The file system resides on a collection of disks; hence, disk management must be provided (Chapter 10). In addition, a time-sharing system provides a mechanism for protecting resources from inappropriate use (Chapter 14). To ensure orderly execution, the system must provide mechanisms for job synchronization and communication (Chapter 5), and it may ensure that jobs do not get stuck in a deadlock, forever waiting for one another (Chapter 7).\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '1.5 Operating-System Operations\\n',\n",
              " 'As mentioned earlier, modern operating systems are interrupt driven. If there are no processes to execute, no I/O devices to service, and no users to whom to respond, an operating system will sit quietly, waiting for something to happen. Events are almost always signaled by the occurrence of an interrupt or a trap. A trap (or an exception) is a software-generated interrupt caused either by an error (for example, division by zero or invalid memory access) or by a specific request from a user program that an operating-system service be performed. The interrupt-driven nature of an operating system defines that systems general structure. For each type of interrupt, separate segments of code in the operating system determine what action should be taken. An interrupt service routine is provided to deal with the interrupt.\\n',\n",
              " '   Since the operating system and the users share the hardware and software resources of the computer system, we need to make sure that an error in a user program could cause problems only for the one program running. With sharing, many processes could be adversely affected by a bug in one program. For example, if a process gets stuck in an infinite loop, this loop could prevent the correct operation of many other processes. More subtle errors can occur in a multiprogramming system, where one erroneous program might modify another program, the data of another program, or even the operating system itself.\\n',\n",
              " '   Without protection against these sorts of errors, either the computer must execute only one process at a time or all output must be suspect. A properly designed operating system must ensure that an incorrect (or malicious) program cannot cause other programs to execute incorrectly.\\n',\n",
              " '\\n',\n",
              " '1.5.1 Dual-Mode and Multimode Operation\\n',\n",
              " 'In order to ensure the proper execution of the operating system, we must be able to distinguish between the execution of operating-system code and user- defined code. The approach taken by most computer systems is to provide hardware support that allows us to differentiate among various modes of execution.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'user process\\n',\n",
              " 'user mode (mode bit = 1)\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " ...]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Aby-H6hseAHE"
      },
      "outputs": [],
      "source": [
        "s=s[706:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxhNk9szeAHE",
        "outputId": "ccfa5e0c-eb30-4cef-a5cc-85a6ca7b7c15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20409"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "pUXGX10seAHF"
      },
      "outputs": [],
      "source": [
        "for i in range(len(s)):\n",
        "    try:\n",
        "        s.remove('\\n')\n",
        "    except:\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "for i in s:\n",
        "    if(len(i)<190):\n",
        "        s.remove(i)\n",
        "    else :\n",
        "        continue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqy0f48qeAHG",
        "outputId": "71998e4f-4562-4f03-ecc4-6be4f040e677"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3861"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO0cAAGKeAHI",
        "outputId": "9fa097cc-dde7-4a38-c1f2-964aa9c3bd73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['   Internally, operating systems vary greatly in their makeup, since they are organized along many different lines. The design of a new operating system is a major task. It is important that the goals of the system be well defined before the design begins. These goals form the basis for choices among various algorithms and strategies.\\n',\n",
              " '   Because an operating system is large and complex, it must be created piece by piece. Each of these pieces should be a well-delineated portion of the system, with carefully defined inputs, outputs, and functions.\\n',\n",
              " 'An operating system is a program that manages a computers hardware. It also provides a basis for application programs and acts as an intermediary between the computer user and the computer hardware. An amazing aspect of operating systems is how they vary in accomplishing these tasks. Mainframe operating systems are designed primarily to optimize utilization of hardware. Personal computer (PC) operating systems support complex games, business applications, and everything in between. Operating systems for mobile com- puters provide an environment in which a user can easily interface with the computer to execute programs. Thus, some operating systems are designed to be convenient, others to be efflcient, and others to be some combination of the two.\\n',\n",
              " '    Before we can explore the details of computer system operation, we need to know something about system structure. We thus discuss the basic functions of system startup, I/O, and storage early in this chapter. We also describe the basic computer architecture that makes it possible to write a functional operating system.\\n',\n",
              " '   Because an operating system is large and complex, it must be created piece by piece. Each of these pieces should be a well-delineated portion of the system, with carefully defined inputs, outputs, and functions. In this chapter, we provide a general overview of the major components of a contemporary computer system as well as the functions provided by the operating system. Additionally, we cover several other topics to help set the stage for the remainder of this text: data structures used in operating systems, computing environments, and open-source operating systems.\\n',\n",
              " 'We begin our discussion by looking at the operating systems role in the overall computer system. A computer system can be divided roughly into four components: the hardware, the operating system, the application programs, and the users (Figure 1.1).\\n',\n",
              " '    The hardware the central processing unit (CPU), the memory, and the input/output (I/O) devices provides the basic computing resources for the system. The application programs such as word processors, spreadsheets, compilers, and Web browsers define the ways in which these resources are used to solve users computing problems. The operating system controls the hardware and coordinates its use among the various application programs for the various users.\\n',\n",
              " '   We can also view a computer system as consisting of hardware, software, and data. The operating system provides the means for proper use of these resources in the operation of the computer system. An operating system is similar to a government. Like a government, it performs no useful function by itself. It simply provides an environment within which other programs can do useful work.\\n',\n",
              " 'The users view of the computer varies according to the interface being used. Most computer users sit in front of a PC, consisting of a monitor, keyboard, mouse, and system unit. Such a system is designed for one user\\n',\n",
              " 'to monopolize its resources. The goal is to maximize the work (or play) that the user is performing. In this case, the operating system is designed mostly for ease of use, with some attention paid to performance and none paid to resource utilization  how various hardware and software resources are shared. Performance is, of course, important to the user; but such systems are optimized for the single-user experience rather than the requirements of multiple users.\\n',\n",
              " '   In other cases, a user sits at a terminal connected to a mainframe or a minicomputer. Other users are accessing the same computer through other terminals. These users share resources and may exchange information. The operating system in such cases is designed to maximize resource utilization to assure that all available CPU time, memory, and I/O are used efficiently and that no individual user takes more than her fair share.\\n',\n",
              " '   In still other cases, users sit at workstations connected to networks of other workstations and servers. These users have dedicated resources at their disposal, but they also share resources such as networking and servers, including file, compute, and print servers. Therefore, their operating system is designed to compromise between individual usability and resource utilization. Recently, many varieties of mobile computers, such as smartphones and tablets, have come into fashion. Most mobile computers are standalone units for individual users. Quite often, they are connected to networks through cellular or other wireless technologies. Increasingly, these mobile devices are replacing desktop and laptop computers for people who are primarily interested in using computers for e-mail and web browsing. The user interface for mobile computers generally features a touch screen, where the user interacts with the system by pressing and swiping fingers across the screen rather than using a\\n',\n",
              " '   Some computers have little or no user view. For example, embedded computers in home devices and automobiles may have numeric keypads and may turn indicator lights on or off to show status, but they and their operating systems are designed primarily to run without user intervention.\\n',\n",
              " 'From the computers point of view, the operating system is the program most intimately involved with the hardware. In this context, we can view an operating system as a resource allocator. A computer system has many resources that may be required to solve a problem: CPU time, memory space, file-storage space, I/O devices, and so on. The operating system acts as the manager of these resources. Facing numerous and possibly conflicting requests for resources, the operating system must decide how to allocate them to specific programs and users so that it can operate the computer system efficiently and fairly. As we have seen, resource allocation is especially important where many users access the same mainframe or minicomputer.\\n',\n",
              " '   A slightly different view of an operating system emphasizes the need to control the various I/O devices and user programs. An operating system is a control program. A control program manages the execution of user programs to prevent errors and improper use of the computer. It is especially concerned with the operation and control of I/O devices.\\n',\n",
              " 'By now, you can probably see that the term operating system covers many roles and functions. That is the case, at least in part, because of the myriad designs and uses of computers. Computers are present within toasters, cars, ships, spacecraft, homes, and businesses. They are the basis for game machines, music players, cable TV tuners, and industrial control systems. Although computers have a relatively short history, they have evolved rapidly. Computing started as an experiment to determine what could be done and quickly moved to fixed-purpose systems for military uses, such as code breaking and trajectory plotting, and governmental uses, such as census calculation. Those early computers evolved into general-purpose, multifunction mainframes, and thats when operating systems were born. In the 1960s, Moores Law predicted that the number of transistors on an integrated circuit would double every eighteen months, and that prediction has held true. Computers gained in functionality and shrunk in size, leading to a vast number of uses and a vast number and variety of operating systems. (See Chapter 20 for more details on the history of operating systems.)\\n',\n",
              " '    How, then, can we define what an operating system is? In general, we have no completely adequate definition of an operating system. Operating systems exist because they offer a reasonable way to solve the problem of creating a usable computing system. The fundamental goal of computer systems is to execute user programs and to make solving user problems easier. Computer hardware is constructed toward this goal. Since bare hardware alone is not particularly easy to use, application programs are developed. These programs require certain common operations, such as those controlling the I/O devices. The common functions of controlling and allocating resources are then brought together into one piece of software: the operating system.\\n',\n",
              " '    In addition, we have no universally accepted definition of what is part of the operating system. A simple viewpoint is that it includes everything a vendor ships when you order the operating system. The features included, however, vary greatly across systems. Some systems take up less than a megabyte of space and lack even a full-screen editor, whereas others require gigabytes of space and are based entirely on graphical windowing systems. A more common definition, and the one that we usually follow, is that the operating system is the one program running at all times on the computer usually called the kernel. (Along with the kernel, there are two other types of programs: system programs, which are associated with the operating system but are not necessarily part of the kernel, and application programs, which include all programs not associated with the operation of the system.)\\n',\n",
              " '   The matter of what constitutes an operating system became increasingly important as personal computers became more widespread and operating systems grew increasingly sophisticated. In 1998, the United States Department of Justice filed suit against Microsoft, in essence claiming that Microsoft included too much functionality in its operating systems and thus prevented application vendors from competing. (For example, a Web browser was an integral part of the operating systems.) As a result, Microsoft was found guilty of using its operating-system monopoly to limit competition.\\n',\n",
              " 'is increasing. Mobile operating systems often include not only a core kernel but also middleware  a set of software frameworks that provide additional services to application developers. For example, each of the two most promi- nent mobile operating systems Apples iOS and Googles Android features a core kernel along with middleware that supports databases, multimedia, and graphics (to name a only few).\\n',\n",
              " 'Before we can explore the details of how computer systems operate, we need general knowledge of the structure of a computer system. In this section, we look at several parts of this structure. The section is mostly concerned with computer-system organization, so you can skim or skip it if you already understand the concepts.\\n',\n",
              " 'A modern general-purpose computer system consists of one or more CPUs and a number of device controllers connected through a common bus that provides access to shared memory (Figure 1.2). Each device controller is in charge of a specific type of device (for example, disk drives, audio devices, or video displays). The CPU and the device controllers can execute in parallel, competing for memory cycles. To ensure orderly access to the shared memory, a memory controller synchronizes access to the memory.\\n',\n",
              " '   For a computer to start running  for instance, when it is powered up or rebooted  it needs to have an initial program to run. This initial program, or bootstrap program, tends to be simple. Typically, it is stored within the computer hardware in read-only memory (ROM) or electrically erasable programmable read-only memory (EEPROM), known by the general term firmware. It initializes all aspects of the system, from CPU registers to device controllers to memory contents. The bootstrap program must know how to load the operating system and how to start executing that system. To accomplish\\n',\n",
              " '   Once the kernel is loaded and executing, it can start providing services to the system and its users. Some services are provided outside of the kernel, by system programs that are loaded into memory at boot time to become system processes, or system daemons that run the entire time the kernel is running. On UNIX, the first system process is init, and it starts many other daemons. Once this phase is complete, the system is fully booted, and the system waits for some event to occur.\\n',\n",
              " '   The occurrence of an event is usually signaled by an interrupt from either the hardware or the software. Hardware may trigger an interrupt at any time by sending a signal to the CPU, usually by way of the system bus. Software may trigger an interrupt by executing a special operation called a system call (also called a monitor call).\\n',\n",
              " '   When the CPU is interrupted, it stops what it is doing and immediately transfers execution to a fixed location. The fixed location usually contains the starting address where the service routine for the interrupt is located. The interrupt service routine executes; on completion, the CPU resumes the interrupted computation. A timeline of this operation is shown in Figure 1.3.\\n',\n",
              " '    Interrupts are an important part of a computer architecture. Each computer design has its own interrupt mechanism, but several functions are common. The interrupt must transfer control to the appropriate interrupt service routine. The straightforward method for handling this transfer would be to invoke a generic routine to examine the interrupt information. The routine, in turn, would call the interrupt-specific handler. However, interrupts must be handled quickly. Since only a predefined number of interrupts is possible, a table of pointers to interrupt routines can be used instead to provide the necessary speed. The interrupt routine is called indirectly through the table, with no intermediate routine needed. Generally, the table of pointers is stored in low memory (the first hundred or so locations). These locations hold the addresses of the interrupt service routines for the various devices. This array, or interrupt vector, of addresses is then indexed by a unique device number, given with the interrupt request, to provide the address of the interrupt service routine for\\n',\n",
              " '   The interrupt architecture must also save the address of the interrupted instruction. Many old designs simply stored the interrupt address in a fixed location or in a location indexed by the device number. More recent architectures store the return address on the system stack. If the interrupt routine needs to modify the processor state for instance, by modifying register values it must explicitly save the current state and then restore that state before returning. After the interrupt is serviced, the saved return address is loaded into the program counter, and the interrupted computation resumes as though the interrupt had not occurred.\\n',\n",
              " 'The CPU can load instructions only from memory, so any programs to run must be stored there. General-purpose computers run most of their programs from rewritable memory, called main memory (also called random-access memory, or RAM). Main memory commonly is implemented in a semiconductor technology called dynamic random-access memory (DRAM).\\n',\n",
              " '    Computers use other forms of memory as well. We have already mentioned read-only memory, ROM) and electrically erasable programmable read-only memory, EEPROM). Because ROM cannot be changed, only static programs, such as the bootstrap program described earlier, are stored there. The immutability of ROM is of use in game cartridges. EEPROM can be changed but cannot be changed frequently and so contains mostly static programs. For example, smartphones have EEPROM to store their factory-installed programs.\\n',\n",
              " '   All forms of memory provide an array of bytes. Each byte has its own address. Interaction is achieved through a sequence of load or store instructions to specific memory addresses. The load instruction moves a byte or word from main memory to an internal register within the CPU, whereas the store instruction moves the content of a register to main memory. Aside from explicit loads and stores, the CPU automatically loads instructions from main memory for execution.\\n',\n",
              " '    A typical instruction execution cycle, as executed on a system with a von Neumann architecture, first fetches an instruction from memory and stores that instruction in the instruction register. The instruction is then decoded and may cause operands to be fetched from memory and stored in some internal register. After the instruction on the operands has been executed, the result may be stored back in memory. Notice that the memory unit sees only a stream of memory addresses. It does not know how they are generated (by the instruction counter, indexing, indirection, literal addresses, or some other means) or what they are for (instructions or data). Accordingly, we can ignore how a memory address is generated by a program. We are interested only in the sequence of memory addresses generated by the running program.\\n',\n",
              " 'Thus, most computer systems provide secondary storage as an extension of main memory. The main requirement for secondary storage is that it be able to hold large quantities of data permanently.\\n',\n",
              " '   The most common secondary-storage device is a magnetic disk, which provides storage for both programs and data. Most programs (system and application) are stored on a disk until they are loaded into memory. Many programs then use the disk as both the source and the destination of their processing. Hence, the proper management of disk storage is of central importance to a computer system, as we discuss in Chapter 10.\\n',\n",
              " '   In a larger sense, however, the storage structure that we have described consisting of registers, main memory, and magnetic disks  is only one of many possible storage systems. Others include cache memory, CD-ROM, magnetic tapes, and so on. Each storage system provides the basic functions of storing a datum and holding that datum until it is retrieved at a later time. The main differences among the various storage systems lie in speed, cost, size, and volatility.\\n',\n",
              " '    The wide variety of storage systems can be organized in a hierarchy (Figure 1.4) according to speed and cost. The higher levels are expensive, but they are fast. As we move down the hierarchy, the cost per bit generally decreases, whereas the access time generally increases. This trade-off is reasonable; if a given storage system were both faster and less expensive than another other properties being the same  then there would be no reason to use the slower, more expensive memory. In fact, many early storage devices, including paper\\n',\n",
              " 'tape and core memories, are relegated to museums now that magnetic tape and semiconductor memory have become faster and cheaper. The top four levels of memory in Figure 1.4 may be constructed using semiconductor memory.\\n',\n",
              " '   In addition to differing in speed and cost, the various storage systems are either volatile or nonvolatile. As mentioned earlier, volatile storage loses its contents when the power to the device is removed. In the absence of expensive battery and generator backup systems, data must be written to nonvolatile storage for safekeeping. In the hierarchy shown in Figure 1.4, the storage systems above the solid-state disk are volatile, whereas those including the solid-state disk and below are nonvolatile.\\n',\n",
              " '   Solid-state disks have several variants but in general are faster than magnetic disks and are nonvolatile. One type of solid-state disk stores data in a large DRAM array during normal operation but also contains a hidden magnetic hard disk and a battery for backup power. If external power is interrupted, this solid-state disks controller copies the data from RAM to the magnetic disk. When external power is restored, the controller copies the data back into RAM. Another form of solid-state disk is flash memory, which is popular in cameras and personal digital assistants (PDAs), in robots, and increasingly for storage on general-purpose computers. Flash memory is slower than DRAM but needs no power to retain its contents. Another form of nonvolatile storage is NVRAM, which is DRAM with battery backup power. This memory can be as fast as DRAM and (as long as the battery lasts) is nonvolatile.\\n',\n",
              " '   The design of a complete memory system must balance all the factors just discussed: it must use only as much expensive memory as necessary while providing as much inexpensive, nonvolatile memory as possible. Caches can\\n',\n",
              " 'Storage is only one of many types of I/O devices within a computer. A large portion of operating system code is dedicated to managing I/O, both because of its importance to the reliability and performance of a system and because of the varying nature of the devices. Next, we provide an overview of I/O.\\n',\n",
              " '   A general-purpose computer system consists of CPUs and multiple device controllers that are connected through a common bus. Each device controller is in charge of a specific type of device. Depending on the controller, more than one device may be attached. For instance, seven or more devices can be attached to the small computer-systems interface (SCSI) controller. A device controller maintains some local buffer storage and a set of special-purpose registers. The device controller is responsible for moving the data between the peripheral devices that it controls and its local buffer storage. Typically, operating systems have a device driver for each device controller. This device driver understands the device controller and provides the rest of the operating system with a uniform interface to the device.\\n',\n",
              " '   To start an I/O operation, the device driver loads the appropriate registers within the device controller. The device controller, in turn, examines the contents of these registers to determine what action to take (such as read a character from the keyboard). The controller starts the transfer of data from the device to its local buffer. Once the transfer of data is complete, the device controller informs the device driver via an interrupt that it has finished its operation. The device driver then returns control to the operating system, possibly returning the data or a pointer to the data if the operation was a read. For other operations, the device driver returns status information.\\n',\n",
              " '   This form of interrupt-driven I/O is fine for moving small amounts of data but can produce high overhead when used for bulk data movement such as disk I/O. To solve this problem, direct memory access (DMA) is used. After setting up buffers, pointers, and counters for the I/O device, the device controller transfers an entire block of data directly to or from its own buffer storage to memory, with no intervention by the CPU. Only one interrupt is generated per block, to tell the device driver that the operation has completed, rather than the one interrupt per byte generated for low-speed devices. While the device controller is performing these operations, the CPU is available to accomplish other work.\\n',\n",
              " '   Some high-end systems use switch rather than bus architecture. On these systems, multiple components can talk to other components concurrently, rather than competing for cycles on a shared bus. In this case, DMA is even more effective. Figure 1.5 shows the interplay of all components of a computer system.\\n',\n",
              " 'Until recently, most computer systems used a single processor. On a single- processor system, there is one main CPU capable of executing a general-purpose instruction set, including instructions from user processes. Almost all single- processor systems have other special-purpose processors as well. They may come in the form of device-specific processors, such as disk, keyboard, and graphics controllers; or, on mainframes, they may come in the form of more general-purpose processors, such as I/O processors that move data rapidly among the components of the system.\\n',\n",
              " '   All of these special-purpose processors run a limited instruction set and do not run user processes. Sometimes, they are managed by the operating system, in that the operating system sends them information about their next task and monitors their status. For example, a disk-controller microprocessor receives a sequence of requests from the main CPU and implements its own disk queue and scheduling algorithm. This arrangement relieves the main CPU of the overhead of disk scheduling. PCs contain a microprocessor in the keyboard to convert the keystrokes into codes to be sent to the CPU. In other systems or circumstances, special-purpose processors are low-level components built into the hardware. The operating system cannot communicate with these processors; they do their jobs autonomously. The use of special-purpose microprocessors is common and does not turn a single-processor system into\\n',\n",
              " 'Within the past several years, multiprocessor systems (also known as parallel systems or multicore systems) have begun to dominate the landscape of computing. Such systems have two or more processors in close communication, sharing the computer bus and sometimes the clock, memory, and peripheral devices. Multiprocessor systems first appeared prominently appeared in servers and have since migrated to desktop and laptop systems. Recently, multiple processors have appeared on mobile devices such as smartphones and tablet computers.\\n',\n",
              " '1. Increased throughput. By increasing the number of processors, we expect to get more work done in less time. The speed-up ratio with N processors is not N, however; rather, it is less than N. When multiple processors cooperate on a task, a certain amount of overhead is incurred in keeping all the parts working correctly. This overhead, plus contention for shared resources, lowers the expected gain from additional processors. Similarly, N programmers working closely together do not produce N times the amount of work a single programmer would produce.\\n',\n",
              " '2. Economy of scale. Multiprocessor systems can cost less than equivalent multiple single-processor systems, because they can share peripherals, mass storage, and power supplies. If several programs operate on the same set of data, it is cheaper to store those data on one disk and to have all the processors share them than to have many computers with local disks and many copies of the data.\\n',\n",
              " '3. Increased reliability. If functions can be distributed properly among several processors, then the failure of one processor will not halt the system, only slow it down. If we have ten processors and one fails, then each of the remaining nine processors can pick up a share of the work of the failed processor. Thus, the entire system runs only 10 percent slower, rather than failing altogether.\\n',\n",
              " '   Increased reliability of a computer system is crucial in many applications. The ability to continue providing service proportional to the level of surviving hardware is called graceful degradation. Some systems go beyond graceful degradation and are called fault tolerant, because they can suffer a failure of any single component and still continue operation. Fault tolerance requires a mechanism to allow the failure to be detected, diagnosed, and, if possible, corrected. The HP NonStop (formerly Tandem) system uses both hardware and software duplication to ensure continued operation despite faults. The system consists of multiple pairs of CPUs, working in lockstep. Both processors in the pair execute each instruction and compare the results. If the results differ, then one CPU of the pair is at fault, and both are halted. The process that was being executed is then moved to another pair of CPUs, and the instruction that failed\\n',\n",
              " '   The multiple-processor systems in use today are of two  types. Some systems use asymmetric multiprocessing, in which each processor is assigned a specific task. A boss processor controls the system; the other processors either look to the boss for instruction or have predefined tasks. This scheme defines a boss worker relationship. The boss processor schedules and allocates work to the worker processors.\\n',\n",
              " '   The most common systems use symmetric multiprocessing (SMP), in which each processor performs all tasks within the operating system. SMP means that all processors are peers; no boss worker relationship exists between processors. Figure 1.6 illustrates a typical SMP architecture. Notice that each processor has its own set of registers, as well as a private or local\\n',\n",
              " ' cache. However, all processors share physical memory. An example of an SMP system is AIX, a commercial version of UNIX designed by IBM. An AIX system can be configured to employ dozens of processors. The benefit of this model is that many processes can run simultaneously N processes can run if there are N CPUs without causing performance to deteriorate significantly. However, we must carefully control I/O to ensure that the data reach the appropriate processor. Also, since the CPUs are separate, one may be sitting idle while another is overloaded, resulting in inefficiencies. These inefficiencies can be avoided if the processors share certain data structures. A multiprocessor system of this form will  allow  processes and  resources such as memory to be shared dynamically among the various processors and can lower the variance among the processors. Such a system must be written carefully, as we shall see in Chapter 5. Virtually all modern operating systems including Windows, Mac OS X, and Linux now provide support for SMP.\\n',\n",
              " '   The difference between symmetric and asymmetric multiprocessing may result from either hardware or software. Special hardware can differentiate the multiple processors, or the software can be written to allow only one boss and multiple workers. For instance, Sun Microsystems operating system SunOS Version 4 provided asymmetric multiprocessing, whereas Version 5 (Solaris) is symmetric on the same hardware.\\n',\n",
              " 'of memory addressable in the system. Either way, multiprocessing can cause a system to change its memory access model from uniform memory access (UMA) to non-uniform memory access (NUMA). UMA is defined as the situation in which access to any RAM from any CPU takes the same amount of time. With NUMA, some parts of memory may take longer to access than other parts, creating a performance penalty. Operating systems can minimize the NUMA penalty through resource management, as discussed in Section 9.5.4.\\n',\n",
              " '   A recent trend in CPU design is to include multiple computing cores on a single chip. Such multiprocessor systems are termed multicore. They can be more efficient than multiple chips with single cores because on-chip communication is faster than between-chip communication. In addition, one chip with multiple cores uses significantly less power than multiple single-core chips.\\n',\n",
              " '1.3.3. In our coverage of multiprocessor systems throughout this text, unless we state otherwise, we generally use the more contemporary term multicore, which excludes some multiprocessor systems.\\n',\n",
              " '   In Figure 1.7, we show a dual-core design with two cores on the same chip. In this design, each core has its own register set as well as its own local cache. Other designs might use a shared cache or a combination of local and shared caches. Aside from architectural considerations, such as cache, memory, and bus contention, these multicore CPUs appear to the operating system as N standard processors. This characteristic puts pressure on operating system designers and application programmers to make use of those processing cores.\\n',\n",
              " '    Finally, blade servers are a relatively recent development in which multiple processor boards, I/O boards, and networking boards are placed in the same chassis. The difference between these and traditional multiprocessor systems is that each blade-processor board boots independently and runs its own operating system. Some blade-server boards are multiprocessor as well, which blurs the lines between types of computers. In essence, these servers consist of multiple independent multiprocessor systems.\\n',\n",
              " 'Another type of multiprocessor system is a clustered system, which gathers together multiple CPUs. Clustered systems differ from the multiprocessor systems described in Section 1.3.2 in that they are composed of two or more individual systems or nodes joined together. Such systems are considered loosely coupled. Each node may be a single processor system or a multicore system. We should note that the definition of clustered is not concrete; many commercial packages wrestle to define a clustered system and why one form is better than another. The generally accepted definition is that clustered computers share storage and are closely linked via a local-area network LAN (as described in Chapter 17) or a faster interconnect, such as InfiniBand.\\n',\n",
              " '    Clustering is usually used to provide high-availability service that is, service will continue even if one or more systems in the cluster fail. Generally, we obtain high availability by adding a level of redundancy in the system. A layer of cluster software runs on the cluster nodes. Each node can monitor one or more of the others (over the LAN). If the monitored machine fails, the monitoring machine can take ownership of its storage and restart the applications that were running on the failed machine. The users and clients of the applications see only a brief interruption of service.\\n',\n",
              " '   Clustering can be structured asymmetrically or symmetrically. In asym- metric clustering, one machine is in hot-standby mode while the other is running the applications. The hot-standby host machine does nothing but monitor the active server. If that server fails, the hot-standby host becomes the active server. In symmetric clustering, two or more hosts are running applications and are monitoring each other. This structure is obviously more efficient, as it uses all of the available hardware. However it does require that more than one application be available to run.\\n',\n",
              " '   Since a cluster consists of several computer systems connected via a network, clusters can also be used to provide high-performance computing environments. Such systems can supply significantly greater computational power than single-processor or even SMP systems because they can run an application concurrently on all computers in the cluster. The application must have been written specifically to take advantage of the cluster, however. This involves a technique known as parallelization, which divides a program into separate components that run in parallel on individual computers in the cluster. Typically, these applications are designed so that once each computing node in the cluster has solved its portion of the problem, the results from all the nodes are combined into a final solution.\\n',\n",
              " '   Other forms of clusters include parallel clusters and clustering over a wide-area network (WAN) (as described in Chapter 17). Parallel clusters allow multiple hosts to access the same data on shared storage. Because most operating systems lack support for simultaneous data access by multiple hosts, parallel clusters usually require the use of special versions of software and special releases of applications. For example, Oracle Real Application Cluster is a version of Oracles database that has been designed to run on a parallel cluster. Each machine runs Oracle, and a layer of software tracks access to the shared disk. Each machine has full access to all data in the database. To provide this shared access, the system must also supply access control and locking to\\n',\n",
              " 'ensure that no conflicting operations occur. This function, commonly known as a distributed lock manager (DLM), is included in some cluster technology. Cluster technology is changing rapidly. Some cluster products support dozens of systems in a cluster, as well as clustered nodes that are separated by miles. Many of these improvements are made possible by storage-area networks (SANs), as described in Section 10.3.3, which allow many systems to attach to a pool of storage. If the applications and their data are stored on the SAN, then the cluster software can assign the application to run on any host that is attached to the SAN. If the host fails, then any other host can take over. In a database cluster, dozens of hosts can share the same database, greatly increasing performance and reliability. Figure 1.8 depicts the general structure\\n',\n",
              " 'Now that we have discussed basic computer-system organization and archi- tecture, we are ready to talk about operating systems. An operating system provides the environment within which programs are executed. Internally, operating systems vary greatly in their makeup, since they are organized along many different lines. There are, however, many commonalities, which we consider in this section.\\n',\n",
              " '   One of the most important aspects of operating systems is the ability to multiprogram. A single program cannot, in general, keep either the CPU or the I/O devices busy at all times. Single users frequently have multiple programs running. Multiprogramming increases CPU utilization by organizing jobs (code and data) so that the CPU always has one to execute.\\n',\n",
              " '   The idea is as follows: The operating system keeps several jobs in memory simultaneously (Figure 1.9). Since, in general, main memory is too small to accommodate all jobs, the jobs are kept initially on the disk in the job pool. This pool consists of all processes residing on disk awaiting allocation of main memory.\\n',\n",
              " '   The set of jobs in memory can be a subset of the jobs kept in the job pool. The operating system picks and begins to execute one of the jobs in memory. Eventually, the job may have to wait for some task, such as an I/O operation, to complete. In a non-multiprogrammed system, the CPU would sit idle. In a multiprogrammed system, the operating system simply switches to, and executes, another job. When that job needs to wait, the CPU switches to another job, and so on. Eventually, the first job finishes waiting and gets the CPU back. As long as at least one job needs to execute, the CPU is never idle.\\n',\n",
              " '   This idea is common in other life situations. A lawyer does not work for only one client at a time, for example. While one case is waiting to go to trial or have papers typed, the lawyer can work on another case. If he has enough clients, the lawyer will never be idle for lack of work. (Idle lawyers tend to become politicians, so there is a certain social value in keeping lawyers busy.)\\n',\n",
              " '   Multiprogrammed systems provide an environment in which the various system resources (for example, CPU, memory, and peripheral devices) are utilized effectively, but they do not provide for user interaction with the computer system. Time sharing (or multitasking) is a logical extension of multiprogramming. In time-sharing systems, the CPU executes multiple jobs by switching among them, but the switches occur so frequently that the users can interact with each program while it is running.\\n',\n",
              " '   Time sharing requires an interactive computer system, which provides direct communication between the user and the system. The user gives instructions to the operating system or to a program directly, using a input device such as a keyboard, mouse, touch pad, or touch screen, and waits for immediate results on an output device. Accordingly, the response time should be short  typically less than one second.\\n',\n",
              " '   A time-shared operating system allows many users to share the computer simultaneously. Since each action or command in a time-shared system tends to be short, only a little CPU time is needed for each user. As the system switches rapidly from one user to the next, each user is given the impression that the entire computer system is dedicated to his use, even though it is being shared among many users.\\n',\n",
              " '   A time-shared operating system uses CPU scheduling and multiprogram- ming to provide each user with a small portion of a time-shared computer. Each user has at least one separate program in memory. A program loaded into memory and executing is called a process. When a process executes, it typically executes for only a short time before it either finishes or needs to perform I/O. I/O may be interactive; that is, output goes to a display for the user, and input comes from a user keyboard, mouse, or other device. Since interactive I/O typically runs at people speeds, it may take a long time to complete. Input, for example, may be bounded by the users typing speed; seven characters per second is fast for people but incredibly slow for computers. Rather than let the CPU sit idle as this interactive input takes place, the operating system will rapidly switch the CPU to the program of some other user.\\n',\n",
              " '   Time sharing and multiprogramming require that several jobs be kept simultaneously in memory. If several jobs are ready to be brought into memory, and if there is not enough room for all of them, then the system must choose among them. Making this decision involves job scheduling, which we discuss in Chapter 6. When the operating system selects a job from the job pool, it loads that job into memory for execution. Having several programs in memory at the same time requires some form of memory management, which we cover in Chapters 8 and 9. In addition, if several jobs are ready to run at the same time, the system must choose which job will run first. Making this decision is CPU scheduling, which is also discussed in Chapter 6. Finally, running multiple jobs concurrently requires that their ability to affect one another be limited in all phases of the operating system, including process scheduling, disk storage, and memory management. We discuss these considerations throughout the text.\\n',\n",
              " '   In a time-sharing system, the operating system must ensure reasonable response time. This goal is sometimes accomplished through swapping, whereby processes are swapped in and out of main memory to the disk. A more common method for ensuring reasonable response time is virtual memory, a technique that allows the execution of a process that is not completely in\\n',\n",
              " 'memory (Chapter 9). The main advantage of the virtual-memory scheme is that it enables users to run programs that are larger than actual physical memory. Further, it abstracts main memory into a large, uniform array of storage, separating logical memory as viewed by the user from physical memory. This arrangement frees programmers from concern over memory-storage limitations.\\n',\n",
              " '   A time-sharing system must also provide a file system (Chapters 11 and 12). The file system resides on a collection of disks; hence, disk management must be provided (Chapter 10). In addition, a time-sharing system provides a mechanism for protecting resources from inappropriate use (Chapter 14). To ensure orderly execution, the system must provide mechanisms for job synchronization and communication (Chapter 5), and it may ensure that jobs do not get stuck in a deadlock, forever waiting for one another (Chapter 7).\\n',\n",
              " 'As mentioned earlier, modern operating systems are interrupt driven. If there are no processes to execute, no I/O devices to service, and no users to whom to respond, an operating system will sit quietly, waiting for something to happen. Events are almost always signaled by the occurrence of an interrupt or a trap. A trap (or an exception) is a software-generated interrupt caused either by an error (for example, division by zero or invalid memory access) or by a specific request from a user program that an operating-system service be performed. The interrupt-driven nature of an operating system defines that systems general structure. For each type of interrupt, separate segments of code in the operating system determine what action should be taken. An interrupt service routine is provided to deal with the interrupt.\\n',\n",
              " '   Since the operating system and the users share the hardware and software resources of the computer system, we need to make sure that an error in a user program could cause problems only for the one program running. With sharing, many processes could be adversely affected by a bug in one program. For example, if a process gets stuck in an infinite loop, this loop could prevent the correct operation of many other processes. More subtle errors can occur in a multiprogramming system, where one erroneous program might modify another program, the data of another program, or even the operating system itself.\\n',\n",
              " '   Without protection against these sorts of errors, either the computer must execute only one process at a time or all output must be suspect. A properly designed operating system must ensure that an incorrect (or malicious) program cannot cause other programs to execute incorrectly.\\n',\n",
              " 'In order to ensure the proper execution of the operating system, we must be able to distinguish between the execution of operating-system code and user- defined code. The approach taken by most computer systems is to provide hardware support that allows us to differentiate among various modes of execution.\\n',\n",
              " '   At the very least, we need two separate modes of operation: user mode and kernel mode (also called supervisor mode, system mode, or privileged mode). A bit, called the mode bit, is added to the hardware of the computer to indicate the current mode: kernel (0) or user (1). With the mode bit, we can distinguish between a task that is executed on behalf of the operating system and one that is executed on behalf of the user. When the computer system is executing on behalf of a user application, the system is in user mode. However, when a user application requests a service from the operating system (via a system call), the system must transition from user to kernel mode to fulfill the request. This is shown in Figure 1.10. As we shall see, this architectural enhancement is useful for many other aspects of system operation as well.\\n',\n",
              " '   At system boot time, the hardware starts in kernel mode. The operating system is then loaded and starts user applications in user mode. Whenever a trap or interrupt occurs, the hardware switches from user mode to kernel mode (that is, changes the state of the mode bit to 0). Thus, whenever the operating system gains control of the computer, it is in kernel mode. The system always switches to user mode (by setting the mode bit to 1) before passing control to a user program.\\n',\n",
              " '   The dual mode of operation provides us with the means for protecting the operating system from errant users  and errant users from one another. We accomplish this protection by designating some of the machine instructions that may cause harm as privileged instructions. The hardware allows privileged instructions to be executed only in kernel mode. If an attempt is made to execute a privileged instruction in user mode, the hardware does not execute the instruction but rather treats it as illegal and traps it to the operating system. The instruction to switch to kernel mode is an example of a privileged instruction. Some other examples include I/O control, timer management, and interrupt management. As we shall see throughout the text, there are many\\n',\n",
              " '   The concept of modes can be extended beyond two modes (in which case the CPU uses more than one bit to set and test the mode). CPUs that support virtualization (Section 16.1) frequently have a separate mode to indicate when the virtual machine manager (VMM)  and the virtualization management software is in control of the system. In this mode, the VMM has more privileges than user processes but fewer than the kernel. It needs that level of privilege so it can create and manage virtual machines, changing the CPU state to do so. Sometimes, too, different modes are used by various kernel\\n',\n",
              " 'components. We should note that, as an alternative to modes, the CPU designer may use other methods to differentiate operational privileges. The Intel 64 family of CPUs supports four privilege levels, for example, and supports virtualization but does not have a separate mode for virtualization.\\n',\n",
              " '    We can now see the life cycle of instruction execution in a computer system. Initial control resides in the operating system, where instructions are executed in kernel mode. When control is given to a user application, the mode is set to user mode. Eventually, control is switched back to the operating system via an interrupt, a trap, or a system call.\\n',\n",
              " '   System calls provide the means for a user program to ask the operating system to perform tasks reserved for the operating system on the user programs behalf. A system call is invoked in a variety of ways, depending on the functionality provided by the underlying processor. In all forms, it is the method used by a process to request action by the operating system. A system call usually takes the form of a trap to a specific location in the interrupt vector. This trap can be executed by a generic trap instruction, although some systems (such as MIPS) have a specific syscall instruction to invoke a system call.\\n',\n",
              " '   When a system call is executed, it is typically treated by the hardware as a software interrupt. Control passes through the interrupt vector to a service routine in the operating system, and the mode bit is set to kernel mode. The system-call service routine is a part of the operating system. The kernel examines the interrupting instruction to determine what system call has occurred; a parameter indicates what type of service the user program is requesting. Additional information needed for the request may be passed in registers, on the stack, or in memory (with pointers to the memory locations passed in registers). The kernel verifies that the parameters are correct and legal, executes the request, and returns control to the instruction following the system call. We describe system calls more fully in Section 2.3.\\n',\n",
              " '   The lack of a hardware-supported dual mode can cause serious shortcom- ings in an operating system. For instance, MS-DOS was written for the Intel 8088 architecture, which has no mode bit and therefore no dual mode. A user program running awry can wipe out the operating system by writing over it with data; and multiple programs are able to write to a device at the same time, with potentially disastrous results. Modern versions of the Intel CPU do provide dual-mode operation. Accordingly, most contemporary operating systems  such as Microsoft Windows 7, as well as Unix and Linux  take advantage of this dual-mode feature and provide greater protection for the operating system.\\n',\n",
              " '   Once hardware protection is in place, it detects errors that violate modes. These errors are normally handled by the operating system. If a user program fails in some way such as by making an attempt either to execute an illegal instruction or to access memory that is not in the users address space  then the hardware traps to the operating system. The trap transfers control through the interrupt vector to the operating system, just as an interrupt does. When a program error occurs, the operating system must terminate the program abnormally. This situation is handled by the same code as a user-requested abnormal termination. An appropriate error message is given, and the memory of the program may be dumped. The memory dump is usually written to a file so that the user or programmer can examine it and perhaps correct it and restart the program.\\n',\n",
              " 'We must ensure that the operating system maintains control over the CPU. We cannot allow a user program to get stuck in an infinite loop or to fail to call system services and never return control to the operating system. To accomplish this goal, we can use a timer. A timer can be set to interrupt the computer after a specified period. The period may be fixed (for example, 1/60 second) or variable (for example, from 1 millisecond to 1 second). A variable timer is generally implemented by a fixed-rate clock and a counter. The operating system sets the counter. Every time the clock ticks, the counter is decremented. When the counter reaches 0, an interrupt occurs. For instance, a 10-bit counter with a 1-millisecond clock allows interrupts at intervals from 1 millisecond to 1,024 milliseconds, in steps of 1 millisecond.\\n',\n",
              " '   Before turning over control to the user, the operating system ensures that the timer is set to interrupt. If the timer interrupts, control transfers automatically to the operating system, which may treat the interrupt as a fatal error or may give the program more time. Clearly, instructions that modify the content of the timer are privileged.\\n',\n",
              " '   We can use the timer to prevent a user program from running too long. A simple technique is to initialize a counter with the amount of time that a program is allowed to run. A program with a 7-minute time limit, for example, would have its counter initialized to 420. Every second, the timer interrupts, and the counter is decremented by 1. As long as the counter is positive, control is returned to the user program. When the counter becomes negative, the operating system terminates the program for exceeding the assigned time limit.\\n',\n",
              " 'A program does nothing unless its instructions are executed by a CPU. A program in execution, as mentioned, is a process. A time-shared user program such as a compiler is a process. A word-processing program being run by an individual user on a PC is a process. A system task, such as sending output to a printer, can also be a process (or at least part of one). For now, you can consider a process to be a job or a time-shared program, but later you will learn that the concept is more general. As we shall see in Chapter 3, it is possible to provide system calls that allow processes to create subprocesses to execute concurrently.\\n',\n",
              " '    A process needs certain resources including CPU time, memory, files, and I/O devices to accomplish its task. These resources are either given to the process when it is created or allocated to it while it is running. In addition to the various physical and logical resources that a process obtains when it is created, various initialization data (input) may be passed along. For example, consider a process whose function is to display the status of a file on the screen of a terminal. The process will be given the name of the file as an input and will execute the appropriate instructions and system calls to obtain and display the desired information on the terminal. When the process terminates, the operating system will reclaim any reusable resources.\\n',\n",
              " 'is an active entity. A single-threaded process has one program counter specifying the next instruction to execute. (Threads are covered in Chapter 4.) The execution of such a process must be sequential. The CPU executes one instruction of the process after another, until the process completes. Further, at any time, one instruction at most is executed on behalf of the process. Thus, although two processes may be associated with the same program, they are nevertheless considered two separate execution sequences. A multithreaded process has multiple program counters, each pointing to the next instruction to execute for a given thread.\\n',\n",
              " '   A process is the unit of work in a system. A system consists of a collection of processes, some of which are operating-system processes (those that execute system code) and the rest of which are user processes (those that execute user code). All these processes can potentially execute concurrently by multiplexing on a single CPU, for example.\\n',\n",
              " 'As we discussed in Section 1.2.2, the main memory is central to the operation of a modern computer system. Main memory is a large array of bytes, ranging in size from hundreds of thousands to billions. Each byte has its own address. Main memory is a repository of quickly accessible data shared by the CPU and I/O devices. The central processor reads instructions from main memory during the instruction-fetch cycle and both reads and writes data from main memory during the data-fetch cycle (on a von Neumann architecture). As noted earlier, the main memory is generally the only large storage device that the CPU is able to address and access directly. For example, for the CPU to process data from disk, those data must first be transferred to main memory by CPU-generated I/O calls. In the same way, instructions must be in memory for the CPU to execute them.\\n',\n",
              " '    For a program to be executed, it must be mapped to absolute addresses and loaded into memory. As the program executes, it accesses program instructions and data from memory by generating these absolute addresses. Eventually, the program terminates, its memory space is declared available, and the next program can be loaded and executed.\\n',\n",
              " '    To improve both the utilization of the CPU and the speed of the computers response to its users, general-purpose computers must keep several programs in memory, creating a need for memory management. Many different memory-\\n',\n",
              " 'management schemes are used. These schemes reflect various approaches, and the effectiveness of any given algorithm depends on the situation. In selecting a memory-management scheme for a specific system, we must take into account many factors  especially the hardware design of the system. Each algorithm requires its own hardware support.\\n',\n",
              " 'To make the computer system convenient for users, the operating system provides a uniform, logical view of information storage. The operating system abstracts from the physical properties of its storage devices to define a logical storage unit, the file. The operating system maps files onto physical media and accesses these files via the storage devices.\\n',\n",
              " 'File management is one of the most visible components of an operating system. Computers can store information on several different types of physical media. Magnetic disk, optical disk, and magnetic tape are the most common. Each of these media has its own characteristics and physical organization. Each medium is controlled by a device, such as a disk drive or tape drive, that also has its own unique characteristics. These properties include access speed, capacity, data-transfer rate, and access method (sequential or random).\\n',\n",
              " '    A file is a collection of related information defined by its creator. Commonly, files represent programs (both source and object forms) and data. Data files may be numeric, alphabetic, alphanumeric, or binary. Files may be free-form (for example, text files), or they may be formatted rigidly (for example, fixed fields). Clearly, the concept of a file is an extremely general one.\\n',\n",
              " '    The operating system implements the abstract concept of a file by managing mass-storage media, such as tapes and disks, and the devices that control them. In addition, files are normally organized into directories to make them easier to use. Finally, when multiple users have access to files, it may be desirable to control which user may access a file and how that user may access it (for example, read, write, append).\\n',\n",
              " 'As we have already seen, because main memory is too small to accommodate all data and programs, and because the data that it holds are lost when power is lost, the computer system must provide secondary storage to back up main memory. Most modern computer systems use disks as the principal on-line storage medium for both programs and data. Most programs including compilers, assemblers, word processors, editors, and formatters are stored on a disk until loaded into memory. They then use the disk as both the source and destination of their processing. Hence, the proper management of disk storage is of central importance to a computer system. The operating system is responsible for the following activities in connection with disk management:\\n',\n",
              " 'Because secondary storage is used frequently, it must be used efficiently. The entire speed of operation of a computer may hinge on the speeds of the disk subsystem and the algorithms that manipulate that subsystem.\\n',\n",
              " '   There are, however, many uses for storage that is slower and lower in cost (and sometimes of higher capacity) than secondary storage. Backups of disk data, storage of seldom-used data, and long-term archival storage are some examples. Magnetic tape drives and their tapes and CD and DVD drives and platters are typical tertiary storage devices. The media (tapes and optical platters) vary between WORM (write-once, read-many-times) and RW (read write) formats.\\n',\n",
              " '   Tertiary storage is not crucial to system performance, but it still must be managed. Some operating systems take on this task, while others leave tertiary-storage management to application programs. Some of the functions that operating systems can provide include mounting and unmounting media in devices, allocating and freeing the devices for exclusive use by processes, and migrating data from secondary to tertiary storage.\\n',\n",
              " 'Caching is an important principle of computer systems. Heres how it works. Information is normally kept in some storage system (such as main memory). As it is used, it is copied into a faster storage system the cache on a\\n',\n",
              " 'temporary basis. When we need a particular piece of information, we first check whether it is in the cache. If it is, we use the information directly from the cache. If it is not, we use the information from the source, putting a copy in the cache under the assumption that we will need it again soon.\\n',\n",
              " '   In addition, internal programmable registers, such as index registers, provide a high-speed cache for main memory. The programmer (or compiler) implements the register-allocation and register-replacement algorithms to decide which information to keep in registers and which to keep in main memory.\\n',\n",
              " '   Other caches are implemented totally in hardware. For instance, most systems have an instruction cache to hold the instructions expected to be executed next. Without this cache, the CPU would have to wait several cycles while an instruction was fetched from main memory. For similar reasons, most systems have one or more high-speed data caches in the memory hierarchy. We are not concerned with these hardware-only caches in this text, since they are outside the control of the operating system.\\n',\n",
              " '   Because caches have limited size, cache management is an important design problem. Careful selection of the cache size and of a replacement policy can result in greatly increased performance. Figure 1.11 compares storage performance in large workstations and small servers. Various replacement algorithms for software-controlled caches are discussed in Chapter 9.\\n',\n",
              " '   Main memory can be viewed as a fast cache for secondary storage, since data in secondary storage must be copied into main memory for use and data must be in main memory before being moved to secondary storage for safekeeping. The file-system data, which resides permanently on secondary storage, may appear on several levels in the storage hierarchy. At the highest level, the operating system may maintain a cache of file-system data in main memory. In addition, solid-state disks may be used for high-speed storage that is accessed through the file-system interface. The bulk of secondary storage is on magnetic disks. The magnetic-disk storage, in turn, is often backed up onto magnetic tapes or removable disks to protect against data loss in case of a hard-disk failure. Some systems automatically archive old file data from secondary storage to tertiary storage, such as tape jukeboxes, to lower the storage cost (see Chapter 10).\\n',\n",
              " '   The movement of information between levels of a storage hierarchy may be either explicit or implicit, depending on the hardware design and the controlling operating-system software. For instance, data transfer from cache to CPU and registers is usually a hardware function, with no operating-system intervention. In contrast, transfer of data from disk to memory is usually controlled by the operating system.\\n',\n",
              " '   In a hierarchical storage structure, the same data may appear in different levels of the storage system. For example, suppose that an integer A that is to be incremented by 1 is located in file B, and file B resides on magnetic disk. The increment operation proceeds by first issuing an I/O operation to copy the disk block on which A resides to main memory. This operation is followed by copying A to the cache and to an internal register. Thus, the copy of A appears in several places: on the magnetic disk, in main memory, in the cache, and in an internal register (see Figure 1.12). Once the increment takes place in the internal register, the value of A differs in the various storage systems. The value of A becomes the same only after the new value of A is written from the internal register back to the magnetic disk.\\n',\n",
              " '   In a computing environment where only one process executes at a time, this arrangement poses no difficulties, since an access to integer A will always be to the copy at the highest level of the hierarchy. However, in a multitasking environment, where the CPU is switched back and forth among various processes, extreme care must be taken to ensure that, if several processes wish to access A, then each of these processes will obtain the most recently updated value of A.\\n',\n",
              " '   The situation becomes more complicated in a multiprocessor environment where, in addition to maintaining internal registers, each of the CPUs also contains a local cache (Figure 1.6). In such an environment, a copy of A may exist simultaneously in several caches. Since the various CPUs can all execute in parallel, we must make sure that an update to the value of A in one cache is immediately reflected in all other caches where A resides. This situation is called cache coherency, and it is usually a hardware issue (handled below the operating-system level).\\n',\n",
              " '   In a distributed environment, the situation becomes even more complex. In this environment, several copies (or replicas) of the same file can be kept on different computers. Since the various replicas may be accessed and updated concurrently, some distributed systems ensure that, when a replica is updated in one place, all other replicas are brought up to date as soon as possible. There are various ways to achieve this guarantee, as we discuss in Chapter 17.\\n',\n",
              " '    We discussed in Section 1.2.3 how interrupt handlers and device drivers are used in the construction of efficient I/O subsystems. In Chapter 13, we discuss how the I/O subsystem interfaces to the other system components, manages devices, transfers data, and detects I/O completion.\\n',\n",
              " 'If a computer system has multiple users and allows the concurrent execution of multiple processes, then access to data must be regulated. For that purpose, mechanisms ensure that files, memory segments, CPU, and other resources can be operated on by only those processes that have gained proper authoriza- tion from the operating system. For example, memory-addressing hardware ensures that a process can execute only within its own address space. The timer ensures that no process can gain control of the CPU without eventually relinquishing control. Device-control registers are not accessible to users, so the integrity of the various peripheral devices is protected.\\n',\n",
              " '   Protection, then, is any mechanism for controlling the access of processes or users to the resources defined by a computer system. This mechanism must provide means to specify the controls to be imposed and to enforce the controls. Protection can improve reliability by detecting latent errors at the interfaces between component subsystems. Early detection of interface errors can often prevent contamination of a healthy subsystem by another subsystem that is malfunctioning. Furthermore, an unprotected resource cannot defend against use (or misuse) by an unauthorized or incompetent user. A protection-oriented system provides a means to distinguish between authorized and unauthorized\\n',\n",
              " '   A system can have adequate protection but still be prone to failure and allow inappropriate access. Consider a user whose authentication information (her means of identifying herself to the system) is stolen. Her data could be copied or deleted, even though file and memory protection are working. It is the job of security to defend a system from external and internal attacks. Such attacks spread across a huge range and include viruses and worms, denial-of- service attacks (which use all of a systems resources and so keep legitimate users out of the system), identity theft, and theft of service (unauthorized use of a system). Prevention of some of these attacks is considered an operating-system function on some systems, while other systems leave it to policy or additional software. Due to the alarming rise in security incidents,\\n',\n",
              " '   Protection and security require the system to be able to distinguish among all its users. Most operating systems maintain a list of user names and associated user identifiers (user IDs). In Windows parlance, this is a security ID (SID). These numerical IDs are unique, one per user. When a user logs in to the system, the authentication stage determines the appropriate user ID for the user. That user ID is associated with all of the users processes and threads. When an ID needs to be readable by a user, it is translated back to the user name via the user name list.\\n',\n",
              " '   In some circumstances, we wish to distinguish among sets of users rather than individual users. For example, the owner of a file on a UNIX system may be allowed to issue all operations on that file, whereas a selected set of users may be allowed only to read the file. To accomplish this, we need to define a group name and the set of users belonging to that group. Group functionality can be implemented as a system-wide list of group names and group identifiers. A user can be in one or more groups, depending on operating-system design decisions. The users group IDs are also included in every associated process and thread.\\n',\n",
              " '   In the course of normal system use, the user ID and group ID for a user are sufficient. However, a user sometimes needs to escalate privileges to gain extra permissions for an activity. The user may need access to a device that is restricted, for example. Operating systems provide various methods to allow privilege escalation. On UNIX, for instance, the setuid attribute on a program causes that program to run with the user ID of the owner of the file, rather than the current users ID. The process runs with this effective UID until it turns off the extra privileges or terminates.\\n',\n",
              " 'We turn next to a topic central to operating-system implementation: the way data are structured in the system. In this section, we briefly describe several fundamental data structures used extensively in operating systems. Readers who require further details on these structures, as well as others, should consult the bibliography at the end of the chapter.\\n',\n",
              " 'An array is a simple data structure in which each element can be accessed directly. For example, main memory is constructed as an array. If the data item being stored is larger than one byte, then multiple bytes can be allocated to the item, and the item is addressed as item number item size. But what about storing an item whose size may vary? And what about removing an item if the relative positions of the remaining items must be preserved? In such situations, arrays give way to other data structures.\\n',\n",
              " '   After arrays, lists are perhaps the most fundamental data structures in computer science. Whereas each item in an array can be accessed directly, the items in a list must be accessed in a particular order. That is, a list represents a collection of data values as a sequence. The most common method for\\n',\n",
              " '   Linked lists accommodate items of varying sizes and allow easy insertion and deletion of items. One potential disadvantage of using a list is that performance for retrieving a specified item in a list of size n is linear  O(n), as it requires potentially traversing all n elements in the worst case. Lists are sometimes used directly by kernel algorithms. Frequently, though, they are used for constructing more powerful data structures, such as stacks and queues.\\n',\n",
              " '   A stack is a sequentially ordered data structure that uses the last in, first out (LIFO) principle for adding and removing items, meaning that the last item placed onto a stack is the first item removed. The operations for inserting and removing items from a stack are known as push and pop, respectively. An operating system often uses a stack when invoking function calls. Parameters, local variables, and the return address are pushed onto the stack when a function is called; returning from the function call pops those items off the stack.\\n',\n",
              " '   A queue, in contrast, is a sequentially ordered data structure that uses the first in, first out (FIFO) principle: items are removed from a queue in the order in which they were inserted. There are many everyday examples of queues, including shoppers waiting in a checkout line at a store and cars waiting in line at a traffic signal. Queues are also quite common in operating systems jobs that are sent to a printer are typically printed in the order in which they were submitted, for example. As we shall see in Chapter 6, tasks that are waiting to be run on an available CPU are often organized in queues.\\n',\n",
              " 'A tree is a data structure that can be used to represent data hierarchically. Data values in a tree structure are linked through parent child relationships. In a general tree, a parent may have an unlimited number of children. In a binary tree, a parent may have at most two children, which we term the left child and the right child. A binary search tree additionally requires an ordering between the parents two children in which le f t child <    right child. Figure\\n',\n",
              " '1.16 provides an example of a binary search tree. When we search for an item in a binary search tree, the worst-case performance is O(n) (consider how this can occur). To remedy this situation, we can use an algorithm to create a balanced binary search tree. Here, a tree containing n items has at most lg n levels, thus ensuring worst-case performance of O(lg n). We shall see in Section 6.7.1 that Linux uses a balanced binary search tree as part its CPU-scheduling algorithm.\\n',\n",
              " 'A hash function takes data as its input, performs a numeric operation on this data, and returns a numeric value. This numeric value can then be used as an index into a table (typically an array) to quickly retrieve the data. Whereas searching for a data item through a list of size n can require up to O(n) comparisons in the worst case, using a hash function for retrieving data from table can be as good as O(1) in the worst case, depending on implementation details. Because of this performance, hash functions are used extensively in operating systems.\\n',\n",
              " '   One potential difficulty with hash functions is that two inputs can result in the same output value  that is, they can link to the same table location. We can accommodate this hash collision by having a linked list at that table location that contains all of the items with the same hash value. Of course, the more collisions there are, the less efficient the hash function is.\\n',\n",
              " '   One use of a hash function is to implement a hash map, which associates (or maps) [key:value] pairs using a hash function. For example, we can map the key operating to the value system. Once the mapping is established, we can apply the hash function to the key to obtain the value from the hash map (Figure 1.17). For example, suppose that a user name is mapped to a password. Password authentication then proceeds as follows: a user enters his user name and password. The hash function is applied to the user name, which is then used to retrieve the password. The retrieved password is then compared with the password entered by the user for authentication.\\n',\n",
              " 'A bitmap is a string of n binary digits that can be used to represent the status of n items. For example, suppose we have several resources, and the availability of each resource is indicated by the value of a binary digit: 0 means that the resource is available, while 1 indicates that it is unavailable (or vice-versa). The value of the ith position in the bitmap is associated with the ith resource. As an example, consider the bitmap shown below:\\n',\n",
              " 'Resources 2, 4, 5, 6, and 8 are unavailable; resources 0, 1, 3, and 7 are available. The power of bitmaps becomes apparent when we consider their space efficiency. If we were to use an eight-bit Boolean value instead of a single bit, the resulting data structure would be eight times larger. Thus, bitmaps are commonly used when there is a need to represent the availability of a large number of resources. Disk drives provide a nice illustration. A medium-sized disk drive might be divided into several thousand individual units, called disk\\n',\n",
              " '   Data structures are pervasive in operating system implementations. Thus, we will see the structures discussed here, along with others, throughout this text as we explore kernel algorithms and their implementations.\\n',\n",
              " 'So far, we have briefly described several aspects of computer systems and the operating systems that manage them. We turn now to a discussion of how operating systems are used in a variety of computing environments.\\n',\n",
              " 'As computing has matured, the lines separating many of the traditional com- puting environments have blurred. Consider the typical office environment. Just a few years ago, this environment consisted of PCs connected to a network, with servers providing file and print services. Remote access was awkward, and portability was achieved by use of laptop computers. Terminals attached to mainframes were prevalent at many companies as well, with even fewer remote access and portability options.\\n',\n",
              " '   The current trend is toward providing more ways to access these computing environments. Web technologies and increasing WAN bandwidth are stretching the boundaries of traditional computing. Companies establish portals, which provide Web accessibility to their internal servers. Network computers (or thin clients) which are essentially terminals that understand web-based computing  are used in place of traditional workstations where more security or easier maintenance is desired. Mobile computers can synchronize with PCs to allow very portable use of company information. Mobile computers can also connect to wireless networks and cellular data networks to use the companys Web portal (as well as the myriad other Web resources).\\n',\n",
              " '   At home, most users once had a single computer with a slow modem connection to the office, the Internet, or both. Today, network-connection speeds once available only at great cost are relatively inexpensive in many places, giving home users more access to more data. These fast data connections are allowing home computers to serve up Web pages and to run networks that include printers, client PCs, and servers. Many homes use firewalls to protect their networks from security breaches.\\n',\n",
              " '   In the latter half of the 20th century, computing resources were relatively scarce. (Before that, they were nonexistent!) For a period of time, systems were either batch or interactive. Batch systems processed jobs in bulk, with predetermined input from files or other data sources. Interactive systems waited for input from users. To optimize the use of the computing resources, multiple users shared time on these systems. Time-sharing systems used a\\n',\n",
              " '    Today, traditional time-sharing systems are uncommon. The same schedul- ing technique is still in use on desktop computers, laptops, servers, and even mobile computers, but frequently all the processes are owned by the same user (or a single user and the operating system). User processes, and system processes that provide services to the user, are managed so that each frequently gets a slice of computer time. Consider the windows created while a user is working on a PC, for example, and the fact that they may be performing different tasks at the same time. Even a web browser can be composed of multiple processes, one for each website currently being visited, with time sharing applied to each web browser process.\\n',\n",
              " 'Mobile computing refers to computing on handheld smartphones and tablet computers. These devices share the distinguishing physical features of being portable and lightweight. Historically, compared with desktop and laptop computers, mobile systems gave up screen size, memory capacity, and overall functionality in return for handheld mobile access to services such as e-mail and web browsing. Over the past few years, however, features on mobile devices have become so rich that the distinction in functionality between, say, a consumer laptop and a tablet computer may be difficult to discern. In fact, we might argue that the features of a contemporary mobile device allow it to provide functionality that is either unavailable or impractical on a desktop or laptop computer.\\n',\n",
              " '   Today, mobile systems are used not only for e-mail and web browsing but also for playing music and video, reading digital books, taking photos, and recording high-definition video. Accordingly, tremendous growth continues in the wide range of applications that run on such devices. Many developers are now designing applications that take advantage of the unique features of mobile devices, such as global positioning system (GPS) chips, accelerometers, and gyroscopes. An embedded GPS chip allows a mobile device to use satellites to determine its precise location on earth. That functionality is especially useful in designing applications that provide navigation for example, telling users which way to walk or drive or perhaps directing them to nearby services, such as restaurants. An accelerometer allows a mobile device to detect its orientation with respect to the ground and to detect certain other forces, such as tilting and shaking. In several computer games that employ accelerometers, players interface with the system not by using a mouse or a keyboard but rather by tilting, rotating, and shaking the mobile device! Perhaps more a practical use of these features is found in augmented-reality applications, which overlay information on a display of the current environment. It is difficult to imagine how equivalent applications could be developed on traditional laptop or desktop computer systems.\\n',\n",
              " '   To provide access to on-line services, mobile devices typically use either IEEE standard 802.11 wireless or cellular data networks. The memory capacity and processing speed of mobile devices, however, are more limited than those of PCs. Whereas a smartphone or tablet may have 64 GB in storage, it is not uncommon to find 1 TB in storage on a desktop computer. Similarly, because\\n',\n",
              " 'power consumption is such a concern, mobile devices often use processors that are smaller, are slower, and offer fewer processing cores than processors found on traditional desktop and laptop computers.\\n',\n",
              " '   Two operating systems currently dominate mobile computing: Apple iOS and Google Android. iOS was designed to run on Apple iPhone and iPad mobile devices. Android powers smartphones and tablet computers available from many manufacturers. We examine these two mobile operating systems in further detail in Chapter 2.\\n',\n",
              " 'A distributed system is a collection of physically separate, possibly heteroge- neous, computer systems that are networked to provide users with access to the various resources that the system maintains. Access to a shared resource increases computation speed, functionality, data availability, and reliability. Some operating systems generalize network access as a form of file access, with the details of networking contained in the network interfaces device driver. Others make users specifically invoke network functions. Generally, systems contain a mix of the two modes  for example FTP and NFS. The protocols that create a distributed system can greatly affect that systems utility and popularity.\\n',\n",
              " '   A network, in  the simplest terms, is a communication  path between two or more systems. Distributed systems depend on networking for their functionality. Networks vary by the protocols used, the distances between nodes, and the transport media. TCP/IP is the most common network protocol, and it provides the fundamental architecture of the Internet. Most operating systems support TCP/IP, including all general-purpose ones. Some systems support proprietary protocols to suit their needs. To an operating system, a network protocol simply needs an interface device a network adapter, for example with a device driver to manage it, as well as software to handle data. These concepts are discussed throughout this book.\\n',\n",
              " '   Networks are characterized based on the distances between their nodes. A local-area network (LAN) connects computers within a room, a building, or a campus. A wide-area network (WAN) usually links buildings, cities, or countries. A global company may have a WAN to connect its offices worldwide, for example. These networks may run one protocol or several protocols. The continuing advent of new technologies brings about new forms of networks. For example, a metropolitan-area network (MAN) could link buildings within a city. BlueTooth and 802.11 devices use wireless technology to communicate over a distance of several feet, in essence creating a personal-area network (PAN) between a phone and a headset or a smartphone and a desktop computer. The media to carry networks are equally varied. They include copper wires, fiber strands, and wireless transmissions between satellites, microwave dishes, and radios. When computing devices are connected to cellular phones, they create a network. Even very short-range infrared communication can be used for networking. At a rudimentary level, whenever computers communicate, they use or create a network. These networks also vary in their performance\\n',\n",
              " 'A network operating system is an operating system that provides features such as file sharing across the network, along with a communication scheme that allows different processes on different computers to exchange messages. A computer running a network operating system acts autonomously from all other computers on the network, although it is aware of the network and is able to communicate with other networked computers. A distributed operating system provides a less autonomous environment. The different computers communicate closely enough to provide the illusion that only a single operating system controls the network. We cover computer networks and distributed systems in Chapter 17.\\n',\n",
              " 'As PCs have become faster, more powerful, and cheaper, designers have shifted away from centralized system architecture. Terminals connected to centralized systems are now being supplanted by PCs and mobile devices. Correspond- ingly, user-interface functionality once handled directly by centralized systems is increasingly being handled by PCs, quite often through a web interface. As a result, many of todays systems act as server systems to satisfy requests generated by client systems. This form of specialized distributed system, called a client server system, has the general structure depicted in Figure 1.18.\\n',\n",
              " ' The compute-server system provides an interface to which a client can send a request to perform an action (for example, read data). In response, the server executes the action and sends the results to the client. A server running a database that responds to client requests for data is an example of such a system.\\n',\n",
              " ' The file-server system provides a file-system interface where clients can create, update, read, and delete files. An example of such a system is a web server that delivers files to clients running web browsers.\\n',\n",
              " 'Another structure for a distributed system is the peer-to-peer (P2P) system model. In this model, clients and servers are not distinguished from one another. Instead, all nodes within the system are considered peers, and each may act as either a client or a server, depending on whether it is requesting or providing a service. Peer-to-peer systems offer an advantage over traditional client-server systems. In a client-server system, the server is a bottleneck; but in a peer-to-peer system, services can be provided by several nodes distributed throughout the network.\\n',\n",
              " '   To participate in a peer-to-peer system, a node must first join the network of peers. Once a node has joined the network, it can begin providing services to and requesting services from other nodes in the network. Determining what services are available is accomplished in one of two general ways:\\n',\n",
              " ' When a node joins a network, it registers its service with a centralized lookup service on the network. Any node desiring a specific service first contacts this centralized lookup service to determine which node provides the service. The remainder of the communication takes place between the client and the service provider.\\n',\n",
              " ' An alternative scheme uses no centralized lookup service. Instead, a peer acting as a client must discover what node provides a desired service by broadcasting a request for the service to all other nodes in the network. The node (or nodes) providing that service responds to the peer making the request. To support this approach, a discovery protocol must be provided that allows peers to discover services provided by other peers in the network. Figure 1.19 illustrates such a scenario.\\n',\n",
              " '    Peer-to-peer networks gained widespread popularity in the late 1990s with several file-sharing services, such as Napster and Gnutella, that enabled peers to exchange files with one another. The Napster system used an approach similar to the first type described above: a centralized server maintained an index of all files stored on peer nodes in the Napster network, and the actual\\n',\n",
              " 'exchange of files took place between the peer nodes. The Gnutella system used a technique similar to the second type: a client broadcasted file requests to other nodes in the system, and nodes that could service the request responded directly to the client. The future of exchanging files remains uncertain because peer-to-peer networks can be used to exchange copyrighted materials (music, for example) anonymously, and there are laws governing the distribution of copyrighted material. Notably, Napster ran into legal trouble for copyright infringement and its services were shut down in 2001.\\n',\n",
              " '   Skype is another example of peer-to-peer computing. It allows clients to make voice calls and video calls and to send text messages over the Internet using a technology known as voice over IP (VoIP). Skype uses a hybrid peer- to-peer approach. It includes a centralized login server, but it also incorporates decentralized peers and allows two peers to communicate.\\n',\n",
              " 'Virtualization is a technology that allows operating systems to run as appli- cations within other operating systems. At first blush, there seems to be little reason for such functionality. But the virtualization industry is vast and growing, which is a testament to its utility and importance.\\n',\n",
              " '   Broadly speaking, virtualization is one member of a class of software that also includes emulation. Emulation is used when the source CPU type is different from the target CPU type. For example, when Apple switched from the IBM Power CPU to the Intel x86 CPU for its desktop and laptop computers, it included an emulation facility called Rosetta, which allowed applications compiled for the IBM CPU to run on the Intel CPU. That same concept can be extended to allow an entire operating system written for one platform to run on another. Emulation comes at a heavy price, however. Every machine-level instruction that runs natively on the source system must be translated to the equivalent function on the target system, frequently resulting in several target instructions. If the source and target CPUs have similar performance levels, the emulated code can run much slower than the native code.\\n',\n",
              " '   A common example of emulation occurs when a computer language is not compiled to native code but instead is either executed in its high-level form or translated to an intermediate form. This is known as interpretation. Some languages, such as BASIC, can be either compiled or interpreted. Java, in contrast, is always interpreted. Interpretation is a form of emulation in that the high-level language code is translated to native CPU instructions, emulating not another CPU but a theoretical virtual machine on which that language could run natively. Thus, we can run Java programs on Java virtual machines, but technically those virtual machines are Java emulators.\\n',\n",
              " '   With virtualization, in contrast, an operating system that is natively com- piled for a particular CPU architecture runs within another operating system also native to that CPU. Virtualization first came about on IBM mainframes as a method for multiple users to run tasks concurrently. Running multiple virtual machines allowed (and still allows) many users to run tasks on a system designed for a single user. Later, in response to problems with running multiple Microsoft Windows XP applications on the Intel x86 CPU, VMware created a new virtualization technology in the form of an application that ran on XP. That application ran one or more guest copies of Windows or other native\\n',\n",
              " 'x86 operating systems, each running its own applications. (See Figure 1.20.) Windows was the host operating system, and the VMware application was the virtual machine manager VMM. The VMM runs the guest operating systems, manages their resource use, and protects each guest from the others.\\n',\n",
              " '   Even though modern operating systems are fully capable of running multiple applications reliably, the use of virtualization continues to grow. On laptops and desktops, a VMM allows the user to install multiple operating systems for exploration or to run applications written for operating systems other than the native host. For example, an Apple laptop running Mac OS X on the x86 CPU can run a Windows guest to allow execution of Windows applications. Companies writing software for multiple operating systems can use virtualization to run all of those operating systems on a single physical server for development, testing, and debugging. Within data centers, virtualization has become a common method of executing and managing computing environments. VMMs like VMware, ESX, and Citrix XenServer no longer run on host operating systems but rather are the hosts. Full details of the features and implementation of virtualization are found in Chapter 16.\\n',\n",
              " 'Cloud computing is a type of computing that delivers computing, storage, and even applications as a service across a network. In some ways, its a logical extension of virtualization, because it uses virtualization as a base for its functionality. For example, the Amazon Elastic Compute Cloud (EC2) facility has thousands of servers, millions of virtual machines, and petabytes of storage available for use by anyone on the Internet. Users pay per month based on how much of those resources they use.\\n',\n",
              " 'These cloud-computing types are not discrete, as a cloud computing environ- ment may provide a combination of several types. For example, an organization may provide both SaaS and IaaS as a publicly available service.\\n',\n",
              " '   Certainly, there are traditional operating systems within many of the types of cloud infrastructure. Beyond those are the VMMs that manage the virtual machines in which the user processes run. At a higher level, the VMMs themselves are managed by cloud management tools, such as Vware vCloud Director and the open-source Eucalyptus toolset. These tools manage the resources within a given cloud and provide interfaces to the cloud components, making a good argument for considering them a new type of operating system.\\n',\n",
              " 'Embedded computers are the most prevalent form of computers in existence. These devices are found everywhere, from car engines and manufacturing robots to DVDs and microwave ovens. They tend to have very specific tasks. The systems they run on are usually primitive, and so the operating systems provide limited features. Usually, they have little or no user interface, preferring to spend their time monitoring and managing hardware devices, such as automobile engines and robotic arms.\\n',\n",
              " '   These embedded systems vary considerably. Some are general-purpose computers, running standard operating systems  such as Linux  with special-purpose applications to implement the functionality. Others are hard- ware devices with a special-purpose embedded operating system providing just the functionality desired. Yet others are hardware devices with application- specific integrated circuits (ASICs) that perform their tasks without an operat- ing system.\\n',\n",
              " '   The use of embedded systems continues to expand. The power of these devices, both as standalone units and as elements of networks and the web, is sure to increase as well. Even now, entire houses can be computerized, so that a central computer either a general-purpose computer or an embedded system can control heating and lighting, alarm systems, and even coffee makers. Web access can enable a home owner to tell the house to heat up before she arrives home. Someday, the refrigerator can notify the grocery store when it notices the milk is gone.\\n',\n",
              " '   Embedded systems almost always run real-time operating systems. A real-time system is used when rigid time requirements have been placed on the operation of a processor or the flow of data; thus, it is often used as a control device in a dedicated application. Sensors bring data to the computer. The computer must analyze the data and possibly adjust controls to modify the sensor inputs. Systems that control scientific experiments, medical imaging systems, industrial control systems, and certain display systems are real- time systems. Some automobile-engine fuel-injection systems, home-appliance controllers, and weapon systems are also real-time systems.\\n',\n",
              " '   A real-time system has well-defined, fixed time constraints. Processing must be done within the defined constraints, or the system will fail. For instance, it would not do for a robot arm to be instructed to halt after it had smashed into the car it was building. A real-time system functions correctly only if it returns the correct result within its time constraints. Contrast this system with a time-sharing system, where it is desirable (but not mandatory) to respond quickly, or a batch system, which may have no time constraints at all.\\n',\n",
              " '   In Chapter 6, we consider the scheduling facility needed to implement real-time functionality in an operating system. In Chapter 9, we describe the design of memory management for real-time computing. Finally, in Chapters 18 and 19, we describe the real-time components of the Linux and Windows 7 operating systems.\\n',\n",
              " 'releases. Open-source operating systems are those available in source-code format rather than as compiled binary code. Linux is the most famous open- source operating system, while Microsoft Windows is a well-known example of the opposite closed-source approach. Apples Mac OS X and iOS operating systems comprise a hybrid approach. They contain an open-source kernel named Darwin yet include proprietary, closed-source components as well.\\n',\n",
              " '   Starting with the source code allows the programmer to produce binary code that can be executed on a system. Doing the opposite reverse engi- neering the source code from the binaries  is quite a lot of work, and useful items such as comments are never recovered. Learning operating systems by examining the source code has other benefits as well. With the source code in hand, a student can modify the operating system and then compile and run the code to try out those changes, which is an excellent learning tool. This text includes projects that involve modifying operating-system source code, while also describing algorithms at a high level to be sure all important operating-system topics are covered. Throughout the text, we provide pointers to examples of open-source code for deeper study.\\n',\n",
              " '   There are many benefits to open-source operating systems, including a community of interested (and usually unpaid) programmers who contribute to the code by helping to debug it, analyze it, provide support, and suggest changes. Arguably, open-source code is more secure than closed-source code because many more eyes are viewing the code. Certainly, open-source code has bugs, but open-source advocates argue that bugs tend to be found and fixed faster owing to the number of people using and viewing the code. Companies that earn revenue from selling their programs often hesitate to open-source their code, but Red Hat and a myriad of other companies are doing just that and showing that commercial companies benefit, rather than suffer, when they open-source their code. Revenue can be generated through support contracts and the sale of hardware on which the software runs, for example.\\n',\n",
              " 'In the early days of modern computing (that is, the 1950s), a great deal of software was available in open-source format. The original hackers (computer enthusiasts) at MITs Tech Model Railroad Club left their programs in drawers for others to work on. Homebrew user groups exchanged code during their meetings. Later, company-specific user groups, such as Digital Equipment Corporations DEC, accepted contributions of source-code programs, collected them onto tapes, and distributed the tapes to interested members.\\n',\n",
              " '   Computer and software companies eventually sought to limit the use of their software to authorized computers and paying customers. Releasing only the binary files compiled from the source code, rather than the source code itself, helped them to achieve this goal, as well as protecting their code and their ideas from their competitors. Another issue involved copyrighted material. Operating systems and other programs can limit the ability to play back movies and music or display electronic books to authorized computers. Such copy protection or digital rights management (DRM) would not be effective if the source code that implemented these limits were published. Laws in many countries, including the U.S. Digital Millennium Copyright Act (DMCA), make it illegal to reverse-engineer DRM code or otherwise try to circumvent copy protection.\\n',\n",
              " '   To counter the move to limit software use and redistribution, Richard Stallman in 1983 started the GNU project to create a free, open-source, UNIX- compatible operating system. In 1985, he published the GNU Manifesto, which argues that all software should be free and open-sourced. He also formed the Free Software Foundation (FSF) with the goal of encouraging the free exchange of software source code and the free use of that software. Rather than copyright its software, the FSF copylefts the software to encourage sharing and improvement. The GNU General Public License (GPL) codifies copylefting and is a common license under which free software is released. Fundamentally, GPL requires that the source code be distributed with any binaries and that any changes made to the source code be released under the same GPL license.\\n',\n",
              " 'As an example of an open-source operating system, consider GNU/Linux. The GNU project produced many UNIX-compatible tools, including compilers, editors, and utilities, but never released a kernel. In 1991, a student in Finland, Linus Torvalds, released a rudimentary UNIX-like kernel using the GNU compilers and tools and invited contributions worldwide. The advent of the Internet meant that anyone interested could download the source code, modify it, and submit changes to Torvalds. Releasing updates once a week allowed this so-called Linux operating system to grow rapidly, enhanced by several thousand programmers.\\n',\n",
              " '   The resulting GNU/Linux operating system has spawned hundreds of unique distributions, or custom builds, of the system. Major distributions include RedHat, SUSE, Fedora, Debian, Slackware, and Ubuntu. Distributions vary in function, utility, installed applications, hardware support, user inter- face, and purpose. For example, RedHat Enterprise Linux is geared to large commercial use. PCLinuxOS is a LiveCD  an operating system that can be booted and run from a CD-ROM without being installed on a systems hard disk. One variant of PCLinuxOS  called PCLinuxOS Supergamer DVDis a LiveDVD that includes graphics drivers and games. A gamer can run it on any compatible system simply by booting from the DVD. When the gamer is finished, a reboot of the system resets it to its installed operating system.\\n',\n",
              " 'With this text, we provide a virtual machine image of Linux running the Debian release. This image contains the Linux source code as well as tools for software development. We cover examples involving that Linux image throughout this text, as well as in a detailed case study in Chapter 18.\\n',\n",
              " 'BSD UNIX has a longer and more complicated history than Linux. It started in 1978 as a derivative of AT&Ts UNIX. Releases from the University of California at Berkeley (UCB) came in source and binary form, but they were not open- source because a license from AT&T was required. BSD UNIXs development was slowed by a lawsuit by AT&T, but eventually a fully functional, open-source version, 4.4BSD-lite, was released in 1994.\\n',\n",
              " '   Just as with Linux, there are many distributions of BSD UNIX, including FreeBSD, NetBSD, OpenBSD, and DragonflyBSD. To explore the source code of FreeBSD, simply download the virtual machine image of the version of interest and boot it within VMware, as described above for Linux. The source code comes with the distribution and is stored in /usr/src/. The kernel source code is in /usr/src/sys. For example, to examine the virtual memory implementation code in the FreeBSD kernel, see the files in /usr/src/sys/vm. Darwin, the core kernel component  of  Mac  OS  X,  is  based  on  BSD UNIX and is open-sourced as well. That source code is available from http://www.opensource.apple.com/. Every Mac OS X release has its  open- source components posted at that site. The name of the package that contains the kernel begins with xnu. Apple also provides extensive developer tools, documentation, and support at http://connect.apple.com. For more informa-\\n',\n",
              " 'Solaris is the commercial UNIX-based operating system of Sun Microsystems. Originally, Suns SunOS operating system was based on BSD UNIX. Sun moved to AT&Ts System V UNIX as its base in 1991. In 2005, Sun open-sourced most of the Solaris code as the OpenSolaris project. The purchase of Sun by Oracle in 2009, however, left the state of this project unclear. The source code as it was in 2005 is still available via a source code browser and for download at http://src.opensolaris.org/source.\\n',\n",
              " '   Several groups interested in using OpenSolaris have started from that base and expanded its features. Their working set is Project Illumos, which has expanded from the OpenSolaris base to include more features and to be the basis for several products. Illumos is available at http://wiki.illumos.org.\\n',\n",
              " 'The free software movement is driving legions of programmers to create thousands of open-source projects, including operating systems. Sites like http://freshmeat.net/   and   http://distrowatch.com/   provide  portals  to   many of these projects. As we stated earlier, open-source projects enable students to use source code as a learning tool. They can modify programs and test them,\\n',\n",
              " 'help find and fix bugs, and otherwise explore mature, full-featured operating systems, compilers, tools, user interfaces, and other types of programs. The availability of source code for historic projects, such as Multics, can help students to understand those projects and to build knowledge that will help in the implementation of new projects.\\n',\n",
              " '    GNU/Linux and BSD UNIX are all open-source operating systems, but each has its own goals, utility, licensing, and purpose. Sometimes, licenses are not mutually exclusive and cross-pollination occurs, allowing rapid improvements in operating-system projects. For example, several major components of OpenSolaris have been ported to BSD UNIX. The advantages of free software and open sourcing are likely to increase the number and quality of open-source projects, leading to an increase in the number of individuals and companies that use these projects.\\n',\n",
              " 'An operating system is software that manages the computer hardware, as well as providing an environment for application programs to run. Perhaps the most visible aspect of an operating system is the interface to the computer system it provides to the human user.\\n',\n",
              " '    For a computer to do its job of executing programs, the programs must be in main memory. Main memory is the only large storage area that the processor can access directly. It is an array of bytes, ranging in size from millions to billions. Each byte in memory has its own address. The main memory is usually a volatile storage device that loses its contents when power is turned off or lost. Most computer systems provide secondary storage as an extension of main memory. Secondary storage provides a form of nonvolatile storage that is capable of holding large quantities of data permanently. The most common secondary-storage device is a magnetic disk, which provides storage of both programs and data.\\n',\n",
              " '    The wide variety of storage systems in a computer system can be organized in a hierarchy according to speed and cost. The higher levels are expensive, but they are fast. As we move down the hierarchy, the cost per bit generally decreases, whereas the access time generally increases.\\n',\n",
              " '   There are several different strategies for designing a computer system. Single-processor systems have only one processor, while multiprocessor systems contain two or more processors that share physical memory and peripheral devices. The most common multiprocessor design is symmetric multiprocessing (or SMP), where all processors are considered peers and run independently of one another. Clustered systems are a specialized form of multiprocessor systems and consist of multiple computer systems connected by a local-area network.\\n',\n",
              " '   To best utilize the CPU, modern operating systems employ multiprogram- ming, which allows several jobs to be in memory at the same time, thus ensuring that the CPU always has a job to execute. Time-sharing systems are an exten- sion of multiprogramming wherein CPU scheduling algorithms rapidly switch between jobs, thus providing the illusion that each job is running concurrently. The operating system must ensure correct operation of the computer system. To prevent user programs from interfering with the proper operation of\\n',\n",
              " 'There has never been a more interesting time to study operating systems, and it has never been easier. The open-source movement has overtaken operating systems, causing many of them to be made available in both source and binary (executable) format. The list of operating systems available in both formats includes Linux, BSD UNIX, Solaris, and part of Mac OS X. The availability of source code allows us to study operating systems from the inside out. Questions that we could once answer only by looking at documentation or the behavior of an operating system we can now answer by examining the code itself.\\n',\n",
              " '  Operating systems that are no longer commercially viable have been open-sourced as well, enabling us to study how systems operated in a time of fewer CPU, memory, and storage resources. An extensive but incomplete list of open-source operating-system projects is available from http://dmoz.org/Computers/Software/Operating Systems/Open Source/.\\n',\n",
              " '  In addition, the rise of virtualization as a mainstream (and frequently free) computer function makes it possible to run many operating systems on top of one core system. For example, VMware ( http://www.vmware.com) provides a free player for Windows on which hundreds of free virtual appliances can run. Virtualbox ( http://www.virtualbox.com) provides a free, open- source virtual machine manager on many operating systems. Using such tools, students can try out hundreds of operating systems without dedicated hardware.\\n',\n",
              " '  In some cases, simulators of specific hardware are also available, allowing the operating system to run on native hardware, all within the confines of a modern computer and modern operating system. For example, a DECSYSTEM-20 simulator running on Mac OS X can boot TOPS-20, load the source tapes, and modify and compile a new TOPS-20 kernel. An interested student can search the Internet to find the original papers that describe the operating system, as well as the original manuals.\\n',\n",
              " '  The advent of open-source operating systems has also made it easier to make the move from student to operating-system developer. With some knowledge, some effort, and an Internet connection, a student can even create a new operating-system distribution. Just a few years ago, it was difficult or impossible to get access to source code. Now, such access is limited only by how much interest, time, and disk space a student has.\\n',\n",
              " 'the system, the hardware has two modes: user mode and kernel mode. Various instructions (such as I/O instructions and halt instructions) are privileged and can be executed only in kernel mode. The memory in which the operating system resides must also be protected from modification by the user. A timer prevents infinite loops. These facilities (dual mode, privileged instructions, memory protection, and timer interrupt) are basic building blocks used by operating systems to achieve correct operation.\\n',\n",
              " '   A process (or job) is the fundamental unit of work in an operating system. Process management includes creating and deleting processes and providing mechanisms for processes to communicate and synchronize with each other.\\n',\n",
              " 'An operating system manages memory by keeping track of what parts of memory are being used and by whom. The operating system is also responsible for dynamically allocating and freeing memory space. Storage space is also managed by the operating system; this includes providing file systems for representing files and directories and managing space on mass-storage devices. Operating systems must also be concerned with protecting and securing the operating system and users. Protection measures control the access of processes or users to the resources made available by the computer system. Security measures are responsible for defending a computer system from external or\\n',\n",
              " '    Computing takes place in a variety of environments. Traditional computing involves desktop and laptop PCs, usually connected to a computer network. Mobile computing refers to computing on handheld smartphones and tablet computers, which offer several unique features. Distributed systems allow users to share resources on geographically dispersed hosts connected via a computer network. Services may be provided through either the client server model or the peer-to-peer model. Virtualization involves abstracting a computers hardware into several different execution environments. Cloud computing uses a distributed system to abstract services into a cloud, where users may access the services from remote locations. Real-time operating systems are designed for embedded environments, such as consumer devices, automobiles, and robotics.\\n',\n",
              " '    The free software movement has created thousands of open-source projects, including operating systems. Because of these projects, students are able to use source code as a learning tool. They can modify programs and test them, help find and fix bugs, and otherwise explore mature, full-featured operating systems, compilers, tools, user interfaces, and other types of programs.\\n',\n",
              " '    GNU/Linux and BSD UNIX are open-source operating systems. The advan- tages of free software and open sourcing are likely to increase the number and quality of open-source projects, leading to an increase in the number of individuals and companies that use these projects.\\n',\n",
              " '1.2 We have stressed the need for an operating system to make efficient use of the computing hardware. When is it appropriate for the operating system to forsake this principle and to waste resources? Why is such a system not really wasteful?\\n',\n",
              " '1.4 Keeping in mind the various definitions of operating system, consider whether the operating system should include applications such as web browsers and mail programs. Argue both that it should and that it should not, and support your answers.\\n',\n",
              " '1.7 Some early computers protected the operating system by placing it in a memory partition that could not be modified by either the user job or the operating system itself. Describe two difficulties that you think could arise with such a scheme.\\n',\n",
              " '1.10 Give two reasons why caches are useful. What problems do they solve? What problems do they cause? If a cache can be made as large as the device for which it is caching (for instance, a cache as large as a disk), why not make it that large and eliminate the device?\\n',\n",
              " '1.17 Consider a computing cluster consisting of two nodes running a database. Describe two ways in which the cluster software can manage access to the data on the disk. Discuss the benefits and disadvantages of each.\\n',\n",
              " 'c. The CPU is allowed to execute other programs while the DMA controller is transferring data. Does this process interfere with the execution of the user programs? If so, describe what forms of interference are caused.\\n',\n",
              " '1.21 Some computer systems do not provide a privileged mode of operation in hardware. Is it possible to construct a secure operating system for these computer systems? Give arguments both that it is and that it is not possible.\\n',\n",
              " '1.22 Many SMP systems have different levels of caches; one level is local to each processing core, and another level is shared among all processing cores. Why are caching systems designed this way?\\n',\n",
              " '    [Russinovich and Solomon (2009)] give an overview of Microsoft Windows and covers considerable technical detail about the system internals and components. [McDougall and Mauro (2007)] cover the internals of the Solaris operating system. Mac OS X internals are discussed in [Singh (2007)]. [Love (2010)] provides an overview of the Linux operating system and great detail about data structures used in the Linux kernel.\\n',\n",
              " '   Many general textbooks  cover operating systems, including [Stallings (2011)], [Deitel et al. (2004)], and [Tanenbaum (2007)]. [Kurose and Ross (2013)] provides a general overview of computer networks, including a discussion of client-server and peer-to-peer systems. [Tarkoma and Lagerspetz (2011)] examines several different mobile operating systems, including Android and iOS.\\n',\n",
              " '   [Hennessy and Patterson (2012)] provide coverage of I/O systems and buses and of system architecture in general. [Bryant and OHallaron (2010)] provide a thorough overview of a computer system from the perspective of a computer programmer. Details of the Intel 64 instruction set and privilege modes can be found in [Intel (2011)].\\n',\n",
              " '   The history of open sourcing and its benefits and challenges appears in [Raymond (1999)]. The Free Software Foundation has published its philosophy in  http://www.gnu.org/philosophy/free-software-for-freedom.html.  The  open source of Mac OS X are available from http://www.apple.com/opensource/.\\n',\n",
              " 'An operating system provides the environment within which programs are executed. Internally, operating systems vary greatly in their makeup, since they are organized along many different lines. The design of a new operating system is a major task. It is important that the goals of the system be well defined before the design begins. These goals form the basis for choices among various algorithms and strategies.\\n',\n",
              " '   We can view an operating system from several vantage points. One view focuses on the services that the system provides; another, on the interface that it makes available to users and programmers; a third, on its components and their interconnections. In this chapter, we explore all three aspects of operating systems, showing the viewpoints of users, programmers, and operating system designers. We consider what services an operating system provides, how they are provided, how they are debugged, and what the various methodologies are for designing such systems. Finally, we describe how operating systems are created and how a computer starts its operating system.\\n',\n",
              " 'An operating system provides an environment for the execution of programs. It provides certain services to programs and to the users of those programs. The specific services provided, of course, differ from one operating system to another, but we can identify common classes. These operating system services are provided for the convenience of the programmer, to make the programming\\n',\n",
              " ' User interface. Almost all operating systems have a user interface (UI). This interface can take several forms. One is a command-line interface (CLI), which uses text commands and a method for entering them (say, a keyboard for typing in commands in a specific format with specific options). Another is a batch interface, in which commands and directives to control those commands are entered into files, and those files are executed. Most commonly, a graphical user interface (GUI) is used. Here, the interface is a window system with a pointing device to direct I/O, choose from menus, and make selections and a keyboard to enter text. Some systems provide two or all three of these variations.\\n',\n",
              " ' Program execution. The system must be able to load a program into memory and to run that program. The program must be able to end its execution, either normally or abnormally (indicating error).\\n',\n",
              " ' I/O operations.A running program may require I/O, which may involve a file or an I/O device. For specific devices, special functions may be desired (such as recording to a CD or DVD drive or blanking a display screen). For efficiency and protection, users usually cannot control I/O devices directly. Therefore, the operating system must provide a means to do I/O.\\n',\n",
              " ' File-system manipulation. The file system is of particular interest. Obvi- ously, programs need to read and write files and directories. They also need to create and delete them by name, search for a given file, and list file information. Finally, some operating systems include permissions management to allow or deny access to files or directories based on file ownership. Many operating systems provide a variety of file systems, sometimes to allow personal choice and sometimes to provide specific features or performance characteristics.\\n',\n",
              " ' Communications. There are many circumstances in which one process needs to exchange information with another process. Such communication may occur between processes that are executing on the same computer or between processes that are executing on different computer systems tied together by a computer network. Communications may be implemented via shared memory, in which two or more processes read and write to a shared section of memory, or message passing, in which packets of information in predefined formats are moved between processes by the operating system.\\n',\n",
              " ' Error detection. The operating system needs to be detecting and correcting errors constantly. Errors may occur in the CPU and memory hardware (such as a memory error or a power failure), in I/O devices (such as a parity error on disk, a connection failure on a network, or lack of paper in the printer), and in the user program (such as an arithmetic overflow, an attempt to access an illegal memory location, or a too-great use of CPU time). For each type of error, the operating system should take the appropriate action to ensure correct and consistent computing. Sometimes, it has no choice but to halt the system. At other times, it might terminate an error-causing process or return an error code to a process for the process to detect and possibly correct.\\n',\n",
              " '   Another set of operating system functions exists not for helping the user but rather for ensuring the efficient operation of the system itself. Systems with multiple users can gain efficiency by sharing the computer resources among the users.\\n',\n",
              " ' Resource allocation. When there are multiple users or multiple jobs running at the same time, resources must be allocated to each of them. The operating system manages many different types of resources. Some (such as CPU cycles, main memory, and file storage) may have special allocation code, whereas others (such as I/O devices) may have much more general request and release code. For instance, in determining how best to use the CPU, operating systems have CPU-scheduling routines that take into account the speed of the CPU, the jobs that must be executed, the number of registers available, and other factors. There may also be routines to allocate printers, USB storage drives, and other peripheral devices.\\n',\n",
              " ' Accounting. We want to keep track of which users use how much and what kinds of computer resources. This record keeping may be used for accounting (so that users can be billed) or simply for accumulating usage statistics. Usage statistics may be a valuable tool for researchers who wish to reconfigure the system to improve computing services.\\n',\n",
              " ' Protection and security. The owners of information stored in a multiuser or networked computer system may want to control use of that information. When several separate processes execute concurrently, it should not be possible for one process to interfere with the others or with the operating system itself. Protection involves ensuring that all access to system resources is controlled. Security of the system from outsiders is also important. Such security starts with requiring each user to authenticate\\n',\n",
              " 'himself or herself to the system, usually by means of a password, to gain access to system resources. It extends to defending external I/O devices, including network adapters, from invalid access attempts and to recording all such connections for detection of break-ins. If a system is to be protected and secure, precautions must be instituted throughout it. A chain is only as strong as its weakest link.\\n',\n",
              " 'We mentioned earlier that there are several ways for users to interface with the operating system. Here, we discuss two fundamental approaches. One provides a command-line interface, or command interpreter, that allows users to directly enter commands to be performed by the operating system. The other allows users to interface with the operating system via a graphical user interface, or GUI.\\n',\n",
              " 'Some operating systems include the command interpreter in the kernel. Others, such as Windows and UNIX, treat the command interpreter as a special program that is running when a job is initiated or when a user first logs on (on interactive systems). On systems with multiple command interpreters to choose from, the interpreters are known as shells. For example, on UNIX and Linux systems, a user may choose among several different shells, including the Bourne shell, C shell, Bourne-Again shell, Korn shell, and others. Third-party shells and free user-written shells are also available. Most shells provide similar functionality, and a users choice of which shell to use is generally based on personal preference. Figure 2.2 shows the Bourne shell command interpreter being used on Solaris 10.\\n',\n",
              " '    The main function of the command interpreter is to get and execute the next user-specified command. Many of the commands given at this level manipulate files: create, delete, list, print, copy, execute, and so on. The MS-DOS and UNIX shells operate in this way. These commands can be implemented in two general ways.\\n',\n",
              " '   In one approach, the command interpreter itself contains the code to execute the command. For example, a command to delete a file may cause the command interpreter to jump to a section of its code that sets up the parameters and makes the appropriate system call. In this case, the number of commands that can be given determines the size of the command interpreter, since each command requires its own implementing code.\\n',\n",
              " 'implements most commands through system programs. In this case, the command interpreter does not understand the command in any way; it merely uses the command to identify a file to be loaded into memory and executed.\\n',\n",
              " 'be defined completely by the code in the file rm. In this way, programmers can add new commands to the system easily by creating new files with the proper names. The command-interpreter program, which can be small, does not have to be changed for new commands to be added.\\n',\n",
              " 'A second strategy for interfacing with the operating system is through a user- friendly graphical user interface, or GUI. Here, rather than entering commands directly via a command-line interface, users employ a mouse-based window- and-menu system characterized by a desktop metaphor. The user moves the mouse to position its pointer on images, or icons, on the screen (the desktop) that represent programs, files, directories, and system functions. Depending on the mouse pointers location, clicking a button on the mouse can invoke a program, select a file or directory known as a folder  or pull down a menu that contains commands.\\n',\n",
              " '    Graphical user interfaces first appeared due in part to research taking place in the early 1970s at Xerox PARC research facility. The first GUI appeared on the Xerox Alto computer in 1973. However, graphical interfaces became more widespread with the advent of Apple Macintosh computers in the 1980s. The user interface for the Macintosh operating system (Mac OS) has undergone various changes over the years, the most significant being the adoption of the Aqua interface that appeared with Mac OS X. Microsofts first version of Windows Version 1.0  was based on the addition of a GUI interface to the MS-DOS operating system. Later versions of Windows have made cosmetic\\n',\n",
              " '   Because a mouse is impractical for most mobile systems, smartphones and handheld tablet computers typically use a touchscreen interface. Here, users interact by making gestures on the touchscreen for example, pressing and swiping fingers across the screen. Figure 2.3 illustrates the touchscreen of the Apple iPad. Whereas earlier smartphones included a physical keyboard, most smartphones now simulate a keyboard on the touchscreen.\\n',\n",
              " '   Traditionally, UNIX systems have been dominated by command-line inter- faces. Various GUI interfaces are available, however. These include the Common Desktop Environment (CDE) and X-Windows systems, which are common on commercial versions of UNIX, such as Solaris and IBMs AIX system. In addition, there has been significant development in GUI designs from various open-source projects, such as K Desktop Environment (or KDE) and the GNOME desktop by the GNU project. Both the KDE and GNOME desktops run on Linux and various UNIX systems and are available under open-source licenses, which means their source code is readily available for reading and for modification under specific license terms.\\n',\n",
              " 'The choice of whether to use a command-line or GUI interface is mostly one of personal preference. System administrators who manage computers and power users who have deep knowledge of a system frequently use the command-line interface. For them, it is more efficient, giving them faster access to the activities they need to perform. Indeed, on some systems, only a subset of system functions is available via the GUI, leaving the less common tasks to those who are command-line knowledgeable. Further, command- line interfaces usually make repetitive tasks easier, in part because they have their own programmability. For example, if a frequent task requires a set of command-line steps, those steps can be recorded into a file, and that file can be run just like a program. The program is not compiled into executable code but rather is interpreted by the command-line interface. These shell scripts are very common on systems that are command-line oriented, such as UNIX and Linux.\\n',\n",
              " '   In contrast, most Windows users are happy to use the Windows GUI environment and almost never use the MS-DOS shell interface. The various changes undergone by the Macintosh operating systems provide a nice study in contrast. Historically, Mac OS has not provided a command-line interface, always requiring its users to interface with the operating system using its GUI. However, with the release of Mac OS X (which is in part implemented using a UNIX kernel), the operating system now provides both a Aqua interface and a command-line interface. Figure 2.4 is a screenshot of the Mac OS X GUI.\\n',\n",
              " '   The user interface can vary from system to system and even from user to user within a system. It typically is substantially removed from the actual system structure. The design of a useful and friendly user interface is therefore not a direct function of the operating system. In this book, we concentrate on the fundamental problems of providing adequate service to user programs. From the point of view of the operating system, we do not distinguish between user programs and system programs.\\n',\n",
              " 'System calls provide an interface to the services made available by an operating system. These calls are generally available as routines written in C and C++, although certain low-level tasks (for example, tasks where hardware must be accessed directly) may have to be written using assembly-language instructions.\\n',\n",
              " '   Before we discuss how an operating system makes system calls available, lets first use an example to illustrate how system calls are used: writing a simple program to read data from one file and copy them to another file. The first input that the program will need is the names of the two files: the input file and the output file. These names can be specified in many ways, depending on the operating-system design. One approach is for the program to ask the user for the names. In an interactive system, this approach will require a sequence of system calls, first to write a prompting message on the screen and then to read from the keyboard the characters that define the two files. On mouse-based and icon-based systems, a menu of file names is usually displayed in a window. The user can then use the mouse to select the source name, and a window can be opened for the destination name to be specified. This sequence requires many I/O system calls.\\n',\n",
              " '   Once the two file names have been obtained, the program must open the input file and create the output file. Each of these operations requires another system call. Possible error conditions for each operation can require additional system calls. When the program tries to open the input file, for example, it may find that there is no file of that name or that the file is protected against access. In these cases, the program should print a message on the console (another sequence of system calls) and then terminate abnormally (another system call). If the input file exists, then we must create a new output file. We may find that there is already an output file with the same name. This situation may cause the program to abort (a system call), or we may delete the existing file (another system call) and create a new one (yet another system call). Another option, in an interactive system, is to ask the user (via a sequence of system calls to output the prompting message and to read the response from the terminal) whether to replace the existing file or to abort the program.\\n',\n",
              " '   When both files are set up, we enter a loop that reads from the input file (a system call) and writes to the output file (another system call). Each read and write must return status information regarding various possible error conditions. On input, the program may find that the end of the file has been reached or that there was a hardware failure in the read (such as a parity error). The write operation may encounter various errors, depending on the output device (for example, no more disk space).\\n',\n",
              " '   Finally, after the entire file is copied, the program may close both files (another system call), write a message to the console or window (more system calls), and finally terminate normally (the final system call). This system-call sequence is shown in Figure 2.5.\\n',\n",
              " '   As you can see, even simple programs may make heavy use of the operating system. Frequently, systems execute thousands of system calls per second. Most programmers never see this level of detail, however. Typically, application developers design programs according to an application programming interface (API). The API specifies a set of functions that are available to an application programmer, including the parameters that are passed to each function and the return values the programmer can expect. Three of the most common APIs available to application programmers are the Windows API for Windows systems, the POSIX API for POSIX-based systems (which include virtually all versions of UNIX, Linux, and Mac OS X), and the Java API for programs that run on the Java virtual machine. A programmer accesses an API via a library of code provided by the operating system. In the case of UNIX and Linux for programs written in the C language, the library is called libc. Note that unless specified the system-call names used throughout this text are generic examples. Each operating system has its own name for each system call.\\n',\n",
              " '   Behind the scenes, the functions that make up an API typically invoke the actual system calls on behalf of the application programmer. For example, the Windows function CreateProcess() (which unsurprisingly is used to create a new process) actually invokes the NTCreateProcess() system call in the Windows kernel.\\n',\n",
              " '   Why would an application programmer prefer programming according to an API rather than invoking actual system calls? There are several reasons for doing so. One benefit concerns program portability. An application program-\\n',\n",
              " 'mer designing a program using an API can expect her program to compile and run on any system that supports the same API (although, in reality, architectural differences often make this more difficult than it may appear). Furthermore, actual system calls can often be more detailed and difficult to work with than the API available to an application programmer. Nevertheless, there often exists a strong correlation between a function in the API and its associated system call within the kernel. In fact, many of the POSIX and Windows APIs are similar to the native system calls provided by the UNIX, Linux, and Windows operating systems.\\n',\n",
              " '   For most programming languages, the run-time support system (a set of functions built into libraries included with a compiler) provides a system- call interface that serves as the link to system calls made available by the operating system. The system-call interface intercepts function calls in the API and invokes the necessary system calls within the operating system. Typically, a number is associated with each system call, and the system-call interface maintains a table indexed according to these numbers. The system call interface\\n',\n",
              " '   The caller need know nothing about how the system call is implemented or what it does during execution. Rather, the caller need only obey the API and understand what the operating system will do as a result of the execution of that system call. Thus, most of the details of the operating-system interface are hidden from the programmer by the API and are managed by the run-time support library. The relationship between an API, the system-call interface, and the operating system is shown in Figure 2.6, which illustrates how the operating system handles a user application invoking the open() system call. System calls occur in different ways, depending on the computer in use.\\n',\n",
              " 'Often, more information is required than simply the identity of the desired system call. The exact type and amount of information vary according to the particular operating system and call. For example, to get input, we may need to specify the file or device to use as the source, as well as the address and length of the memory buffer into which the input should be read. Of course, the device or file and length may be implicit in the call.\\n',\n",
              " '    Three general methods are used to pass parameters to the operating system. The simplest approach is to pass the parameters in registers. In some cases, however, there may be more parameters than registers. In these cases, the parameters are generally stored in a block, or table, in memory, and the address of the block is passed as a parameter in a register (Figure 2.7). This is the approach taken by Linux and Solaris. Parameters also can be placed, or pushed, onto the stack by the program and popped off the stack by the operating system. Some operating systems prefer the block or stack method because those approaches do not limit the number or length of parameters being passed.\\n',\n",
              " 'System calls can be grouped roughly into six major categories: process control, file manipulation, device manipulation, information maintenance, communications, and protection. In Sections 2.4.1 through 2.4.6, we briefly discuss the types of system calls that may be provided by an operating system. Most of these system calls support, or are supported by, concepts and functions that are discussed in later chapters. Figure 2.8 summarizes the types of system calls normally provided by an operating system. As mentioned, in this text, we normally refer to the system calls by generic names. Throughout the text, however, we provide examples of the actual counterparts to the system calls for Windows, UNIX, and Linux systems.\\n',\n",
              " 'A running program needs to be able to halt its execution either normally (end()) or abnormally (abort()). If a system call is made to terminate the currently running program abnormally, or if the program runs into a problem and causes an error trap, a dump of memory is sometimes taken and an error message generated. The dump is written to disk and may be examined by a debugger a system program designed to aid the programmer in finding and correcting errors, or bugs to determine the cause of the problem. Under either normal or abnormal circumstances, the operating system must transfer control to the invoking command interpreter. The command interpreter then reads the next command. In an interactive system, the command interpreter simply continues with the next command; it is assumed that the user will issue an appropriate command to respond to any error. In a GUI system, a pop-up window might alert the user to the error and ask for guidance. In a batch system, the command interpreter usually terminates the entire job and continues with the next job. Some systems may allow for special recovery actions in case an error occurs. If the program discovers an error in its input and wants to terminate abnormally, it may also want to define an error level. More severe errors can be indicated by a higher-level error parameter. It is then\\n',\n",
              " 'possible to combine normal and abnormal termination by defining a normal termination as an error at level 0. The command interpreter or a following program can use this error level to determine the next action automatically.\\n',\n",
              " '   A process or job executing one program may want to load() and execute() another program. This feature allows the command interpreter to execute a program as directed by, for example, a user command, the click of a\\n',\n",
              " 'mouse, or a batch command. An interesting question is where to return control when the loaded program terminates. This question is related to whether the existing program is lost, saved, or allowed to continue execution concurrently with the new program.\\n',\n",
              " '   If control returns to the existing program when the new program termi- nates, we must save the memory image of the existing program; thus, we have effectively created a mechanism for one program to call another program. If both programs continue concurrently, we have created a new job or process to be multiprogrammed. Often, there is a system call specifically for this purpose (create process() or submit job()).\\n',\n",
              " '   If we create a new job or process, or perhaps even a set of jobs or processes, we should be able to control its execution. This control requires the ability to determine and reset the attributes of a job or process, includ- ing the jobs priority, its maximum allowable execution time, and so on (get process attributes() and set process attributes()). We may also want to terminate a job or process that we created (terminate process()) if we find that it is incorrect or is no longer needed.\\n',\n",
              " '   Having created new jobs or processes, we may need to wait for them to finish their execution. We may want to wait for a certain amount of time to pass (wait time()). More probably, we will want to wait for a specific event to occur (wait event()). The jobs or processes should then signal when that event has occurred (signal event()).\\n',\n",
              " '   Quite often, two or more processes may share data. To ensure the integrity of the data being shared, operating systems often provide system calls allowing a process to lock shared data. Then, no other process can access the data until the lock is released. Typically, such system calls include acquire lock() and release lock(). System calls of these types, dealing with the coordination of concurrent processes, are discussed in great detail in Chapter 5.\\n',\n",
              " '   There are so many facets of and variations in process and job control that we next use two examples one involving a single-tasking system and the other a multitasking system to clarify these concepts. The MS-DOS operating system is an example of a single-tasking system. It has a command interpreter that is invoked when the computer is started (Figure 2.9(a)). Because MS-DOS is single-tasking, it uses a simple method to run a program and does not create a new process. It loads the program into memory, writing over most of itself to\\n',\n",
              " 'give the program as much memory as possible (Figure 2.9(b)). Next, it sets the instruction pointer to the first instruction of the program. The program then runs, and either an error causes a trap, or the program executes a system call to terminate. In either case, the error code is saved in the system memory for later use. Following this action, the small portion of the command interpreter that was not overwritten resumes execution. Its first task is to reload the rest of the command interpreter from disk. Then the command interpreter makes the previous error code available to the user or to the next program.\\n',\n",
              " '    FreeBSD (derived from Berkeley UNIX) is an example of a multitasking system. When a user logs on to the system, the shell of the users choice is run. This shell is similar to the MS-DOS shell in that it accepts commands and executes programs that the user requests. However, since FreeBSD is a multitasking system, the command interpreter may continue running while another program is executed (Figure 2.10). To start a new process, the shell\\n',\n",
              " 'executes a fork() system call. Then, the selected program is loaded into memory via an exec() system call, and the program is executed. Depending on the way the command was issued, the shell then either waits for the process to finish or runs the process in the background. In the latter case, the shell immediately requests another command. When a process is running in the background, it cannot receive input directly from the keyboard, because the shell is using this resource. I/O is therefore done through files or through a GUI interface. Meanwhile, the user is free to ask the shell to run other programs, to monitor the progress of the running process, to change that programs priority, and so on. When the process is done, it executes an exit() system call to terminate, returning to the invoking process a status code of 0 or a nonzero error code. This status or error code is then available to the shell or other programs. Processes are discussed in Chapter 3 with a program example using the fork() and exec() system calls.\\n',\n",
              " '   We first need to be able to create() and delete() files. Either system call requires the name of the file and perhaps some of the files attributes. Once the file is created, we need to open() it and to use it. We may also read(), write(), or reposition() (rewind or skip to the end of the file, for example). Finally, we need to close() the file, indicating that we are no longer using it. We may need these same sets of operations for directories if we have a directory structure for organizing files in the file system. In addition, for either files or directories, we need to be able to determine the values of various attributes and perhaps to reset them if necessary. File attributes include the file name, file type, protection codes, accounting information, and so on. At least two system calls, get file attributes() and set file attributes(), are required for this function. Some operating systems provide many more calls, such as calls for file move() and copy(). Others might provide an API that performs those operations using code and other system calls, and others might provide system programs to perform those tasks. If the system programs are callable by other programs, then each can be considered an API by other system\\n',\n",
              " 'A process may need several resources to execute main memory, disk drives, access to files, and so on. If the resources are available, they can be granted, and control can be returned to the user process. Otherwise, the process will have to wait until sufficient resources are available.\\n',\n",
              " '   The various resources controlled by the operating system can be thought of as devices. Some of these devices are physical devices (for example, disk drives), while others can be thought of as abstract or virtual devices (for example, files). A system with multiple users may require us to first request() a device, to ensure exclusive use of it. After we are finished with the device, we release() it. These functions are similar to the open() and close() system calls for files. Other operating systems allow unmanaged access to devices.\\n',\n",
              " '   Once the device has been requested (and allocated to us), we can read(), write(), and (possibly) reposition() the device, just as we can with files. In fact, the similarity between I/O devices and files is so great that many operating systems, including UNIX, merge the two into a combined file device structure. In this case, a set of system calls is used on both files and devices. Sometimes, I/O devices are identified by special file names, directory placement, or file attributes.\\n',\n",
              " '    The user interface can also make files and devices appear to be similar, even though the underlying system calls are dissimilar. This is another example of the many design decisions that go into building an operating system and user interface.\\n',\n",
              " 'Many system calls exist simply for the purpose of transferring information between the user program and the operating system. For example, most systems have a system call to return the current time() and date(). Other system calls may return information about the system, such as the number of current users, the version number of the operating system, the amount of free memory or disk space, and so on.\\n',\n",
              " '   Another set of system calls is helpful in debugging a program. Many systems provide system calls to dump() memory. This provision is useful for debugging. A program trace lists each system call as it is executed. Even microprocessors provide a CPU mode known as single step, in which a trap is executed by the CPU after every instruction. The trap is usually caught by a debugger.\\n',\n",
              " '   Many operating systems provide a time profile of a program to indicate the amount of time that the program executes at a particular location or set of locations. A time profile requires either a tracing facility or regular timer interrupts. At every occurrence of the timer interrupt, the value of the program counter is recorded. With sufficiently frequent timer interrupts, a statistical picture of the time spent on various parts of the program can be obtained.\\n',\n",
              " '   In addition, the operating system keeps information about all its processes, and system calls are used to access this information. Generally, calls are also used to reset the process information (get process attributes() and set process attributes()). In Section 3.1.3, we discuss what information is normally kept.\\n',\n",
              " 'There are two common models of interprocess communication: the message- passing model and the shared-memory model. In the message-passing model, the communicating processes exchange messages with one another to transfer information. Messages can be exchanged between the processes either directly or indirectly through a common mailbox. Before communication can take place, a connection must be opened. The name of the other communicator must be known, be it another process on the same system or a process on another computer connected by a communications network. Each computer in a network has a host name by which it is commonly known. A host also has a\\n',\n",
              " 'network identifier, such as an IP address. Similarly, each process has a process name, and this name is translated into an identifier by which the operating system can refer to the process. The get hostid() and get processid() system calls do this translation. The identifiers are then passed to the general- purpose open() and close() calls provided by the file system or to specific open connection() and close connection() system calls, depending on the systems model of communication. The recipient process usually must give its permission for communication to take place with an accept connection() call. Most processes that will be receiving connections are special-purpose daemons, which are system programs provided for that purpose. They execute a wait for connection() call and are awakened when a connection is made. The source of the communication, known as the client, and the receiving daemon, known as a server, then exchange messages by using read message() and write message() system calls. The close connection() call terminates the communication.\\n',\n",
              " '   In the shared-memory model, processes use shared memory create() and shared memory attach() system calls to create and gain access to regions of memory owned by other processes. Recall that, normally, the operating system tries to prevent one process from accessing another processs memory. Shared memory requires that two or more processes agree to remove this restriction. They can then exchange information by reading and writing data in the shared areas. The form of the data is determined by the processes and is not under the operating systems control. The processes are also responsible for ensuring that they are not writing to the same location simultaneously. Such mechanisms are discussed in Chapter 5. In Chapter 4, we look at a variation of the process scheme threads in which memory is shared by default.\\n',\n",
              " '   Both of the models just discussed are common in operating systems, and most systems implement both. Message passing is useful for exchanging smaller amounts of data, because no conflicts need be avoided. It is also easier to implement than is shared memory for intercomputer communication. Shared memory allows maximum speed and convenience of communication, since it can be done at memory transfer speeds when it takes place within a computer. Problems exist, however, in the areas of protection and synchronization between the processes sharing memory.\\n',\n",
              " 'Protection provides a mechanism for controlling access to the resources provided by a computer system. Historically, protection was a concern only on multiprogrammed computer systems with several users. However, with the advent of networking and the Internet, all computer systems, from servers to mobile handheld devices, must be concerned with protection.\\n',\n",
              " '   Typically, system calls providing protection include set permission() and get permission(), which manipulate the permission settings of resources such as files and disks. The allow user() and deny user() system calls specify whether particular users can or cannot be allowed access to certain resources.\\n',\n",
              " 'Another aspect of a modern system is its collection of system programs. Recall Figure 1.1, which depicted the logical computer hierarchy. At the lowest level is hardware. Next is the operating system, then the system programs, and finally the application programs. System programs, also known as system utilities, provide a convenient environment for program development and execution. Some of them are simply user interfaces to system calls. Others are considerably more complex. They can be divided into these categories:\\n',\n",
              " ' Status information. Some programs simply ask the system for the date, time, amount of available memory or disk space, number of users, or similar status information. Others are more complex, providing detailed performance, logging, and debugging information. Typically, these pro- grams format and print the output to the terminal or other output devices or files or display it in a window of the GUI. Some systems also support a registry, which is used to store and retrieve configuration information.\\n',\n",
              " ' File modification. Several text editors may be available to create and modify the content of files stored on disk or other storage devices. There may also be special commands to search contents of files or perform transformations of the text.\\n',\n",
              " ' Programming-language support. Compilers, assemblers, debuggers, and interpreters for common programming languages (such as C, C++, Java, and PERL) are often provided with the operating system or available as a separate download.\\n',\n",
              " ' Program loading and execution. Once a program is assembled or com- piled, it must be loaded into memory to be executed. The system may provide absolute loaders, relocatable loaders, linkage editors, and overlay loaders. Debugging systems for either higher-level languages or machine language are needed as well.\\n',\n",
              " ' Communications. These programs provide the mechanism for creating virtual connections among processes, users, and computer systems. They allow users to send messages to one anothers screens, to browse Web pages, to send e-mail messages, to log in remotely, or to transfer files from one machine to another.\\n',\n",
              " ' Background services. All general-purpose systems have methods for launching certain system-program processes at boot time. Some of these processes terminate after completing their tasks, while others continue to run until the system is halted. Constantly running system-program processes are known as services, subsystems, or daemons. One example is the network daemon discussed in Section 2.4.5. In that example, a system needed a service to listen for network connections in order to connect those requests to the correct processes. Other examples include process schedulers that start processes according to a specified schedule, system error monitoring services, and print servers. Typical systems have dozens\\n',\n",
              " '   Along with system programs, most operating systems are supplied with programs that are useful in solving common problems or performing common operations. Such application programs include Web browsers, word proces- sors and text formatters, spreadsheets, database systems, compilers, plotting and statistical-analysis packages, and games.\\n',\n",
              " '   The view of the operating system seen by most users is defined by the application and system programs, rather than by the actual system calls. Consider a users PC. When a users computer is running the Mac OS X operating system, the user might see the GUI, featuring a mouse-and-windows interface. Alternatively, or even in one of the windows, the user might have a command-line UNIX shell. Both use the same set of system calls, but the system calls look different and act in different ways. Further confusing the user view, consider the user dual-booting from Mac OS X into Windows. Now the same user on the same hardware has two entirely different interfaces and two sets of applications using the same physical resources. On the same hardware, then, a user can be exposed to multiple user interfaces sequentially or concurrently.\\n',\n",
              " 'In this section, we discuss problems we face in designing and implementing an operating system. There are, of course, no complete solutions to such problems, but there are approaches that have proved successful.\\n',\n",
              " 'The first problem in designing a system is to define goals and specifications. At the highest level, the design of the system will be affected by the choice of hardware and the type of system: batch, time sharing, single user, multiuser, distributed, real time, or general purpose.\\n',\n",
              " '   Users want certain obvious properties in a system. The system should be convenient to use, easy to learn and to use, reliable, safe, and fast. Of course, these specifications are not particularly useful in the system design, since there is no general agreement on how to achieve them.\\n',\n",
              " '   A similar set of requirements can be defined by those people who must design, create, maintain, and operate the system. The system should be easy to design, implement, and maintain; and it should be flexible, reliable, error free, and efficient. Again, these requirements are vague and may be interpreted in various ways.\\n',\n",
              " '   There is, in short, no unique solution to the problem of defining the requirements for an operating system. The wide range of systems in existence shows that different requirements can result in a large variety of solutions for different environments. For example, the requirements for VxWorks, a real-\\n',\n",
              " '   Specifying and designing an operating system is a highly creative task. Although no textbook can tell you how to do it, general principles have been developed in the field of software engineering, and we turn now to a discussion of some of these principles.\\n',\n",
              " 'One important principle is the separation of policy from mechanism. Mecha- nisms determine how to do something; policies determine what will be done. For example, the timer construct (see Section 1.5.2) is a mechanism for ensuring CPU protection, but deciding how long the timer is to be set for a particular user is a policy decision.\\n',\n",
              " '    The separation of policy and mechanism is important for flexibility. Policies are likely to change across places or over time. In the worst case, each change in policy would require a change in the underlying mechanism. A general mechanism insensitive to changes in policy would be more desirable. A change in policy would then require redefinition of only certain parameters of the system. For instance, consider a mechanism for giving priority to certain types of programs over others. If the mechanism is properly separated from policy, it can be used either to support a policy decision that I/O-intensive programs should have priority over CPU-intensive ones or to support the opposite policy. Microkernel-based operating systems (Section 2.7.3) take the separation of mechanism and policy to one extreme by implementing a basic set of primitive building blocks. These blocks are almost policy free, allowing more advanced mechanisms and policies to be added via user-created kernel modules or user programs themselves. As an example, consider the history of UNIX. At first, it had a time-sharing scheduler. In the latest version of Solaris, scheduling is controlled by loadable tables. Depending on the table currently loaded, the system can be time sharing, batch processing, real time, fair share, or any combination. Making the scheduling mechanism general purpose allows vast policy changes to be made with a single load-new-table command. At the other extreme is a system such as Windows, in which both mechanism and policy are encoded in the system to enforce a global look and feel. All applications have similar interfaces, because the interface itself is built into the kernel and system libraries. The Mac OS X operating system has similar\\n',\n",
              " '   Policy decisions are important for all resource allocation. Whenever it is necessary to decide whether or not to allocate a resource, a policy decision must be made. Whenever the question is how rather than what, it is a mechanism that must be determined.\\n',\n",
              " 'Once an operating system is designed, it must be implemented. Because operating systems are collections of many programs, written by many people over a long period of time, it is difficult to make general statements about how they are implemented.\\n',\n",
              " '    Early operating systems were written in assembly language. Now, although some operating systems are still written in assembly language, most are written in a higher-level language such as C or an even higher-level language such as C++. Actually, an operating system can be written in more than one language. The lowest levels of the kernel might be assembly language. Higher-level routines might be in C, and system programs might be in C or C++, in interpreted scripting languages like PERL or Python, or in shell scripts. In fact, a given Linux distribution probably includes programs written in all of those languages.\\n',\n",
              " '   The first system that was not written in assembly language was probably the Master Control Program (MCP) for Burroughs computers. MCP was written in a variant of ALGOL. MULTICS, developed at MIT, was written mainly in the system programming language PL/1. The Linux and Windows operating system kernels are written mostly in C, although there are some small sections of assembly code for device drivers and for saving and restoring the state of registers.\\n',\n",
              " '   The advantages of using a higher-level language, or at least a systems- implementation language, for implementing operating systems are the same as those gained when the language is used for application programs: the code can be written faster, is more compact, and is easier to understand and debug. In addition, improvements in compiler technology will improve the generated code for the entire operating system by simple recompilation. Finally, an operating system is far easier to port to move to some other hardware if it is written in a higher-level language. For example, MS-DOS was written in Intel 8088 assembly language. Consequently, it runs natively only on the Intel X86 family of CPUs. (Note that although MS-DOS runs natively only on Intel X86, emulators of the X86 instruction set allow the operating system to run on other CPUs but more slowly, and with higher resource use. As we mentioned in Chapter 1, emulators are programs that duplicate the functionality of one system on another system.) The Linux operating system, in contrast, is written mostly in C and is available natively on a number of different CPUs, including Intel X86, Oracle SPARC, and IBMPowerPC.\\n',\n",
              " '    The only possible disadvantages of implementing an operating system in a higher-level language are reduced speed and increased storage requirements. This, however, is no longer a major issue in todays systems. Although an expert assembly-language programmer can produce efficient small routines, for large programs a modern compiler can perform complex analysis and apply sophisticated optimizations that produce excellent code. Modern processors have deep pipelining and multiple functional units that can handle the details of complex dependencies much more easily than can the human mind.\\n',\n",
              " '   As is true in other systems, major performance improvements in oper- ating systems are more likely to be the result of better data structures and algorithms than of excellent assembly-language code. In addition, although operating systems are large, only a small amount of the code is critical to high performance; the interrupt handler, I/O manager, memory manager, and CPU scheduler are probably the most critical routines. After the system is written and is working correctly, bottleneck routines can be identified and can be replaced with assembly-language equivalents.\\n',\n",
              " 'A system as large and complex as a modern operating system must be engineered carefully if it is to function properly and be modified easily. A common approach is to partition the task into small components, or modules, rather than have one monolithic system. Each of these modules should be a well-defined portion of the system, with carefully defined inputs, outputs, and functions. We have already discussed briefly in Chapter 1 the common components of operating systems. In this section, we discuss how these components are interconnected and melded into a kernel.\\n',\n",
              " 'Many operating systems do not have well-defined structures. Frequently, such systems started as small, simple, and limited systems and then grew beyond their original scope. MS-DOS is an example of such a system. It was originally designed and implemented by a few people who had no idea that it would become so popular. It was written to provide the most functionality in the least space, so it was not carefully divided into modules. Figure 2.11 shows its structure.\\n',\n",
              " '   In MS-DOS, the interfaces and levels of functionality are not well separated. For instance, application programs are able to access the basic I/O routines to write directly to the display and disk drives. Such freedom leaves MS-DOS vulnerable to errant (or malicious) programs, causing entire system crashes when user programs fail. Of course, MS-DOS was also limited by the hardware of its era. Because the Intel 8088 for which it was written provides no dual mode and no hardware protection, the designers of MS-DOS had no choice but to leave the base hardware accessible.\\n',\n",
              " '   Another example of limited structuring is the original UNIX operating system. Like MS-DOS, UNIX initially was limited by hardware functionality. It consists of two separable parts: the kernel and the system programs. The kernel\\n',\n",
              " 'is further separated into a series of interfaces and device drivers, which have been added and expanded over the years as UNIX has evolved. We can view the traditional UNIX operating system as being layered to some extent, as shown in Figure 2.12. Everything below the system-call interface and above the physical hardware is the kernel. The kernel provides the file system, CPU scheduling, memory management, and other operating-system functions through system calls. Taken in sum, that is an enormous amount of functionality to be combined into one level. This monolithic structure was difficult to implement and maintain. It had a distinct performance advantage, however: there is very little overhead in the system call interface or in communication within the kernel. We still see evidence of this simple, monolithic structure in the UNIX, Linux, and Windows operating systems.\\n',\n",
              " 'With proper hardware support, operating systems can be broken into pieces that are smaller and more appropriate than those allowed by the original MS-DOS and UNIX systems. The operating system can then retain much greater control over the computer and over the applications that make use of that computer. Implementers have more freedom in changing the inner workings of the system and in creating modular operating systems. Under a top- down approach, the overall functionality and features are determined and are separated into components. Information hiding is also important, because it leaves programmers free to implement the low-level routines as they see fit, provided that the external interface of the routine stays unchanged and that the routine itself performs the advertised task.\\n',\n",
              " '   A system can be made modular in many ways. One method is the layered approach, in which the operating system is broken into a number of layers (levels). The bottom layer (layer 0) is the hardware; the highest (layer N) is the user interface. This layering structure is depicted in Figure 2.13.\\n',\n",
              " '    An operating-system layer is an implementation of an abstract object made up of data and the operations that can manipulate those data. A typical operating-system layer say, layer M  consists of data structures and a set of routines that can be invoked by higher-level layers. Layer M, in turn, can invoke operations on lower-level layers.\\n',\n",
              " '   The main advantage of the layered approach is simplicity of construction and debugging. The layers are selected so that each uses functions (operations) and services of only lower-level layers. This approach simplifies debugging and system verification. The first layer can be debugged without any concern for the rest of the system, because, by definition, it uses only the basic hardware (which is assumed correct) to implement its functions. Once the first layer is debugged, its correct functioning can be assumed while the second layer is debugged, and so on. If an error is found during the debugging of a particular layer, the error must be on that layer, because the layers below it are already debugged. Thus, the design and implementation of the system are simplified. Each layer is implemented only with operations provided by lower-level layers. A layer does not need to know how these operations are implemented; it needs to know only what these operations do. Hence, each layer hides the existence of certain data structures, operations, and hardware from higher-level\\n',\n",
              " '   The major difficulty with the layered approach involves appropriately defining the various layers. Because a layer can use only lower-level layers, careful planning is necessary. For example, the device driver for the backing store (disk space used by virtual-memory algorithms) must be at a lower level than the memory-management routines, because memory management requires the ability to use the backing store.\\n',\n",
              " '   Other requirements may not be so obvious. The backing-store driver would normally be above the CPU scheduler, because the driver may need to wait for I/O and the CPU can be rescheduled during this time. However, on a large\\n',\n",
              " 'system, the CPU scheduler may have more information about all the active processes than can fit in memory. Therefore, this information may need to be swapped in and out of memory, requiring the backing-store driver routine to be below the CPU scheduler.\\n',\n",
              " '   A final problem with layered implementations is that they tend to be less efficient than other types. For instance, when a user program executes an I/O operation, it executes a system call that is trapped to the I/O layer, which calls the memory-management layer, which in turn calls the CPU-scheduling layer, which is then passed to the hardware. At each layer, the parameters may be modified, data may need to be passed, and so on. Each layer adds overhead to the system call. The net result is a system call that takes longer than does one on a nonlayered system.\\n',\n",
              " '   These limitations have caused a small backlash against layering in recent years. Fewer layers with more functionality are being designed, providing most of the advantages of modularized code while avoiding the problems of layer definition and interaction.\\n',\n",
              " 'We have already seen that as UNIX expanded, the kernel became large and difficult to manage. In the mid-1980s, researchers at Carnegie Mellon University developed an operating system called Mach that modularized the kernel using the microkernel approach. This method structures the operating system by removing all nonessential components from the kernel and implementing them as system and user-level programs. The result is a smaller kernel. There is little consensus regarding which services should remain in the kernel and which should be implemented in user space. Typically, however, microkernels provide minimal process and memory management, in addition to a communication facility. Figure 2.14 illustrates the architecture of a typical microkernel.\\n',\n",
              " '    The main function of the microkernel is to provide communication between the client program and the various services that are also running in user space. Communication is provided through message passing, which was described in Section 2.4.5. For example, if the client program wishes to access a file, it\\n',\n",
              " '   One benefit of the microkernel approach is that it makes extending the operating system easier. All new services are added to user space and consequently do not require modification of the kernel. When the kernel does have to be modified, the changes tend to be fewer, because the microkernel is a smaller kernel. The resulting operating system is easier to port from one hardware design to another. The microkernel also provides more security and reliability, since most services are running as user rather than kernel processes. If a service fails, the rest of the operating system remains untouched. Some contemporary operating systems have used the microkernel approach. Tru64 UNIX (formerly Digital UNIX) provides a UNIX interface to the user, but it is implemented with a Mach kernel. The Mach kernel maps UNIX system calls into messages to the appropriate user-level services. The Mac OS X kernel (also known as Darwin) is also partly based on the Mach microkernel. Another example is QNX, a real-time operating system for embedded systems. The QNX Neutrino microkernel provides services for message passing and process scheduling. It also handles low-level network communication and hardware interrupts. All other services in QNX are provided by standard\\n',\n",
              " '   Unfortunately, the performance of microkernels can suffer due to increased system-function overhead. Consider the history of Windows NT. The first release had a layered microkernel organization. This versions performance was low compared with that of Windows 95. Windows NT 4.0 partially corrected the performance problem by moving layers from user space to kernel space and integrating them more closely. By the time Windows XP was designed, Windows architecture had become more monolithic than microkernel.\\n',\n",
              " 'Perhaps the best current methodology for operating-system design involves using loadable kernel modules. Here, the kernel has a set of core components and links in additional services via modules, either at boot time or during run time. This type of design is common in modern implementations of UNIX, such as Solaris, Linux, and Mac OS X, as well as Windows.\\n',\n",
              " '   The idea of the design is for the kernel to provide core services while other services are implemented dynamically, as the kernel is running. Linking services dynamically is preferable to adding new features directly to the kernel, which would require recompiling the kernel every time a change was made. Thus, for example, we might build CPU scheduling and memory management algorithms directly into the kernel and then add support for different file systems by way of loadable modules.\\n',\n",
              " '   The overall result resembles a layered system in that each kernel section has defined, protected interfaces; but it is more flexible than a layered system, because any module can call any other module. The approach is also similar to the microkernel approach in that the primary module has only core functions and knowledge of how to load and communicate with other modules; but it\\n',\n",
              " '   Linux also uses loadable kernel modules, primarily for supporting device drivers and file systems. We cover creating loadable kernel modules in Linux as a programming exercise at the end of this chapter.\\n',\n",
              " 'In practice, very few operating systems adopt a single, strictly defined structure. Instead, they combine different structures, resulting in hybrid systems that address performance, security, and usability issues. For example, both Linux and Solaris are monolithic, because having the operating system in a single address space provides very efficient performance. However, they are also modular, so that new functionality can be dynamically added to the kernel. Windows is largely monolithic as well (again primarily for performance reasons), but it retains some behavior typical of microkernel systems, including providing support for separate subsystems (known as operating-system personalities) that run as user-mode processes. Windows systems also provide support for dynamically loadable kernel modules. We provide case studies of Linux and Windows 7 in in Chapters 18 and 19, respectively. In the remainder of this section, we explore the structure of\\n',\n",
              " 'The Apple Mac OS X operating system uses a hybrid structure. As shown in Figure 2.16, it is a layered system. The top layers include the Aqua user interface (Figure 2.4) and a set of application environments and services. Notably, the Cocoa environment specifies an API for the Objective-C programming language, which is used for writing Mac OS X applications. Below these layers is the kernel environment, which consists primarily of the Mach microkernel and the BSD UNIX kernel. Mach provides memory management; support for remote procedure calls (RPCs) and interprocess communication (IPC) facilities, including message passing; and thread scheduling. The BSD component provides a BSD command-line interface, support for networking and file systems, and an implementation of POSIX APIs, including Pthreads. In addition to Mach and BSD, the kernel environment provides an I/O kit for development of device drivers and dynamically loadable modules (which Mac OS X refers to as kernel extensions). As shown in Figure 2.16, the BSD application environment can make use of BSD facilities directly.\\n',\n",
              " 'iOS is a mobile operating system designed by Apple to run its smartphone, the iPhone, as well as its tablet computer, the iPad. iOS is structured on the Mac OS X operating system, with added functionality pertinent to mobile devices, but does not directly run Mac OS X applications. The structure of iOS appears in Figure 2.17.\\n',\n",
              " '    Cocoa Touch is an API for Objective-C that provides several frameworks for developing applications that run on iOS devices. The fundamental difference between Cocoa, mentioned earlier, and Cocoa Touch is that the latter provides support for hardware features unique to mobile devices, such as touch screens. The media services layer provides services for graphics, audio, and video.\\n',\n",
              " 'The core services layer provides a variety of features, including support for cloud computing and databases. The bottom layer represents the core operating system, which is based on the kernel environment shown in Figure 2.16.\\n',\n",
              " 'The Android operating system was designed by the Open Handset Alliance (led primarily by Google) and was developed for Android smartphones and tablet computers. Whereas iOS is designed to run on Apple mobile devices and is close-sourced, Android runs on a variety of mobile platforms and is open-sourced, partly explaining its rapid rise in popularity. The structure of Android appears in Figure 2.18.\\n',\n",
              " '   Android is similar to iOS in that it is a layered stack of software that provides a rich set of frameworks for developing mobile applications. At the bottom of this software stack is the Linux kernel, although it has been modified by Google and is currently outside the normal distribution of Linux releases.\\n',\n",
              " 'Linux is used primarily for process, memory, and device-driver support for hardware and has been expanded to include power management. The Android runtime environment includes a core set of libraries as well as the Dalvik virtual machine. Software designers for Android devices develop applications in the Java language. However, rather than using the standard Java API, Google has designed a separate Android API for Java development. The Java class files are first compiled to Java bytecode and then translated into an executable file that runs on the Dalvik virtual machine. The Dalvik virtual machine was designed for Android and is optimized for mobile devices with limited memory and CPU processing capabilities.\\n',\n",
              " '    The set of libraries available for Android applications includes frameworks for developing web browsers (webkit), database support (SQLite), and multi- media. The libc library is similar to the standard C library but is much smaller and has been designed for the slower CPUs that characterize mobile devices.\\n',\n",
              " 'We have mentioned debugging frequently in this chapter. Here, we take a closer look. Broadly, debugging is the activity of finding and fixing errors in a system, both in hardware and in software. Performance problems are considered bugs, so debugging can also include performance tuning, which seeks to improve performance by removing processing bottlenecks. In this section, we explore debugging process and kernel errors and performance problems. Hardware debugging is outside the scope of this text.\\n',\n",
              " 'If a process fails, most operating systems write the error information to a log file to alert system operators or users that the problem occurred. The operating system can also take a core dump a capture of the memory of the process and store it in a file for later analysis. (Memory was referred to as the core in the early days of computing.) Running programs and core dumps can be probed by a debugger, which allows a programmer to explore the code and memory of a process.\\n',\n",
              " '    Debugging user-level process code is a challenge. Operating-system kernel debugging is even more complex because of the size and complexity of the kernel, its control of the hardware, and the lack of user-level debugging tools. A failure in the kernel is called a crash. Whena crash occurs, error information is saved to a log file, and the memory state is saved to a crash dump.\\n',\n",
              " '   Operating-system debugging and process debugging frequently use dif- ferent tools and techniques due to the very different nature of these two tasks. Consider that a kernel failure in the file-system code would make it risky for the kernel to try to save its state to a file on the file system before rebooting. A common technique is to save the kernels memory state to a section of disk set aside for this purpose that contains no file system. If the kernel detects an unrecoverable error, it writes the entire contents of memory, or at least the kernel-owned parts of the system memory, to the disk area. When the system reboots, a process runs to gather the data from that area and write it to a crash\\n',\n",
              " 'We mentioned earlier that performance tuning seeks to improve performance by removing processing bottlenecks. To identify bottlenecks, we must be able to monitor system performance. Thus, the operating system must have some means of computing and displaying measures of system behavior. In a number of systems, the operating system does this by producing trace listings of system behavior. All interesting events are logged with their time and important parameters and are written to a file. Later, an analysis program can process the log file to determine system performance and to identify bottlenecks and inefficiencies. These same traces can be run as input for a simulation of a suggested improved system. Traces also can help people to find errors in operating-system behavior.\\n',\n",
              " '   Another approach to performance tuning uses single-purpose, interactive tools that allow users and administrators to question the state of various system components to look for bottlenecks. One such tool employs the UNIX command top to display the resources used on the system, as well as a sorted list of the top resource-using processes. Other tools display the state of disk I/O, memory allocation, and network traffic.\\n',\n",
              " '   The Windows Task Manager is a similar tool for Windows systems. The task manager includes information for current applications as well as processes, CPU and memory usage, and networking statistics. A screen shot of the task manager appears in Figure 2.19.\\n',\n",
              " '   Making operating systems easier to understand, debug, and tune as they run is an active area of research and implementation. A new generation of kernel-enabled performance analysis tools has made significant improvements in how this goal can be achieved. Next, we discuss a leading example of such a tool: the Solaris 10 DTrace dynamic tracing facility.\\n',\n",
              " 'DTrace is a facility that dynamically adds probes to a running system, both in user processes and in the kernel. These probes can be queried via the D programming language to determine an astonishing amount about the kernel, the system state, and process activities. For example, Figure 2.20 follows an application as it executes a system call (ioctl()) and shows the functional calls within the kernel as they execute to perform the system call. Lines ending with U are executed in user mode, and lines ending in K in kernel mode.\\n',\n",
              " '   Debugging the interactions between user-level and kernel code is nearly impossible without a toolset that understands both sets of code and can instrument the interactions. For that toolset to be truly useful, it must be able to debug any area of a system, including areas that were not written with debugging in mind, and do so without affecting system reliability. This tool must also have a minimum performance impact ideally it should have no impact when not in use and a proportional impact during use. The DTrace tool meets these requirements and provides a dynamic, safe, low-impact debugging environment.\\n',\n",
              " '   Until the DTrace framework and tools became available with Solaris 10, kernel debugging was usually shrouded in mystery and accomplished via happenstance and archaic code and tools. For example, CPUs havea breakpoint feature that will halt execution and allow a debugger to examine the state of the system. Then execution can continue until the next breakpoint or termination. This method cannot be used in a multiuser operating-system kernel without negatively affecting all of the users on the system. Profiling, which periodically samples the instruction pointer to determine which code is being executed, can show statistical trends but not individual activities. Code can be included in the kernel to emit specific data under specific circumstances, but that code slows down the kernel and tends not to be included in the part of the kernel where the specific problem being debugged is occurring.\\n',\n",
              " '   In contrast, DTrace runs on production systems  systems that are running important or critical applications  and causes no harm to the system. It slows activities while enabled, but after execution it resets the system to its pre-debugging state. It is also a broad and deep tool. It can broadly debug everything happening in the system (both at the user and kernel levels and between the user and kernel layers). It can also delve deep into code, showing individual CPU instructions or kernel subroutine activities.\\n',\n",
              " '   DTrace is composed of a compiler, a framework, providers of probes written within that framework, and consumers of those probes. DTrace providers create probes. Kernel structures exist to keep track of all probes that the providers have created. The probes are stored in a hash-table data structure that is hashed by name and indexed according to unique probe identifiers. When a probe is enabled, a bit of code in the area to be probed is rewritten to call dtrace probe(probe identifier) and then continue with the codes original operation. Different providers create different kinds of probes. For example, a kernel system-call probe works differently from a user-process probe, and that is different from an I/O probe.\\n',\n",
              " '    DTrace features a compiler that generates a byte code that is run in the kernel. This code is assured to be safe by the compiler. For example, no loops are allowed, and only specific kernel state modifications are allowed when specifically requested. Only users with DTrace privileges (or root users)\\n',\n",
              " 'are allowed to use DTrace, as it can retrieve private kernel data (and modify data if requested). The generated code runs in the kernel and enables probes. It also enables consumers in user mode and enables communications between the two.\\n',\n",
              " '   A DTrace consumer is code that is interested in a probe and its results. A consumer requests that the provider create one or more probes. When a probe fires, it emits data that are managed by the kernel. Within the kernel, actions called enabling control blocks, or ECBs, are performed when probes fire. One probe can cause multiple ECBs to execute if more than one consumer is interested in that probe. Each ECB contains a predicate (if statement) that can filter out that ECB. Otherwise, the list of actions in the ECB is executed. The most common action is to capture some bit of data, such as a variables value at that point of the probe execution. By gathering such data, a complete picture of a user or kernel action can be built. Further, probes firing from both user space and the kernel can show how a user-level action caused kernel-level reactions. Such data are invaluable for performance monitoring and code optimization. Once the probe consumer terminates, its ECBs are removed. If there are no ECBs consuming a probe, the probe is removed. That involves rewriting the code to remove the dtrace probe() call and put back the original code. Thus, before a probe is created and after it is destroyed, the system is exactly the\\n',\n",
              " '    DTrace takes care to assure that probes do not use too much memory or CPU capacity, which could harm the running system. The buffers used to hold the probe results are monitored for exceeding default and maximum limits. CPU time for probe execution is monitored as well. If limits are exceeded, the consumer is terminated, along with the offending probes. Buffers are allocated per CPU to avoid contention and data loss.\\n',\n",
              " '    An example of D code and its output shows some of its utility. The following program shows the DTrace code to enable scheduler probes and record the amount of CPU time of each process running with user ID 101 while those probes are enabled (that is, while the program runs):\\n',\n",
              " 'systems do not have conflicting license agreements. For example, DTrace has been added to Mac OS X and FreeBSD and will likely spread further due to its unique capabilities. Other operating systems, especially the Linux derivatives, are adding kernel-tracing functionality as well. Still other operating systems are beginning to include performance and tracing tools fostered by research at various institutions, including the Paradyn project.\\n',\n",
              " 'It is possible to design, code, and implement an operating system specifically for one machine at one site. More commonly, however, operating systems are designed to run on any of a class of machines at a variety of sites with a variety of peripheral configurations. The system must then be configured or generated for each specific computer site, a process sometimes known as system generation SYSGEN.\\n',\n",
              " '   The operating system is normally distributed on disk, on CD-ROM or DVD-ROM, or as an ISO image, which is a file in the format of a CD-ROM or DVD-ROM. To generate a system, we use a special program. This SYSGEN program reads from a  given file, or asks the operator of the  system for information concerning the specific configuration of the hardware system, or probes the hardware directly to determine what components are there. The following kinds of information must be determined.\\n',\n",
              " ' How much memory is available? Some systems will determine this value themselves by referencing memory location after memory location until an illegal address fault is generated. This procedure defines the final legal address and hence the amount of available memory.\\n',\n",
              " ' What devices are available? The system will need to know how to address each device (the device number), the device interrupt number, the devices type and model, and any special device characteristics.\\n',\n",
              " ' What operating-system options are desired, or what parameter values are to be used? These options or values might include how many buffers of which sizes should be used, what type of CPU-scheduling algorithm is desired, what the maximum number of processes to be supported is, and so on.\\n',\n",
              " '    Once this information is determined, it can be used in several ways. At one extreme, a system administrator can use it to modify a copy of the source code of the operating system. The operating system then is completely compiled. Data declarations, initializations, and constants, along with conditional compilation, produce an output-object version of the operating system that is tailored to the system described.\\n',\n",
              " '   At a slightly less tailored level, the system description can lead to the creation of tables and the selection of modules from a precompiled library. These modules are linked together to form the generated operating system. Selection allows the library to contain the device drivers for all supported I/O devices, but only those needed are linked into the operating system. Because the system is not recompiled, system generation is faster, but the resulting system may be overly general.\\n',\n",
              " '   At the other extreme, it is possible to construct a system that is completely table driven. All the code is always part of the system, and selection occurs at execution time, rather than at compile or link time. System generation involves simply creating the appropriate tables to describe the system.\\n',\n",
              " '   The major differences among these approaches are the size and generality of the generated system and the ease of modifying it as the hardware configuration changes. Consider the cost of modifying the system to support a newly acquired graphics terminal or another disk drive. Balanced against that cost, of course, is the frequency (or infrequency) of such changes.\\n',\n",
              " 'After an operating system is generated, it must be made available for use by the hardware. But how does the hardware know where the kernel is or how to load that kernel? The procedure of starting a computer by loading the kernel is known as booting the system. On most computer systems, a small piece of code known as the bootstrap program or bootstrap loader locates the kernel, loads it into main memory, and starts its execution. Some computer systems, such as PCs, use a two-step process in which a simple bootstrap loader fetches a more complex boot program from disk, which in turn loads the kernel.\\n',\n",
              " 'location, and execution starts there. At that location is the initial bootstrap program. This program is in the form of read-only memory (ROM), because the RAM is in an unknown state at system startup. ROM is convenient because it needs no initialization and cannot easily be infected by a computer virus.\\n',\n",
              " '   The bootstrap program can perform a variety of tasks. Usually, one task is to run diagnostics to determine the state of the machine. If the diagnostics pass, the program can continue with the booting steps. It can also initialize all aspects of the system, from CPU registers to device controllers and the contents of main memory. Sooner or later, it starts the operating system.\\n',\n",
              " '    Some systems such as cellular phones, tablets, and game consoles store the entire operating system in ROM. Storing the operating system in ROM is suitable for small operating systems, simple supporting hardware, and rugged operation. A problem with this approach is that changing the bootstrap code requires changing the ROM hardware chips. Some systems resolve this problem by using erasable programmable read-only memory (EPROM), which is read- only except when explicitly given a command to become writable. All forms of ROM are also known as firmware, since their characteristics fall somewhere between those of hardware and those of software. A problem with firmware in general is that executing code there is slower than executing code in RAM. Some systems store the operating system in firmware and copy it to RAM for fast execution. A final issue with firmware is that it is relatively expensive, so usually only small amounts are available.\\n',\n",
              " '   For large operating systems (including most general-purpose operating systems like Windows, Mac OS X, and UNIX) or for systems that change frequently, the bootstrap loader is stored in firmware, and the operating system is on disk. In this case, the bootstrap runs diagnostics and has a bit of code that can read a single block at a fixed location (say block zero) from disk into memory and execute the code from that boot block. The program stored in the boot block may be sophisticated enough to load the entire operating system into memory and begin its execution. More typically, it is simple code (as it fits in a single disk block) and knows only the address on disk and length of the remainder of the bootstrap program. GRUB is an example of an open-source bootstrap program for Linux systems. All of the disk-bound bootstrap, and the operating system itself, can be easily changed by writing new versions to disk. A disk that has a boot partition (more on that in Section 10.5.1) is called a boot disk or system disk.\\n',\n",
              " '   Now that the full bootstrap program has been loaded, it can traverse the file system to find the operating system kernel, load it into memory, and start its execution. It is only at this point that the system is said to be running.\\n',\n",
              " 'Operating systems provide a number of services. At the lowest level, system calls allow a running program to make requests from the operating system directly. At a higher level, the command interpreter or shell provides a mechanism for a user to issue a request without writing a program. Commands may come from files during batch-mode execution or directly from a terminal or desktop GUI when in an interactive or time-shared mode. System programs are provided to satisfy many common user requests.\\n',\n",
              " '   The types of requests vary according to level. The system-call level must provide the basic functions, such as process control and file and device manipulation. Higher-level requests, satisfied by the command interpreter or system programs, are translated into a sequence of system calls. System services can be classified into several categories: program control, status requests, and I/O requests. Program errors can be considered implicit requests for service.\\n',\n",
              " '   The design of a new operating system is a major task. It is important that the goals of the system be well defined before the design begins. The type of system desired is the foundation for choices among various algorithms and strategies that will be needed.\\n',\n",
              " '   Throughout the entire design cycle, we must be careful to separate policy decisions from implementation details (mechanisms). This separation allows maximum flexibility if policy decisions are to be changed later.\\n',\n",
              " '   Once an operating system is designed, it must be implemented. Oper- ating systems today are almost always written in a systems-implementation language or in a higher-level language. This feature improves their implemen- tation, maintenance, and portability.\\n',\n",
              " '   A system as large and complex as a modern operating system must be engineered carefully. Modularity is important. Designing a system as a sequence of layers or using a microkernel is considered a good technique. Many operating systems now support dynamically loaded modules, which allow adding functionality to an operating system while it is executing. Generally, operating systems adopt a hybrid approach that combines several different types of structures.\\n',\n",
              " '   Debugging process and kernel failures can be accomplished through the use of debuggers and other tools that analyze core dumps. Tools such as DTrace analyze production systems to find bottlenecks and understand other system behavior.\\n',\n",
              " '   To create an operating system for a particular machine configuration, we must perform system generation. For the computer system to begin running, the CPU must initialize and start executing the bootstrap program in firmware. The bootstrap can execute the operating system directly if the operating system is also in the firmware, or it can complete a sequence in which it loads progressively smarter programs from firmware and disk until the operating system itself is loaded into memory and executed.\\n',\n",
              " '2.9 List five services provided by an operating system, and explain how each creates convenience for users. In which cases would it be impossible for user-level programs to provide these services? Explain your answer.\\n',\n",
              " '2.14 Describe how you could obtain a statistical profile of the amount of time spent by a program executing different sections of its code. Discuss the importance of obtaining such a statistical profile.\\n',\n",
              " '2.20 It is sometimes difficult to achieve a layered approach if two components of the operating system are dependent on each other. Identify a scenario in which it is unclear how to layer two system components that require tight coupling of their functionalities.\\n',\n",
              " '2.21 What is the main advantage of the microkernel approach to system design? How do user programs and system services interact in a microkernel architecture? What are the disadvantages of using the microkernel approach?\\n',\n",
              " '2.25 The experimental Synthesis operating system has an assembler incor- porated in the kernel. To optimize system-call performance, the kernel assembles routines within kernel space to minimize the path that the system call must take through the kernel. This approach is the antithesis of the layered approach, in which the path through the kernel is extended to make building the operating system easier. Discuss the pros and cons of the Synthesis approach to kernel design and system-performance optimization.\\n',\n",
              " '2.26 In Section 2.3, we described a program that copies the contents of one file to a destination file. This program works by first prompting the user for the name of the source and destination files. Write this program using either the Windows or POSIX API. Be sure to include all necessary error checking, including ensuring that the source file exists.\\n',\n",
              " '    Once you have correctly designed and tested the program, if you used a system that supports it, run the program using a utility that traces system calls. Linux systems provide the strace utility, and Solaris and Mac OS X systems use the dtrace command. As Windows systems do not provide such features, you will have to trace through the Windows version of this program using a debugger.\\n',\n",
              " 'In this project, you will learn how to create a kernel module and load it into the Linux kernel. The project can be completed using the Linux virtual machine that is available with this text. Although you may use an editor to write these C programs, you will have to use the terminal application to compile the programs, and you will have to enter commands on the command line to manage the modules in the kernel.\\n',\n",
              " '   As youll discover, the advantage of developing kernel modules is that it is a relatively easy method of interacting with the kernel, thus allowing you to write programs that directly invoke kernel functions. It is important for you to keep in mind that you are indeed writing kernel code that directly interacts with the kernel. That normally means that any errors in the code could crash the system! However, since you will be using a virtual machine, any failures will at worst only require rebooting the system.\\n',\n",
              " '   The following program (named simple.c and available with the source code for this text) illustrates a very basic kernel module that prints appropriate messages when the kernel module is loaded and unloaded.\\n',\n",
              " '   The function simple init() is the module entry point, which represents the function that is invoked when the module is loaded into the kernel. Similarly, the simple exit() function is the module exit point the function that is called when the module is removed from the kernel.\\n',\n",
              " '   The module entry point function must return an integer value, with 0 representing success and any other value representing failure. The module exit point function returns void. Neither the module entry point nor the module exit point is passed any parameters. The two following macros are used for registering the module entry and exit points with the kernel:\\n',\n",
              " '   Notice how both the module entry and exit point functions make calls to the printk() function. printk() is the  kernel equivalent  of  printf(), yet its output is sent to a kernel log buffer whose contents can be read by the dmesg command. One difference between printf() and printk() is that printk() allows us to specify a priority flag whose values are given in the\\n',\n",
              " 'ULE AUTHOR() represent details regarding the software license, description of the module, and author. For our purposes, we do not depend on this information, but we include it because it is standard practice in developing kernel modules.\\n',\n",
              " 'To check whether the module has loaded, enter the lsmod command and search for the module simple. Recall that the module entry point is invoked when the module is inserted into the kernel. To check the contents of this message in the kernel log buffer, enter the command\\n',\n",
              " 'Proceed through the steps described above to create the kernel module and to load and unload the module. Be sure to check the contents of the kernel log buffer using dmesg to ensure you have properly followed the steps.\\n',\n",
              " '   In Section 1.10, we covered various data structures that are common in operating systems. The Linux kernel provides several of these structures. Here, we explore using the circular, doubly linked list that is available to kernel developers. Much of what we discuss is available in the Linux source code in this instance, the include file <linux/list.h> and we recommend that you examine this file as you proceed through the following steps.\\n',\n",
              " 'Notice the member struct list head list. The list head structure is defined in the include file <linux/types.h>. Its intention is to embed the linked list within the nodes that comprise the list. This list head structure is quite simple it merely holds two members, next and prev, that point to the next and previous entries in the list. By embedding the linked list within the structure, Linux makes it possible to manage the data structure with a series of macro functions.\\n',\n",
              " 'The kmalloc() function is the kernel equivalent of the user-level malloc() function for allocating memory, except that kernel memory is being allocated. (The GFP KERNEL flag indicates routine kernel memory allocation.) The macro INIT LIST HEAD() initializes the list member in struct birthday. We can then add this instance to the end of the linked list using the list add tail() macro:\\n',\n",
              " '   Perhaps the simplest approach for removing all elements from a linked list is to remove each element as you traverse the list. The macro list for each entry safe() behaves much like list for each entry()\\n',\n",
              " 'except that it is passed an additional argument that maintains the value of the next pointer of the item being deleted. (This is necessary for preserving the structure of the list.) The following code example illustrates this macro:\\n',\n",
              " 'Notice that after deleting each element, we return memory that was previously allocated with kmalloc() back to the kernel with the call to kfree(). Careful memory management which includes releasing memory to prevent memory leaks is crucial when developing kernel-level code.\\n',\n",
              " 'In the module entry point, create a linked list containing five struct birthday elements. Traverse the linked list and output its contents to the kernel log buffer. Invoke the dmesg command to ensure the list is properly constructed once the kernel module has been loaded.\\n',\n",
              " '    In the module exit point, delete the elements from the linked list and return the free memory back to the kernel. Again, invoke the dmesg command to check that the list has been removed once the kernel module has been unloaded.\\n',\n",
              " '[Dijkstra (1968)] advocated the layered approach to operating-system design. [Brinch-Hansen (1970)] was an early proponent of constructing an operating system as a kernel (or nucleus) on which more complete systems could be built. [Tarkoma and Lagerspetz (2011)] provide an overview of various mobile operating systems, including Android and iOS.\\n',\n",
              " '    MS-DOS, Version 3.1, is described in [Microsoft (1986)]. Windows NT and Windows 2000 are described by [Solomon (1998)] and [Solomon and Russinovich (2000)]. Windows XP internals are described in [Russinovich and Solomon (2009)]. [Hart (2005)] covers Windows systems programming in detail. BSD UNIX is described in [McKusick et al. (1996)]. [Love (2010)] and [Mauerer (2008)] thoroughly discuss the Linux kernel. In particular, [Love (2010)] covers Linux kernel modules as well as kernel data structures. Several UNIX systems including Mach are treated in detail in [Vahalia (1996)]. Mac OS X is presented at http://www.apple.com/macosx and in [Singh (2007)]. Solaris is fully described in [McDougall and Mauro (2007)].\\n',\n",
              " '   A process is the unit of work in most systems. Systems consist of a collection of processes: operating-system processes execute system code, and user processes execute user code. All these processes may execute concurrently.\\n',\n",
              " '   The operating system is responsible for several important aspects of process and thread management: the creation and deletion of both user and system processes; the scheduling of processes; and the provision of mechanisms for synchronization, communication, and deadlock handling for processes.\\n',\n",
              " 'Early computers allowed only one program to be executed at a time. This program had complete control of the system and had access to all the systems resources. In contrast, contemporary computer systems allow multiple pro- grams to be loaded into memory and executed concurrently. This evolution required firmer control and more compartmentalization of the various pro- grams; and these needs resulted in the notion of a process, which is a program in execution. A process is the unit of work in a modern time-sharing system.\\n',\n",
              " '   The more complex the operating system is, the more it is expected to do on behalf of its users. Although its main concern is the execution of user programs, it also needs to take care of various system tasks that are better left outside the kernel itself. A system therefore consists of a collection of processes: operating- system processes executing system code and user processes executing user code. Potentially, all these processes can execute concurrently, with the CPU (or CPUs) multiplexed among them. By switching the CPU between processes, the operating system can make the computer more productive. In this chapter, you will read about what processes are and how they work.\\n',\n",
              " 'system has user programs, or tasks. Even on a single-user system, a user may be able to run several programs at one time: a word processor, a Web browser, and an e-mail package. And even if a user can execute only one program at a time, such as on an embedded device that does not support multitasking, the operating system may need to support its own internal programmed activities, such as memory management. In many respects, all these activities are similar, so we call all of them processes.\\n',\n",
              " '   The terms job and process are used almost interchangeably in this text. Although we personally prefer the term process, much of operating-system theory and terminology was developed during a time when the major activity of operating systems was job processing. It would be misleading to avoid the use of commonly accepted terms that include the word job (such as job scheduling) simply because process has superseded job.\\n',\n",
              " 'Informally, as mentioned earlier, a process is a program in execution. A process is more than the program code, which is sometimes known as the text section. It also includes the current activity, as represented by the value of the program counter and the contents of the processors registers. A process generally also includes the process stack, which contains temporary data (such as function parameters, return addresses, and local variables), and a data section, which contains global variables. A process may also include a heap, which is memory that is dynamically allocated during process run time. The structure of a process in memory is shown in Figure 3.1.\\n',\n",
              " '   We emphasize that a program by itself is not a process. A program is a passive entity, such as a file containing a list of instructions stored on disk (often called an executable file). In contrast, a process is an active entity, with a program counter specifying the next instruction to execute and a set of associated resources. A program becomes a process when an executable file is loaded into memory. Two common techniques for loading executable files\\n',\n",
              " '   Although two processes may be associated with the same program, they are nevertheless considered two separate execution sequences. For instance, several users may be running different copies of the mail program, or the same user may invoke many copies of the web browser program. Each of these is a separate process; and although the text sections are equivalent, the data, heap, and stack sections vary. It is also common to have a process that spawns many processes as it runs. We discuss such matters in Section 3.4.\\n',\n",
              " '   Note that a process itself can be an execution environment for other code. The Java programming environment provides a good example. In most circumstances, an executable Java program is executed within the Java virtual machine (JVM). The JVM executes as a process that interprets the loaded Java code and takes actions (via native machine instructions) on behalf of that code. For example, to run the compiled Java program Program.class, we would enter\\n',\n",
              " 'The command java runs the JVM as an ordinary process, which in turns executes the Java program Program in the virtual machine. The concept is the same as simulation, except that the code, instead of being written for a different instruction set, is written in the Java language.\\n',\n",
              " 'These names are arbitrary, and they vary across operating systems. The states that they represent are found on all systems, however. Certain operating systems also more finely delineate process states. It is important to realize that only one process can be running on any processor at any instant. Many processes may be ready and waiting, however. The state diagram corresponding to these states is presented in Figure 3.2.\\n',\n",
              " 'Each process is represented in the operating system by a process control block (PCB)  also called a task control block.A PCB is shown in Figure 3.3. It contains many pieces of information associated with a specific process, including these:\\n',\n",
              " ' CPU registers. The registers vary in number and type, depending on the computer architecture. They include accumulators, index registers, stack pointers, and general-purpose registers, plus any condition-code information. Along with the program counter, this state information must be saved when an interrupt occurs, to allow the process to be continued correctly afterward (Figure 3.4).\\n',\n",
              " ' Memory-management information. This information may include such items as the value of the base and limit registers and the page tables, or the segment tables, depending on the memory system used by the operating system (Chapter 8).\\n',\n",
              " 'The process model discussed so far has implied that a process is a program that performs a single thread of execution. For example, when a process is running a word-processor program, a single thread of instructions is being executed. This single thread of control allows the process to perform only one task at a time. The user cannot simultaneously type in characters and run the spell checker within the same process, for example. Most modern operating systems have extended the process concept to allow a process to have multiple threads of execution and thus to perform more than one task at a time. This feature is especially beneficial on multicore systems, where multiple threads can run in parallel. On a system that supports threads, the PCB is expanded to include information for each thread. Other changes throughout the system are also needed to support threads. Chapter 4 explores threads in detail.\\n',\n",
              " 'The process control block in the Linux operating system is represented by the C structure task struct, which is found in the  <linux/sched.h> include file in the kernel source-code directory. This structure contains all the necessary information for representing a process, including the state of the process, scheduling and memory-management information, list of open files, and pointers to the processs parent and a list of its children and siblings. (A processs parent is the process that created it; its children are any processes that it creates. Its siblings are children with the same parent process.) Some of these fields include:\\n',\n",
              " 'struct  sched entity  se;  /*  scheduling  information  */ struct task struct *parent; /* this processs  parent  */ struct list head children; /* this processs children */ struct files struct  *files;  /*  list  of  open  files  */ struct mm struct *mm; /* address space of this process */\\n',\n",
              " 'For example, the state of a process is represented by the field long state in this structure. Within the Linux kernel, all active processes are represented using a doubly linked list of task struct. The kernel maintainsa pointer current to the process currently executing on the system, as shown below:\\n',\n",
              " '  As an illustration of how the kernel might manipulate one of the fields in the task struct for a specified process, lets assume the system would like to change the state of the process currently running to the value new state. If current is a pointer to the process currently executing, its state is changed with the following:\\n',\n",
              " 'The objective of multiprogramming is to have some process running at all times, to maximize CPU utilization. The objective of time sharing is to switch the CPU among processes so frequently that users can interact with each program\\n',\n",
              " 'while it is running. To meet these objectives, the process scheduler selects an available process (possibly from a set of several available processes) for program execution on the CPU. For a single-processor system, there will never be more than one running process. If there are more processes, the rest will have to wait until the CPU is free and can be rescheduled.\\n',\n",
              " 'As processes enter the system, they are put into a job queue, which consists of all processes in the system. The processes that are residing in main memory and are ready and waiting to execute are kept on a list called the ready queue. This queue is generally stored as a linked list. A ready-queue header contains pointers to the first and final PCBs in the list. Each PCB includes a pointer field that points to the next PCB in the ready queue.\\n',\n",
              " '   The system also includes other queues. When a process is allocated the CPU, it executes for a while and eventually quits, is interrupted, or waits for the occurrence of a particular event, such as the completion of an I/O request. Suppose the process makes an I/O request to a shared device, such as a disk. Since there are many processes in the system, the disk may be busy with the I/O request of some other process. The process therefore may have to wait for the disk. The list of processes waiting for a particular I/O device is called a device queue. Each device has its own device queue (Figure 3.5).\\n',\n",
              " '   A common representation of process scheduling is a queueing diagram, such as that in Figure 3.6. Each rectangular box represents a queue. Two types of queues are present: the ready queue and a set of device queues. The circles represent the resources that serve the queues, and the arrows indicate the flow of processes in the system.\\n',\n",
              " '   A new process is initially put in the ready queue. It waits there until it is selected for execution, or dispatched. Once the process is allocated the CPU and is executing, one of several events could occur:\\n',\n",
              " '    In the first two cases, the process eventually switches from the waiting state to the ready state and is then put back in the ready queue. A process continues this cycle until it terminates, at which time it is removed from all queues and has its PCB and resources deallocated.\\n',\n",
              " 'A process migrates among the various scheduling queues throughout its lifetime. The operating system must select, for scheduling purposes, processes from these queues in some fashion. The selection process is carried out by the appropriate scheduler.\\n',\n",
              " '    Often, in a batch system, more processes are submitted than can be executed immediately. These processes are spooled to a mass-storage device (typically a disk), where they are kept for later execution. The long-term scheduler, or job scheduler, selects processes from this pool and loads them into memory for\\n',\n",
              " '   The primary distinction between these two schedulers lies in frequency of execution. The short-term scheduler must select a new process for the CPU frequently. A process may execute for only a few milliseconds before waiting for an I/O request. Often, the short-term scheduler executes at least once every 100 milliseconds. Because of the short time between executions, the short-term scheduler must be fast. If it takes 10 milliseconds to decide to execute a process for 100 milliseconds, then 10/(100 + 10) = 9 percent of the CPU is being used (wasted) simply for scheduling the work.\\n',\n",
              " '   The long-term scheduler executes much less frequently; minutes may sep- arate the creation of one new process and the next. The long-term scheduler controls the degree of multiprogramming (the number of processes in mem- ory). If the degree of multiprogramming is stable, then the average rate of process creation must be equal to the average departure rate of processes leaving the system. Thus, the long-term scheduler may need to be invoked only when a process leaves the system. Because of the longer interval between executions, the long-term scheduler can afford to take more time to decide which process should be selected for execution.\\n',\n",
              " '   It is important that the long-term scheduler make a careful selection. In general, most processes can be described as either I/O bound or CPU bound. An I/O-bound process is one that spends more of its time doing I/O than it spends doing computations. A CPU-bound process, in contrast, generates I/O requests infrequently, using more of its time doing computations. It is important that the long-term scheduler select a good process mix of I/O-bound and CPU-bound processes. If all processes are I/O bound, the ready queue will almost always be empty, and the short-term scheduler will have little to do. If all processes are CPU bound, the I/O waiting queue will almost always be empty, devices will go unused, and again the system will be unbalanced. The system with the best performance will thus have a combination of CPU-bound and I/O-bound processes.\\n',\n",
              " '   On some systems, the long-term scheduler may be absent or minimal. For example, time-sharing systems such as UNIX and Microsoft Windows systems often have no long-term scheduler but simply put every new process in memory for the short-term scheduler. The stability of these systems depends either on a physical limitation (such as the number of available terminals) or on the self-adjusting nature of human users. If performance declines to unacceptable levels on a multiuser system, some users will simply quit.\\n',\n",
              " '   Some operating systems, such as time-sharing systems, may introduce an additional, intermediate level of scheduling. This medium-term scheduler is diagrammed in Figure 3.7. The key idea behind a medium-term scheduler is that sometimes it can be advantageous to remove a process from memory (and from active contention for the CPU) and thus reduce the degree of multiprogramming. Later, the process can be reintroduced into memory, and its execution can be continued where it left off. This scheme is called swapping. The process is swapped out, and is later swapped in, by the medium-term scheduler. Swapping may be necessary to improve the process mix or because a change in memory requirements has overcommitted available memory, requiring memory to be freed up. Swapping is discussed in Chapter 8.\\n',\n",
              " 'As mentioned in Section 1.2.1, interrupts cause the operating system to change a CPU from its current task and to run a kernel routine. Such operations happen frequently on general-purpose systems. When an interrupt occurs, the system needs to save the current context of the process running on the CPU so that it can restore that context when its processing is done, essentially suspending the process and then resuming it. The context is represented in the PCB of the process. It includes the value of the CPU registers, the process state (see Figure 3.2), and memory-management information. Generically, we perform a state save of the current state of the CPU, be it in kernel or user mode, and then a state restore to resume operations.\\n',\n",
              " '   Switching the CPU to another process requires performing a state save of the current process and a state restore of a different process. This task is known as a context switch. When a context switch occurs, the kernel saves the context of the old process in its PCB and loads the saved context of the new process scheduled to run. Context-switch time is pure overhead, because the system does no useful work while switching. Switching speed varies from machine to machine, depending on the memory speed, the number of registers that must be copied, and the existence of special instructions (such as a single instruction to load or store all registers). A typical speed is a few milliseconds.\\n',\n",
              " '   Context-switch times are highly dependent on hardware support. For instance, some processors (such as the Sun UltraSPARC) provide multiple sets of registers. A context switch here simply requires changing the pointer to the current register set. Of course, if there are more active processes than there are register sets, the system resorts to copying register data to and from memory, as before. Also, the more complex the operating system, the greater the amount of work that must be done during a context switch. As we will see in Chapter 8, advanced memory-management techniques may require that extra data be switched with each context. For instance, the address space of the current process must be preserved as the space of the next task is prepared for use. How the address space is preserved, and what amount of work is needed to preserve it, depend on the memory-management method of the operating system.\\n',\n",
              " 'Because of the constraints imposed on mobile devices, early versions of iOS did not provide user-application multitasking; only one application runs in the foreground and all other user applications are suspended. Operating- system tasks were multitasked because they were written by Apple and well behaved. However, beginning with iOS 4, Apple now provides a limited form of multitasking for user applications, thus allowing a single foreground application to run concurrently with multiple background applications. (On a mobile device, the foreground application is the application currently open and appearing on the display. The background application remains in memory, but does not occupy the display screen.) The iOS 4 programming API provides support for multitasking, thus allowing a process to run in the background without being suspended. However, it is limited and only available for a limited number of application types, including applications\\n',\n",
              " '  Apple probably limits multitasking due to battery life and memory use concerns. The CPU certainly has the features to support multitasking, but Apple chooses to not take advantage of some of them in order to better manage resource use.\\n',\n",
              " '  Android does not place such constraints on the types of applications that can run in the background. If an application requires processing while in the background, the application must use a service, a separate application component that runs on behalf of the background process. Consider a streaming audio application: if the application moves to the background, the service continues to send audio files to the audio device driver on behalf of the background application. In fact, the service will continue to run even if the background application is suspended. Services do not have a user interface and have a small memory footprint, thus providing an efficient technique for multitasking in a mobile environment.\\n',\n",
              " 'The processes in most systems can execute concurrently, and they may be created and deleted dynamically. Thus, these systems must provide a mechanism for process creation and termination. In this section, we explore the mechanisms involved in creating processes and illustrate process creation on UNIX and Windows systems.\\n',\n",
              " 'During the course of execution, a process may create several new processes. As mentioned earlier, the creating process is called a parent process, and the new processes are called the children of that process. Each of these new processes may in turn create other processes, forming a tree of processes.\\n',\n",
              " '   Most operating systems (including UNIX, Linux, and Windows) identify processes according to a unique process identifier (or pid), which is typically an integer number. The pid provides a unique value for each process in the system, and it can be used as an index to access various attributes of a process within the kernel.\\n',\n",
              " '   Figure 3.8 illustrates a typical process tree for the Linux operating system, showing the name of each process and its pid. (We use the term process rather loosely, as Linux prefers the term task instead.) The init process (which always has a pid of 1) serves as the root parent process for all user processes. Once the system has booted, the initprocess can also create various user processes, such as a web or print server, an ssh server, and the like. In Figure 3.8, we see two children of init kthreadd and sshd. The kthreadd process is responsible for creating additional processes that perform tasks on behalf of the kernel (in this situation, khelper and pdflush). The sshd process is responsible for managing clients that connect to the system by using ssh (which is short for secure shell). The login process is responsible for managing clients that directly log onto the system. In this example, a client has logged on and is using the bash shell, which has been assigned pid 8416. Using the bash command-line interface, this user has created the process ps as well as the emacs editor.\\n',\n",
              " 'will list complete information for all processes currently active in the system. It is easy to construct a process tree similar to the one shown in Figure 3.8 by recursively tracing parent processes all the way to the init process.\\n',\n",
              " '   In general, when a process creates a child process, that child process will need certain resources (CPU time, memory, files, I/O devices) to accomplish its task. A child process may be able to obtain its resources directly from the operating system, or it may be constrained to a subset of the resources of the parent process. The parent may have to partition its resources among its children, or it may be able to share some resources (such as memory or files) among several of its children. Restricting a child process to a subset of the parents resources prevents any process from overloading the system by creating too many child processes.\\n',\n",
              " '   In addition to supplying various physical and logical resources, the parent process may pass along initialization data (input) to the child process. For example, consider a process whose function is to display the contents of a file\\n',\n",
              " 'say, image.jpg on the screen of a terminal. When the process is created, it will get, as an input from its parent process, the name of the file image.jpg. Using that file name, it will open the file and write the contents out. It may also get the name of the output device. Alternatively, some operating systems pass resources to child processes. On such a system, the new process may get two open files, image.jpg and the terminal device, and may simply transfer the datum between the two.\\n',\n",
              " 'To illustrate these differences, lets first consider the UNIX operating system. In UNIX, as weve seen, each process is identified by its process identifier, which is a unique integer. A new process is created by the fork() system call. The new process consists of a copy of the address space of the original process. This mechanism allows the parent process to communicate easily with its child process. Both processes (the parent and the child) continue execution at the instruction after the fork(), with one difference: the return code for the fork() is zero for the new (child) process, whereas the (nonzero) process identifier of the child is returned to the parent.\\n',\n",
              " '   After a fork() system call, one of the two processes typically uses the exec() system call to replace the processs memory space with a new program. The exec() system call loads a binary file into memory (destroying the memory image of the program containing the exec() system call) and starts its execution. In this manner, the two processes are able to communicate and then go their separate ways. The parent can then create more children; or, if it has nothing else to do while the child runs, it can issue a wait() system call to move itself off the ready queue until the termination of the child. Because the\\n',\n",
              " '   The C program shown in Figure 3.9 illustrates the UNIX system calls previously described. We now have two different processes running copies of the same program. The only difference is that the value of pid (the process identifier) for the child process is zero, while that for the parent is an integer value greater than zero (in fact, it is the actual pid of the child process). The child process inherits privileges and scheduling attributes from the parent, as well certain resources, such as open files. The child process then overlays its address space with the UNIX command /bin/ls (used to get a directory listing) using the execlp() system call (execlp() is a version of the exec() system call). The parent waits for the child process to complete with the wait() system call. When the child process completes (by either implicitly or explicitly invoking exit()), the parent process resumes from the call to wait(), where it completes using the exit() system call. This is also illustrated in Figure 3.10. Of course, there is nothing to prevent the child from not invoking exec() and instead continuing to execute as a copy of the parent process. In this scenario, the parent and child are concurrent processes running the same code\\n',\n",
              " '   As an alternative example, we next consider process creation in Windows. Processes are created in the Windows API using the CreateProcess() func- tion, which is similar to fork() in that a parent creates a new child process. However, whereas fork() has the child process inheriting the address space of its parent, CreateProcess() requires loading a specified program into the address space of the child process at process creation. Furthermore, whereas fork() is passed no parameters, CreateProcess() expects no fewer than ten parameters.\\n',\n",
              " '   The C program shown in Figure 3.11 illustrates the CreateProcess() function, which creates a child process that loads the application mspaint.exe. We opt for many of the default values of the ten parameters passed to CreateProcess(). Readers interested in pursuing the details of process creation and management in the Windows API are encouraged to consult the bibliographical notes at the end of this chapter.\\n',\n",
              " '   The two parameters passed to the CreateProcess() function are instances of the STARTUPINFO and PROCESS INFORMATION structures. STARTUPINFO specifies many properties of the new process, such as window size and appearance and handles to standard input and output files. The PRO- CESS INFORMATION structure contains a handle and the identifiers to the newly created process and its thread. We invoke the ZeroMemory() func- tion to allocate memory for each of these structures before proceeding with CreateProcess().\\n',\n",
              " '   The first two parameters passed to CreateProcess() are the application name and command-line parameters. If the application name is NULL (as it is in this case), the command-line parameter specifies the application to load. In this instance, we are loading the Microsoft Windows mspaint.exe application. Beyond these two initial parameters, we use the default parameters for inheriting process and thread handles as well as specifying that there will be no creation flags. We also use the parents existing environment block and starting directory. Last, we provide two pointers to the STARTUPINFO and PROCESS - INFORMATION structures created at the beginning of the program. In Figure 3.9, the parent process waits for the child to complete by invoking the wait() system call. The equivalent of this in Windows is WaitForSingleObject(), which is passed a handle of the child process pi.hProcess and waits for this process to complete. Once the child process exits, control returns from the WaitForSingleObject() function in the parent process.\\n',\n",
              " 'A process terminates when it finishes executing its final statement and asks the operating system to delete it by using the exit() system call. At that point, the process may return a status value (typically an integer) to its parent process (via the wait() system call). All the resources of the process including physical and virtual memory, open files, and I/O buffers are deallocated by the operating system.\\n',\n",
              " '   Termination can occur in other circumstances as well. A process can cause the termination of another process via an appropriate system call (for example, TerminateProcess() in Windows). Usually, such a system call can be invoked\\n',\n",
              " 'only by the parent of the process that is to be terminated. Otherwise, users could arbitrarily kill each others jobs. Note that a parent needs to know the identities of its children if it is to terminate them. Thus, when one process creates a new process, the identity of the newly created process is passed to the parent.\\n',\n",
              " ' The child has exceeded its usage of some of the resources that it has been allocated. (To determine whether this has occurred, the parent must have a mechanism to inspect the state of its children.)\\n',\n",
              " '   Some systems do not allow a child to exist if its parent has terminated. In such systems, if a process terminates (either normally or abnormally), then all its children must also be terminated. This phenomenon, referred to as cascading termination, is normally initiated by the operating system.\\n',\n",
              " '   To illustrate process execution and termination, consider that, in Linux and UNIX systems, we can terminate a process by using the exit() system call, providing an exit status as a parameter:\\n',\n",
              " '   A parent process may wait for the termination of a child process by using the wait() system call. The wait() system call is passed a parameter that allows the parent to obtain the exit status of the child. This system call also returns the process identifier of the terminated child so that the parent can tell which of its children has terminated:\\n',\n",
              " '   When a process terminates, its resources are deallocated by the operating system. However, its entry in the process table must remain there until the parent calls wait(), because the process table contains the processs exit status. A process that has terminated, but whose parent has not yet called wait(), is known as a zombie process. All processes transition to this state when they terminate, but generally they exist as zombies only briefly. Once the parent calls wait(), the process identifier of the zombie process and its entry in the process table are released.\\n',\n",
              " '   Now consider what would happen if a parent did not invoke wait() and instead terminated, thereby leaving its child processes as orphans. Linux and UNIX address this scenario by assigning the init process as the new parent to\\n',\n",
              " 'orphan processes. (Recall from Figure 3.8 that the init process is the root of the process hierarchy in UNIX and Linux systems.) The init process periodically invokes wait(), thereby allowing the exit status of any orphaned process to be collected and releasing the orphans process identifier and process-table entry.\\n',\n",
              " 'Processes executing concurrently in the operating system may be either independent processes or cooperating processes. A process is independent if it cannot affect or be affected by the other processes executing in the system. Any process that does not share data with any other process is independent. A process is cooperating if it can affect or be affected by the other processes executing in the system. Clearly, any process that shares data with other processes is a cooperating process.\\n',\n",
              " ' Information sharing. Since several users may be interested in the same piece of information (for instance, a shared file), we must provide an environment to allow concurrent access to such information.\\n',\n",
              " ' Computation speedup. If we want a particular task to run faster, we must break it into subtasks, each of which will be executing in parallel with the others. Notice that such a speedup can be achieved only if the computer has multiple processing cores.\\n',\n",
              " '    Cooperating processes require an interprocess communication (IPC) mech- anism that will allow them to exchange data and information. There are two fundamental models of interprocess communication: shared memory and mes- sage passing. In the shared-memory model, a region of memory that is shared by cooperating processes is established. Processes can then exchange informa- tion by reading and writing data to the shared region. In the message-passing model, communication takes place by means of messages exchanged between the cooperating processes. The two communications models are contrasted in Figure 3.12.\\n',\n",
              " '   Both of the models just mentioned are common in operating systems, and many systems implement both. Message passing is useful for exchanging smaller amounts of data, because no conflicts need be avoided. Message passing is also easier to implement in a distributed system than shared memory. (Although there are systems that provide distributed shared memory, we do not consider them in this text.) Shared memory can be faster than message passing, since message-passing systems are typically implemented using system calls\\n',\n",
              " 'Many websites contain active content such as JavaScript, Flash, and HTML5 to provide a rich and dynamic web-browsing experience. Unfortunately, these web applications may also contain software bugs, which can result in sluggish response times and can even cause the web browser to crash. This isnt a big problem in a web browser that displays content from only one website. But most contemporary web browsers provide tabbed browsing, which allows a single instance of a web browser application to open several websites at the same time, with each site in a separate tab. To switch between the different sites , a user need only click on the appropriate tab. This arrangement is illustrated below:\\n',\n",
              " '  Googles Chrome web browser was designed to address this issue by using a multiprocess architecture. Chrome identifies three different types of processes: browser, renderers, and plug-ins.\\n',\n",
              " ' The browser process is responsible for managing the user interface as well as disk and network I/O. A new browser process is created when Chrome is started. Only one browser process is created.\\n',\n",
              " ' Renderer processes contain logic for rendering web pages. Thus, they contain the logic for handling HTML, Javascript, images, and so forth. As a general rule, a new renderer process is created for each website opened in a new tab, and so several renderer processes may be active at the same time.\\n',\n",
              " ' A plug-in process is created for each type of plug-in (such as Flash or QuickTime) in use. Plug-in processes contain the code for the plug-in as well as additional code that enables the plug-in to communicate with associated renderer processes and the browser process.\\n',\n",
              " '  The advantage of the multiprocess approach is that websites run in isolation from one another. If one website crashes, only its renderer process is affected; all other processes remain unharmed. Furthermore, renderer processes run in a sandbox, which means that access to disk and network I/O is restricted, minimizing the effects of any security exploits.\\n',\n",
              " '   Recent research on systems with several processing cores indicates that message passing provides better performance than shared memory on such systems. Shared memory suffers from cache coherency issues, which arise because shared data migrate among the several caches. As the number of processing cores on systems increases, it is possible that we will see message passing as the preferred mechanism for IPC.\\n',\n",
              " 'Interprocess communication using shared memory requires communicating processes to establish a region of shared memory. Typically, a shared-memory region resides in the address space of the process creating the shared-memory segment. Other processes that wish to communicate using this shared-memory segment must attach it to their address space. Recall that, normally, the operating system tries to prevent one process from accessing another processs memory. Shared memory requires that two or more processes agree to remove this restriction. They can then exchange information by reading and writing data in the shared areas. The form of the data and the location are determined by these processes and are not under the operating systems control. The processes are also responsible for ensuring that they are not writing to the same location simultaneously.\\n',\n",
              " '   To illustrate the concept of cooperating processes, lets consider the producer consumer problem, which is a common paradigm for cooperating processes. A producer process produces information that is consumed by a consumer process. For example, a compiler may produce assembly code that is consumed by an assembler. The assembler, in turn, may produce object modules that are consumed by the loader. The producer consumer problem\\n',\n",
              " 'also provides a useful metaphor for the client server paradigm. We generally think of a server as a producer and a client as a consumer. For example, a web server produces (that is, provides) HTML files and images, which are consumed (that is, read) by the client web browser requesting the resource.\\n',\n",
              " '   One solution to the producer consumer problem uses shared memory. To allow producer and consumer processes to run concurrently, we must have available a buffer of items that can be filled by the producer and emptied by the consumer. This buffer will reside in a region of memory that is shared by the producer and consumer processes. A producer can produce one item while the consumer is consuming another item. The producer and consumer must be synchronized, so that the consumer does not try to consume an item that has not yet been produced.\\n',\n",
              " '    Two types of buffers can be used. The unbounded buffer places no practical limit on the size of the buffer. The consumer may have to wait for new items, but the producer can always produce new items. The bounded buffer assumes a fixed buffer size. In this case, the consumer must wait if the buffer is empty, and the producer must wait if the buffer is full.\\n',\n",
              " '   Lets look more closely at how the bounded buffer illustrates interprocess communication using shared memory. The following variables reside in a region of memory shared by the producer and consumer processes:\\n',\n",
              " 'The shared buffer is implemented as a circular array with two logical pointers: in and out. The variable in points to the next free position in the buffer; out points to the first full position in the buffer. The buffer is empty when in == out; the buffer is full when ((in + 1) % BUFFER SIZE) == out.\\n',\n",
              " '   This scheme allows at most BUFFER SIZE ? 1 items in the buffer at the same time. We leave it as an exercise for you to provide a solution in which BUFFER SIZE items can be in the buffer at the same time. In Section 3.5.1, we illustrate the POSIX API for shared memory.\\n',\n",
              " '    One issue this illustration does not address concerns the situation in which both the producer process and the consumer process attempt to access the shared buffer concurrently. In Chapter 5, we discuss how synchronization among cooperating processes can be implemented effectively in a shared- memory environment.\\n',\n",
              " 'In Section 3.4.1, we showed how cooperating processes can communicate in a shared-memory environment. The scheme requires that these processes share a region of memory and that the code for accessing and manipulating the shared memory be written explicitly by the application programmer. Another way to achieve the same effect is for the operating system to provide the means for cooperating processes to communicate with each other via a message-passing facility.\\n',\n",
              " '    Message passing provides a mechanism to allow processes to communicate and to synchronize their actions without sharing the same address space. It is particularly useful in a distributed environment, where the communicating processes may reside on different computers connected by a network. For example, an Internet chat program could be designed so that chat participants communicate with one another by exchanging messages.\\n',\n",
              " 'Messages sent by a process can be either fixed or variable in size. If only fixed-sized messages can be sent, the system-level implementation is straight- forward. This restriction, however, makes the task of programming more difficult. Conversely, variable-sized messages require a more complex system-\\n',\n",
              " '    If processes P and Q want to communicate, they must send messages to and receive messages from each other: a communication link must exist between them. This link can be implemented in a variety of ways. We are concerned here not with the links physical implementation (such as shared memory, hardware bus, or network, which are covered in Chapter 17) but rather with its logical implementation. Here are several methods for logically implementing a link and the send()/receive() operations:\\n',\n",
              " '   Under direct communication, each process that wants to communicate must explicitly name the recipient or sender of the communication. In this scheme, the send() and receive() primitives are defined as:\\n',\n",
              " '   This scheme exhibits symmetry in addressing; that is, both the sender process and the receiver process must name the other to communicate. A variant of this scheme employs asymmetry in addressing. Here, only the sender names the recipient; the recipient is not required to name the sender. In this scheme, the send() and receive() primitives are defined as follows:\\n',\n",
              " '   The disadvantage in both of these schemes (symmetric and asymmetric) is the limited modularity of the resulting process definitions. Changing the identifier of a process may necessitate examining all other process definitions. All references to the old identifier must be found, so that they can be modified to the new identifier. In general, any such hard-coding techniques, where identifiers must be explicitly stated, are less desirable than techniques involving indirection, as described next.\\n',\n",
              " '   With indirect communication, the messages are sent to and received from mailboxes, or ports.A mailbox can be viewed abstractly as an object into which messages can be placed by processes and from which messages can be removed. Each mailbox has a unique identification. For example, POSIX message queues use an integer value to identify a mailbox. A process can communicate with another process via a number of different mailboxes, but two processes can communicate only if they have a shared mailbox. The send() and receive() primitives are defined as follows:\\n',\n",
              " '   Now suppose that processes P1, P2, and P3 all share mailbox A. Process P1 sends a message to A, while both P2 and P3 execute a receive() from A. Which process will receive the message sent by P1? The answer depends on which of the following methods we choose:\\n',\n",
              " ' Allow the system to select arbitrarily which process will receive the message (that is, either P2 or P3, but not both, will receive the message). The system may define an algorithm for selecting which process will receive the message (for example, round robin, where processes take turns receiving messages). The system may identify the receiver to the sender.\\n',\n",
              " '   A mailbox may be owned either by a process or by the operating system. If the mailbox is owned by a process (that is, the mailbox is part of the address space of the process), then we distinguish between the owner (which can only receive messages through this mailbox) and the user (which can only send messages to the mailbox). Since each mailbox has a unique owner, there can be no confusion about which process should receive a message sent to this mailbox. When a process that owns a mailbox terminates, the mailbox\\n',\n",
              " '   In contrast, a mailbox that is owned by the operating system has an existence of its own. It is independent and is not attached to any particular process. The operating system then must provide a mechanism that allows a process to do the following:\\n',\n",
              " 'The process that creates a new mailbox is that mailboxs owner by default. Initially, the owner is the only process that can receive messages through this mailbox. However, the ownership and receiving privilege may be passed to other processes through appropriate system calls. Of course, this provision could result in multiple receivers for each mailbox.\\n',\n",
              " 'Communication between processes takes place through calls to send() and receive() primitives. There are different design options for implementing each primitive. Message passing may be either blocking or nonblocking  also known as synchronous and asynchronous. (Throughout this text, you will encounter the concepts of synchronous and asynchronous behavior in relation to various operating-system algorithms.)\\n',\n",
              " '   Different combinations of send() and receive() are possible. When both send() and receive() are blocking, we have a rendezvous between the sender and the receiver. The solution to the producer consumer problem becomes trivial when we use blocking send() and receive() statements. The producer merely invokes the blocking send() call and waits until the message is delivered to either the receiver or the mailbox. Likewise, when the consumer invokes receive(), it blocks until a message is available. This is illustrated in Figures 3.15 and 3.16.\\n',\n",
              " ' Bounded capacity. The queue has finite length n; thus, at most n messages can reside in it. If the queue is not full when a new message is sent, the message is placed in the queue (either the message is copied or a pointer to the message is kept), and the sender can continue execution without waiting. The links capacity is finite, however. If the link is full, the sender must block until space is available in the queue.\\n',\n",
              " 'In this section, we explore three different IPC systems. We first cover the POSIX API for shared memory and then discuss message passing in the Mach operating system. We conclude with Windows, which interestingly uses shared memory as a mechanism for providing certain types of message passing.\\n',\n",
              " 'The first parameter specifies the name of the shared-memory object. Processes that wish to access this shared memory must refer to the object by this name. The subsequent parameters specify that the shared-memory object is to be created if it does not yet exist (O CREAT) and that the object is open for reading and writing (O RDRW). The last parameter establishes the directory permissions of the shared-memory object. A successful call to shm open() returns an integer file descriptor for the shared-memory object.\\n',\n",
              " '   Finally, the mmap() function establishes a memory-mapped file containing the shared-memory object. It also returns a pointer to the memory-mapped file that is used for accessing the shared-memory object.\\n',\n",
              " '   The programs shown in Figure 3.17 and 3.18 use the producer  consumer model in implementing shared memory. The producer establishes a shared- memory object and writes to shared memory, and the consumer reads from shared memory.\\n',\n",
              " '   The producer, shown in Figure 3.17, creates a shared-memory object named OS and writes the infamous string \"Hello World!\" to shared memory. The program memory-maps a shared-memory object of the specified size and allows writing to the object. (Obviously, only writing is necessary for the producer.) The flag MAP SHARED specifies that changes to the shared-memory object will be visible to all processes sharing the object. Notice that we write to the shared-memory object by calling the sprintf() function and writing the formatted string to the pointer ptr. After each write, we must increment the pointer by the number of bytes written.\\n',\n",
              " '   The consumer process, shown in Figure 3.18, reads and outputs the contents of the shared memory. The consumer also invokes the shm unlink() function, which removes the shared-memory segment after the consumer has accessed it. We provide further exercises using the POSIX shared-memory API in the programming exercises at the end of this chapter. Additionally, we provide more detailed coverage of memory mapping in Section 9.7.\\n',\n",
              " 'As an example of message passing, we next consider the Mach operating system. You may recall that we introduced Mach in Chapter 2 as part of the Mac OS X operating system. The Mach kernel supports the creation and destruction of multiple tasks, which are similar to processes but have multiple threads of control and fewer associated resources. Most communication in Mach  including all intertask information is carried out by messages. Messages are sent to and received from mailboxes, called ports in Mach.\\n',\n",
              " '   Even system calls are made by messages. When a task is created, two special mailboxes the Kernel mailbox and the Notify mailbox are also created. The kernel uses the Kernel mailbox to communicate with the task and sends notification of event occurrences to the Notify port. Only three system calls are needed for message transfer. The msg send() call sends a message to a mailbox. A message is received via msg receive(). Remote procedure calls (RPCs) are executed via msg rpc(), which sends a message and waits for exactly one return message from the sender. In this way, the RPC models a\\n',\n",
              " '   The port allocate() system call creates a new mailbox and allocates space for its queue of messages. The maximum size of the message queue defaults to eight messages. The task that creates the mailbox is that mailboxs owner. The owner is also allowed to receive from the mailbox. Only one task at a time can either own or receive from a mailbox, but these rights can be sent to other tasks.\\n',\n",
              " '   The mailboxs message queue is initially empty. As messages are sent to the mailbox, the messages are copied into the mailbox. All messages have the same priority. Mach guarantees that multiple messages from the same sender are queued in first-in, first-out (FIFO) order but does not guarantee an absolute ordering. For instance, messages from two senders may be queued in any order. The messages themselves consist of a fixed-length header followed by a variable-length data portion. The header indicates the length of the message and includes two mailbox names. One mailbox name specifies the mailbox\\n',\n",
              " 'to which the message is being sent. Commonly, the sending thread expects a reply, so the mailbox name of the sender is passed on to the receiving task, which can use it as a return address.\\n',\n",
              " '   The variable part of a message is a list of typed data items. Each entry in the list has a type, size, and value. The type of the objects specified in the message is important, since objects defined by the operating system such as ownership or receive access rights, task states, and memory segments may be sent in messages.\\n',\n",
              " '    The send and receive operations themselves are flexible. For instance, when a message is sent to a mailbox, the mailbox may be full. If the mailbox is not full, the message is copied to the mailbox, and the sending thread continues. If the mailbox is full, the sending thread has four options:\\n',\n",
              " '4. Temporarily cache a message. Here, a message is given to the operating system to keep, even though the mailbox to which that message is being sent is full. When the message can be put in the mailbox, a message is sent back to the sender. Only one message to a full mailbox can be pending at any time for a given sending thread.\\n',\n",
              " 'The final option is meant for server tasks, such as a line-printer driver. After finishing a request, such tasks may need to send a one-time reply to the task that requested service, but they must also continue with other service requests, even if the reply mailbox for a client is full.\\n',\n",
              " '   The receive operation must specify the mailbox or mailbox set from which a message is to be received. A mailbox set is a collection of mailboxes, as declared by the task, which can be grouped together and treated as one mailbox for the purposes of the task. Threads in a task can receive only from a mailbox or mailbox set for which the task has receive access. A port status() system call returns the number of messages in a given mailbox. The receive operation attempts to receive from (1) any mailbox in a mailbox set or (2) a specific (named) mailbox. If no message is waiting to be received, the receiving thread can either wait at most n milliseconds or not wait at all.\\n',\n",
              " '   The Mach system was especially designed for distributed systems, which we discuss in Chapter 17, but Mach was shown to be suitable for systems with fewer processing cores, as evidenced by its inclusion in the Mac OS X system. The major problem with message systems has generally been poor performance caused by double copying of messages: the message is copied first from the sender to the mailbox and then from the mailbox to the receiver. The Mach message system attempts to avoid double-copy operations by using virtual-memory-management techniques (Chapter 9). Essentially, Mach maps the address space containing the senders message into the receivers address space. The message itself is never actually copied. This message-management technique provides a large performance boost but works for only intrasystem messages. The Mach operating system is discussed in more detail in the online Appendix B.\\n',\n",
              " 'The Windows operating system is an example of modern design that employs modularity to increase functionality and decrease the time needed to imple- ment new features. Windows provides support for multiple operating envi- ronments, or subsystems. Application programs communicate with these subsystems via a message-passing mechanism. Thus, application programs can be considered clients of a subsystem server.\\n',\n",
              " '   The message-passing facility in Windows is called the advanced local procedure call (ALPC) facility. It is used for communication between two processes on the same machine. It is similar to the standard remote procedure call (RPC) mechanism that is widely used, but it is optimized for and specific to Windows. (Remote procedure calls are covered in detail in Section 3.6.2.) Like Mach, Windows uses a port object to establish and maintain a connection between two processes. Windows uses two types of ports: connection ports and communication ports.\\n',\n",
              " '   Server processes publish connection-port objects that are visible to all processes. When a client wants services from a subsystem, it opens a handle to the servers connection-port object and sendsa connection request to that port. The server then creates a channel and returns a handle to the client. The channel consists of a pair of private communication ports: one for client server messages, the other for server client messages. Additionally, communication channels support a callback mechanism that allows the client and server to accept requests when they would normally be expecting a reply.\\n',\n",
              " '   The client has to decide when it sets up the channel whether it will need to send a large message. If the client determines that it does want to send large messages, it asks for a section object to be created. Similarly, if the server decides that replies will be large, it creates a section object. So that the section object can be used, a small message is sent that contains a pointer and size information about the section object. This method is more complicated than the first method listed above, but it avoids data copying. The structure of advanced local procedure calls in Windows is shown in Figure 3.19.\\n',\n",
              " '   It is important to note that the ALPC facility in Windows is not part of the Windows API and hence is not visible to the application programmer. Rather, applications using the Windows API invoke standard remote procedure calls. When the RPC is being invoked on a process on the same system, the RPC is handled indirectly through an ALPC. procedure call. Additionally, many kernel services use ALPC to communicate with client processes.\\n',\n",
              " 'In Section 3.4, we described how processes can communicate using shared memory and message passing. These techniques can be used for communica- tion in client server systems (Section 1.11.4) as well. In this section, we explore three other strategies for communication in client server systems: sockets, remote procedure calls (RPCs), and pipes.\\n',\n",
              " 'A socket is defined as an endpoint for communication. A pair of processes communicating over a network employs a pair of sockets  one for each process. A socket is identified by an IP address concatenated with a port number. In general, sockets use a client server architecture. The server waits for incoming client requests by listening to a specified port. Once a request is received, the server accepts a connection from the client socket to complete the connection. Servers implementing specific services (such as telnet, FTP, and HTTP) listen to well-known ports (a telnet server listens to port 23; an FTP server listens to port 21; and a web, or HTTP, server listens to port 80). All ports below 1024 are considered well known; we can use them to implement standard services.\\n',\n",
              " '   When a client process initiates a request for a connection, it is assigned a port by its host computer. This port has some arbitrary number greater than 1024. For example, if a client on host X with IP address 146.86.5.20 wishes to establish a connection with a web server (which is listening on port 80) at address 161.25.19.8, host X may be assigned port 1625. The connection will consist of a pair of sockets: (146.86.5.20:1625) on host X and (161.25.19.8:80) on the web server. This situation is illustrated in Figure 3.20. The packets traveling between the hosts are delivered to the appropriate process based on the destination port number.\\n',\n",
              " '   All connections must be unique. Therefore, if another process also on host X wished to establish another connection with the same web server, it would be assigned a port number greater than 1024 and not equal to 1625. This ensures that all connections consist of a unique pair of sockets.\\n',\n",
              " '   Although most program examples in this text use C, we will illustrate sockets using Java, as it provides a much easier interface to sockets and has a rich library for networking utilities. Those interested in socket programming in C or C++ should consult the bibliographical notes at the end of the chapter. Java provides three different types of sockets. Connection-oriented (TCP) sockets are implemented with the Socket class. Connectionless (UDP) sockets use the DatagramSocket class. Finally, the MulticastSocketclass is a subclass of the DatagramSocket class. A multicast socket allows data to be sent to\\n',\n",
              " '   Our example describes a date server that uses connection-oriented TCP sockets. The operation allows clients to request the current date and time from the server. The server listens to port 6013, although the port could have any arbitrary number greater than 1024. When a connection is received, the server returns the date and time to the client.\\n',\n",
              " '   The date server is shown in Figure 3.21. The server creates a ServerSocket that specifies that it will listen to port 6013. The server then begins listening to the port with the accept() method. The server blocks on the accept() method waiting for a client to request a connection. When a connection request is received, accept() returns a socket that the server can use to communicate with the client.\\n',\n",
              " '   The details of how the server communicates with the socket are as follows. The server first establishes a PrintWriter object that it will use to communicate with the client. A PrintWriter object allows the server to write to the socket using the routine print() and println() methods for output. The server process sends the date to the client, calling the method println(). Once it has written the date to the socket, the server closes the socket to the client and resumes listening for more requests.\\n',\n",
              " '   A client communicates with the server by creating a socket and connecting to the port on which the server is listening. We implement such a client in the Java program shown in Figure 3.22. The client creates a Socket and requests a connection with the server at IP address 127.0.0.1 on port 6013. Once the connection is made, the client can read from the socket using normal stream I/O statements. After it has received the date from the server, the client closes\\n',\n",
              " 'the socket and exits. The IP address 127.0.0.1 is a special IP address known as the loopback. Whena computer refers to IP address 127.0.0.1, it is referring to itself. This mechanism allows a client and server on the same host to communicate using the TCP/IP protocol. The IP address 127.0.0.1 could be replaced with the IP address of another host running the date server. In addition to an IP address, an actual host name, such as www.westminstercollege.edu, can be used as well.\\n',\n",
              " '    Communication using sockets  although common and efficient  is con- sidered a low-level form of communication between distributed processes. One reason is that sockets allow only an unstructured stream of bytes to be exchanged between the communicating threads. It is the responsibility of the client or server application to impose a structure on the data. In the next two subsections, we look at two higher-level methods of communication: remote procedure calls (RPCs) and pipes.\\n',\n",
              " 'abstract the procedure-call mechanism for use between systems with network connections. It is similar in many respects to the IPC mechanism described in Section 3.4, and it is usually built on top of such a system. Here, however, because we are dealing with an environment in which the processes are executing on separate systems, we must use a message-based communication scheme to provide remote service.\\n',\n",
              " '    In contrast to IPC messages, the messages exchanged in RPC communication are well structured and are thus no longer just packets of data. Each message is addressed to an RPC daemon listening to a port on the remote system, and each contains an identifier specifying the function to execute and the parameters to pass to that function. The function is then executed as requested, and any output is sent back to the requester in a separate message.\\n',\n",
              " '   A port is simply a number included at the start of a message packet. Whereas a system normally has one network address, it can have many ports within that address to differentiate the many network services it supports. If a remote process needs a service, it addresses a message to the proper port. For instance, if a system wished to allow other systems to be able to list its current users, it would have a daemon supporting such an RPC attached to a port say, port 3027. Any remote system could obtain the needed information (that\\n',\n",
              " '   The semantics of RPCs allows a client to invoke a procedure on a remote host as it would invoke a procedure locally. The RPC system hides the details that allow communication to take place by providing a stub on the client side. Typically, a separate stub exists for each separate remote procedure. When the client invokes a remote procedure, the RPC system calls the appropriate stub, passing it the parameters provided to the remote procedure. This stub locates the port on the server and marshals the parameters. Parameter marshalling involves packaging the parameters into a form that can be transmitted over a network. The stub then transmits a message to the server using message passing. A similar stub on the server side receives this message and invokes the procedure on the server. If necessary, return values are passed back to the client using the same technique. On Windows systems, stub code is compiled from a specification written in the Microsoft Interface Definition Language (MIDL), which is used for defining the interfaces between client and server programs.\\n',\n",
              " '   One issue that must be dealt with concerns differences in data representa- tion on the client and server machines. Consider the representation of 32-bit integers. Some systems (known as big-endian) store the most significant byte first, while other systems (known as little-endian) store the least significant byte first. Neither order is better per se; rather, the choice is arbitrary within a computer architecture. To resolve differences like this, many RPC systems define a machine-independent representation of data. One such representation is known as external data representation (XDR). On the client side, parameter marshalling involves converting the machine-dependent data into XDR before they are sent to the server. On the server side, the XDR data are unmarshalled and converted to the machine-dependent representation for the server.\\n',\n",
              " '   Another important issue involves the semantics of a call. Whereas local procedure calls fail only under extreme circumstances, RPCs can fail, or be duplicated and executed more than once, as a result of common network errors. One way to address this problem is for the operating system to ensure that messages are acted on exactly once, rather than at most once. Most local procedure calls have the exactly once functionality, but it is more difficult to implement.\\n',\n",
              " '   First, consider at most once. This semantic can be implemented by attaching a timestamp to each message. The server must keep a history of all the timestamps of messages it has already processed or a history large enough to ensure that repeated messages are detected. Incoming messages that have a timestamp already in the history are ignored. The client can then send a message one or more times and be assured that it only executes once.\\n',\n",
              " '   For exactly once, we need to remove the risk that the server will never receive the request. To accomplish this, the server must implement the at most once protocol described above but must also acknowledge to the client that the RPC call was received and executed. These ACK messages are common throughout networking. The client must resend each RPC call periodically until it receives the ACK for that call.\\n',\n",
              " '    Yet another important issue concerns the communication between a server and a client. With standard procedure calls, some form of binding takes place during link, load, or execution time (Chapter 8) so that a procedure calls name\\n',\n",
              " 'is replaced by the memory address of the procedure call. The RPC scheme requires a similar binding of the client and the server port, but how does a client know the port numbers on the server? Neither system has full information about the other, because they do not share memory.\\n',\n",
              " '   Two approaches are common. First, the binding information may be predetermined, in the form of fixed port addresses. At compile time, an RPC call has a fixed port number associated with it. Once a program is compiled, the server cannot change the port number of the requested service. Second, binding can be done dynamically by a rendezvous mechanism. Typically, an operating system provides a rendezvous (also called a matchmaker) daemon on a fixed RPC port. A client then sends a message containing the name of the RPC to the rendezvous daemon requesting the port address of the RPC it needs to execute. The port number is returned, and the RPC calls can be sent to that port until the process terminates (or the server crashes). This method requires the extra overhead of the initial request but is more flexible than the first approach. Figure 3.23 shows a sample interaction.\\n',\n",
              " 'and clients. The messages are addressed to the distributed file system port on a server on which a file operation is to take place. The message contains the disk operation to be performed. The disk operation might be read, write, rename, delete, or status, corresponding to the usual file-related system calls. The return message contains any data resulting from that call, which is executed by the DFS daemon on behalf of the client. For instance, a message might contain a request to transfer a whole file to a client or be limited to a simple block request. In the latter case, several requests may be needed if a whole file is to be transferred.\\n',\n",
              " 'A pipe acts as a conduit allowing two processes to communicate. Pipes were one of the first IPC mechanisms in early UNIX systems. They typically provide one of the simpler ways for processes to communicate with one another, although they also have some limitations. In implementing a pipe, four issues must be considered:\\n',\n",
              " 'Ordinary pipes allow two processes to communicate in standard producer consumer fashion: the producer writes to one end of the pipe (the write-end) and the consumer reads from the other end (the read-end). As a result, ordinary pipes are unidirectional, allowing only one-way communication. If two-way communication is required, two pipes must be used, with each pipe sending data in a different direction. We next illustrate constructing ordinary pipes on both UNIX and Windows systems. In both program examples, one process writes the message Greetings to the pipe, while the other process reads this message from the pipe.\\n',\n",
              " '   An ordinary pipe cannot be accessed from outside the process that created it. Typically, a parent process creates a pipe and uses it to communicate with a child process that it creates via fork(). Recall from Section 3.3.1 that a child process inherits open files from its parent. Since a pipe is a special type of file, the child inherits the pipe from its parent process. Figure 3.24 illustrates the relationship of the file descriptor fd to the parent and child processes.\\n',\n",
              " '   In the UNIX program shown in Figure 3.25, the parent process creates a pipe and then sends a fork() call creating the child process. What occurs after the fork() call depends on how the data are to flow through the pipe. In this instance, the parent writes to the pipe, and the child reads from it. It is important to notice that both the parent process and the child process initially close their unused ends of the pipe. Although the program shown in Figure\\n',\n",
              " '3.25 does not require this action, it is an important step to ensure that a process reading from the pipe can detect end-of-file (read() returns 0) when the writer has closed its end of the pipe.\\n',\n",
              " 'employ parent child relationships between the communicating processes. In addition, reading and writing to the pipe can be accomplished with the ordinary ReadFile() and WriteFile() functions. The Windows API for creating pipes is the CreatePipe() function, which is passed four parameters. The parameters provide separate handles for (1) reading and (2) writing to the pipe, as well as (3) an instance of the STARTUPINFO structure, which is used to specify that the child process is to inherit the handles of the pipe. Furthermore,\\n',\n",
              " 'automatically inherits a pipe created by its parent, Windows requires the programmer to specify which attributes the child process will inherit. This is accomplished by first initializing the SECURITY ATTRIBUTES structure to allow handles to be inherited and then redirecting the child processs handles for standard input or standard output to the read or write handle of the pipe. Since the child will be reading from the pipe, the parent must redirect the childs standard input to the read handle of the pipe. Furthermore, as the pipes are half duplex, it is necessary to prohibit the child from inheriting the write-end of the pipe. The program to create the child process is similar to the program in Figure 3.11, except that the fifth parameter is set to TRUE, indicating that the child process is to inherit designated handles from its parent. Before writing to the pipe, the parent first closes its unused read end of the pipe. The child process that reads from the pipe is shown in Figure 3.29. Before reading from the pipe, this program obtains the read handle to the pipe by invoking GetStdHandle().\\n',\n",
              " '    Note that ordinary pipes require a parent child relationship between the communicating processes on both UNIX and Windows systems. This means that these pipes can be used only for communication between processes on the same machine.\\n',\n",
              " 'Ordinary pipes provide a simple mechanism for allowing a pair of processes to communicate. However, ordinary pipes exist only while the processes are communicating with one another. On both UNIX and Windows systems, once the processes have finished communicating and have terminated, the ordinary pipe ceases to exist.\\n',\n",
              " '   Named pipes provide a much more powerful communication tool. Com- munication can be bidirectional, and no parent child relationship is required. Once a named pipe is established, several processes can use it for communi- cation. In fact, in a typical scenario, a named pipe has several writers. Addi- tionally, named pipes continue to exist after communicating processes have\\n',\n",
              " '   Named pipes are referred to as FIFOs in UNIX systems. Once created, they appear as typical files in the file system. A FIFO is created with the mkfifo() system call and manipulated with the ordinary open(), read(), write(), and close() system calls. It will continue to exist until it is explicitly deleted from the file system. Although FIFOs allow bidirectional communication, only half-duplex transmission is permitted. If data must travel in both directions, two FIFOs are typically used. Additionally, the communicating processes must reside on the same machine. If intermachine communication is required, sockets (Section 3.6.1) must be used.\\n',\n",
              " '    Named pipes on Windows systems provide a richer communication mech- anism than their UNIX counterparts. Full-duplex communication is allowed, and the communicating processes may reside on either the same or different machines. Additionally, only byte-oriented data may be transmitted across a UNIX FIFO, whereas Windows systems allow either byte- or message-oriented data. Named pipes are created with the CreateNamedPipe() function, and a client can connect to a named pipe using ConnectNamedPipe(). Communi- cation over the named pipe can be accomplished using the ReadFile() and WriteFile() functions.\\n',\n",
              " 'A process is a program in execution. As a process executes, it changes state. The state of a process is defined by that processs current activity. Each process may be in one of the following states: new, ready, running, waiting, or terminated.\\n',\n",
              " 'Pipes are used quite often in the UNIX command-line environment for situations in which the output of one command serves as input to another. For example, the UNIX ls command produces a directory listing. For especially long directory listings, the output may scroll through several screens. The command more manages output by displaying only one screen of output at a time; the user must press the space bar to move from one screen to the next. Setting up a pipe between the ls and more commands (which are running as individual processes) allows the output of ls to be delivered as the input to more, enabling the user to display a large directory listing a screen at a time. A pipe can be constructed on the command line using the | character. The complete command is\\n',\n",
              " '  Windows systems provide a more command for the DOS shell with functionality similar to that of its UNIX counterpart. The DOS shell also uses the | character for establishing a pipe. The only difference is that to get a directory listing, DOS uses the dir command rather than ls, as shown below:\\n',\n",
              " '   A process, when it is not executing, is placed in some waiting queue. There are two major classes of queues in an operating system: I/O request queues and the ready queue. The ready queue contains all the processes that are ready to execute and are waiting for the CPU. Each process is represented by a PCB.\\n',\n",
              " '   The operating system must select processes from various scheduling queues. Long-term (job) scheduling is the selection of processes that will be allowed to contend for the CPU. Normally, long-term scheduling is heavily influenced by resource-allocation considerations, especially memory manage- ment. Short-term (CPU) scheduling is the selection of one process from the ready queue.\\n',\n",
              " '   Operating systems must provide a mechanism for parent processes to create new child processes. The parent may wait for its children to terminate before proceeding, or the parent and children may execute concurrently. There are several reasons for allowing concurrent execution: information sharing, computation speedup, modularity, and convenience.\\n',\n",
              " '    The processes executing in the operating system may be either independent processes or cooperating processes. Cooperating processes require an interpro- cess communication mechanism to communicate with each other. Principally, communication is achieved through two schemes: shared memory and mes- sage passing. The shared-memory method requires communicating processes\\n',\n",
              " 'to share some variables. The processes are expected to exchange information through the use of these shared variables. In a shared-memory system, the responsibility for providing communication rests with the application pro- grammers; the operating system needs to provide only the shared memory. The message-passing method allows the processes to exchange messages. The responsibility for providing communication may rest with the operating system itself. These two schemes are not mutually exclusive and can be used simultaneously within a single operating system.\\n',\n",
              " '    Communication in client server systems may use (1) sockets, (2) remote procedure calls (RPCs), or (3) pipes. A socket is defined as an endpoint for communication. A connection between a pair of applications consists of a pair of sockets, one at each end of the communication channel. RPCs are another form of distributed communication. An RPC occurs when a process (or thread) calls a procedure on a remote application. Pipes provide a relatively simple ways for processes to communicate with one another. Ordinary pipes allow communication between parent and child processes, while named pipes permit unrelated processes to communicate.\\n',\n",
              " '3.3 Original versions of Apples mobile iOS operating system provided no means of concurrent processing. Discuss three major complications that concurrent processing adds to an operating system.\\n',\n",
              " '3.4 The Sun UltraSPARC processor has multiple register sets. Describe what happens when a context switch occurs if the new context is already loaded into one of the register sets. What happens if the new context is in memory rather than in a register set and all the register sets are in use?\\n',\n",
              " '3.6 Consider the exactly oncesemantic with respect to the RPC mechanism. Does the algorithm for implementing this semantic execute correctly even if the ACK message sent back to the client is lost due to a network problem? Describe the sequence of messages, and discuss whether exactly once is still preserved.\\n',\n",
              " 'Use the command man ps to get more information about the ps com- mand. The task manager on Windows systems does not provide the parent process ID, but the process monitor tool, available from tech- net.microsoft.com, provides a process-tree tool.\\n',\n",
              " '3.16 Consider the RPC mechanism. Describe the undesirable consequences that could arise from not enforcing either the at most once or exactly once semantic. Describe possible uses for a mechanism that has neither of these guarantees.\\n',\n",
              " '3.19 Using either a UNIX or a Linux system, write a C program that forks a child process that ultimately becomes a zombie process. This zombie process must remain in the system for at least 10 seconds. Process states can be obtained from the command\\n',\n",
              " 'The process states are shown below the S column; processes with a state of Z are zombies. The process identifier (pid) of the child process is listed in the PID column, and that of the parent is listed in the PPID column.\\n',\n",
              " '   Perhaps the easiest way to determine that the child process is indeed a zombie is to run the program that you have written in the background (using the &) and then run the command ps -l to determine whether the child is a zombie process. Because you do not want too many zombie processes existing in the system, you will need to remove the one that you have created. The easiest way to do that is to terminate the parent process using the kill command. For example, if the process id of the parent is 4884, you would enter\\n',\n",
              " '3.20 An operating systems pid manager is responsible for managing process identifiers. When a process is first created, it is assigned a unique pid by the pid manager. The pid is returned to the pid manager when the process completes execution, and the manager may later reassign this pid. Process identifiers are discussed more fully in Section 3.3.1. What is most important here is to recognize that process identifiers must be unique; no two active processes can have the same pid.\\n',\n",
              " 'You may use any data structure of your choice to represent the avail- ability of process identifiers. One strategy is to adopt what Linux has done and use a bitmap in which a value of 0 at position i indicates that a process id of value i is available and a value of 1 indicates that the process id is currently in use.\\n',\n",
              " 'Write a C program using the fork() system call that generates this sequence in the child process. The starting number will be provided from the command line. For example, if 8 is passed as a parameter on the command line, the child process will output 8, 4, 2, 1. Because the parent and child processes have their own copies of the data, it will be necessary for the child to output the sequence. Have the parent invoke the wait() call to wait for the child process to complete before exiting the program. Perform necessary error checking to ensure that a positive integer is passed on the command line.\\n',\n",
              " '3.22 In Exercise 3.21, the child process must output the sequence of numbers generated from the algorithm specified by the Collatz conjecture because the parent and child have their own copies of the data. Another approach to designing this program is to establish a shared-memory object between the parent and child processes. This technique allows the child to write the contents of the sequence to the shared-memory object. The parent can then output the sequence when the child completes. Because the memory is shared, any changes the child makes will be reflected in the parent process as well.\\n',\n",
              " '   One area of concern with cooperating processes involves synchro- nization issues. In this exercise, the parent and child processes must be coordinated so that the parent does not output the sequence until the child finishes execution. These two processes will be synchronized using the wait() system call: the parent process will invoke wait(), which will suspend it until the child process exits.\\n',\n",
              " '   Modify the date server shown in Figure 3.21 so that it delivers a quote of the day rather than the current date. The quotes should be printable ASCII characters and should contain fewer than 512 characters, although multiple lines are allowed. Since port 17 is well known and therefore unavailable, have your server listen to port 6017. The date client shown in Figure 3.22 can be used to read the quotes returned by your server.\\n',\n",
              " '3.24 A haiku is a three-line poem in which the first line contains five syllables, the second line contains seven syllables, and the third line contains five syllables. Write a haiku server that listens to port 5575. When a client connects to this port, the server responds with a haiku. The date client shown in Figure 3.22 can be used to read the quotes returned by your haiku server.\\n',\n",
              " '   Write an echo server using the Java networking API described in Section 3.6.1. This server will wait for a client connection using the accept() method. When a client connection is received, the server will loop, performing the following steps:\\n',\n",
              " '        The date server shown in Figure 3.21 uses the java.io.BufferedReader class. BufferedReader extends the java.io.Reader class, which is used for reading character streams. However, the echo server cannot guarantee that it will read characters from clients; it may receive binary data as  well.  The class java.io.InputStream deals with data at the byte level rather than the character level. Thus, your echo server must use an object that extends java.io.InputStream. The read() method in the java.io.InputStream class returns  1 when the client has closed its end of the socket connection.\\n',\n",
              " '3.26 Design a program using ordinary pipes in which one process sends a string message to a second process, and the second process reverses the case of each character in the message and sends it back to the first process. For example, if the first process sends the message Hi There, the second process will return hI tHERE. This will require using two pipes, one for sending the original message from the first to the second process and the other for sending the modified message from the second to the first process. You can write this program using either UNIX or Windows pipes.\\n',\n",
              " 'copied and the name of the copied file. The program will then create an ordinary pipe and write the contents of the file to be copied to the pipe. The child process will read this file from the pipe and write it to the destination file. For example, if we invoke the program as follows:\\n',\n",
              " 'the file input.txt will be written to the pipe. The child process will read the contents of this file and write it to the destination file copy.txt. You may write this program using either UNIX or Windows pipes.\\n',\n",
              " 'This project consists of designing a C program to serve as a shell interface that accepts user commands and then executes each command in a separate process. This project can be completed on any Linux, UNIX, or Mac OS X system.\\n',\n",
              " '   A shell interface gives the user a prompt, after which the next command is entered. The example below illustrates the prompt osh> and the users next command: cat prog.c. (This command displays the file prog.c on the terminal using the UNIX cat command.)\\n',\n",
              " 'One technique for implementing a shell interface is to have the parent process first read what the user enters on the command line (in this case, cat prog.c), and then create a separate child process that performs the command. Unless otherwise specified, the parent process waits for the child to exit before continuing. This is similar in functionality to the new process creation illustrated in Figure 3.10. However, UNIX shells typically also allow the child process to run in the background, or concurrently. To accomplish this, we add an ampersand (&) at the end of the command. Thus, if we rewrite the above command as\\n',\n",
              " '   A C program that provides the general operations of a command-line shell is supplied in Figure 3.36. The main() function presents the prompt osh-> and outlines the steps to be taken after input from the user has been read. The main() function continually loops as long as should run equals 1; when the user enters exit at the prompt, your program will set should run to 0 and terminate.\\n',\n",
              " 'The first task is to modify the main() function in Figure 3.36 so that a child process is forked and executes the command specified by the user. This will require parsing what the user has entered into separate tokens and storing the tokens in an array of character strings (args in Figure 3.36). For example, if the user enters the command ps -ael at the osh> prompt, the values stored in the args array are:\\n',\n",
              " 'Here, command represents the command to be performed and params stores the parameters to this command. For this project, the execvp() function should be invoked as execvp(args[0], args). Be sure to check whether the user included an & to determine whether or not the parent process is to wait for the child to exit.\\n',\n",
              " 'The next task is to modify the shell interface program so that it provides a history feature that allows the user to access the most recently entered commands. The user will be able to access up to 10 commands by using the feature. The commands will be consecutively numbered starting at 1, and the numbering will continue past 10. For example, if the user has entered 35 commands, the 10 most recent commands will be numbered 26 to 35.\\n',\n",
              " '   Continuing our example from above, if the user enters !!, the ps command will be performed; if the user enters !3, the command cal will be executed. Any command executed in this fashion should be echoed on the users screen. The command should also be placed in the history buffer as the next command.\\n',\n",
              " '   The program should also manage basic error handling. If there are no commands in the history, entering !! should result in a message No commands in history. If there is no command corresponding to the number entered with the single !, the program should output \"No such command in history.\"\\n',\n",
              " 'In this project, you will write a kernel module that lists all current tasks in a Linux system. Be sure to review the programming project in Chapter 2, which deals with creating Linux kernel modules, before you begin this project. The project can be completed using the Linux virtual machine provided with this text.\\n',\n",
              " 'As illustrated in Section 3.1, the PCB in Linux is represented by the structure task struct, which is found in the <linux/sched.h> include file. In Linux, the for each process() macro easily allows iteration over all current tasks in the system:\\n',\n",
              " 'Design a kernel module that iterates through all tasks in the system using the for each process() macro. In particular, output the task name (known as executable name), state, and process id of each task. (You will probably have to read through the task struct structure in <linux/sched.h> to obtain the names of these fields.) Write this code in the module entry point so that its contents will appear in the kernel log buffer, which can be viewed using the dmesg command. To verify that your code is working correctly, compare the contents of the kernel log buffer with the output of the following command, which lists all tasks in the system:\\n',\n",
              " 'The second portion of this project involves iterating over all tasks in the system using a depth-first search (DFS) tree. (As an example: the DFS iteration of the processes in Figure 3.8 is 1, 8415, 8416, 9298, 9204, 2, 6, 200, 3028, 3610, 4005.)\\n',\n",
              " 'These objects are pointers to a list of the tasks children, as well as its sib- lings. Linux also maintains references to the init task (struct task struct init task). Using this information as well as macro operations on lists, we can iterate over the children of init as follows:\\n',\n",
              " 'At each iteration of list for each(), the first parameter is set to the list structure of the next child. We then use this value to obtain each structure in the list using the list entry() macro.\\n',\n",
              " 'Beginning from the init task, design a kernel module that iterates over all tasks in the system using a DFS tree. Just as in the first part of this project, output the name, state, and pid of each task. Perform this iteration in the kernel entry module so that its output appears in the kernel log buffer.\\n',\n",
              " '   If you output all tasks in the system, you may see many more tasks than appear with the ps -ael command. This is because some threads appear as children but do not show up as ordinary processes. Therefore, to check the output of the DFS tree, use the command\\n',\n",
              " 'This command lists all tasks including threads in the system. To verify that you have indeed performed an appropriate DFS iteration, you will have to examine the relationships among the various tasks output by the ps command.\\n',\n",
              " 'Process creation, management, and IPC in UNIX and Windows systems, respectively, are discussed in [Robbins and Robbins (2003)] and [Russinovich and Solomon (2009)]. [Love (2010)] covers support for processes in the Linux kernel, and [Hart (2005)] covers Windows systems programming in detail. Coverage of the multiprocess model used in Googles Chrome can be found at http://blog.chromium.org/2008/09/multi-process-architecture.html.\\n',\n",
              " '   Message passing for multicore systems is discussed in [Holland and Seltzer (2011)]. [Baumann et al. (2009)] describe performance issues in shared- memory and message-passing systems. [Vahalia (1996)] describes interprocess communication in the Mach system.\\n',\n",
              " '   The implementation of RPCs is discussed by [Birrell and Nelson (1984)]. [Staunstrup (1982)] discusses procedure calls versus message-passing com- munication. [Harold (2005)] provides coverage of socket programming in Java.\\n',\n",
              " '[Holland and Seltzer (2011)] D. Holland and M. Seltzer, Multicore OSes: look- ing forward from 1991, er, 2011, Proceedings of the 13th USENIX conference on Hot topics in operating systems (2011), pages 3333.\\n',\n",
              " 'The process model introduced in Chapter 3 assumed that a process was an executing program with a single thread of control. Virtually all modern operating systems, however, provide features enabling a process to contain multiple threads of control. In this chapter, we introduce many concepts associated with multithreaded computer systems, including a discussion of the APIs for the Pthreads, Windows, and Java thread libraries. We look at a number of issues related to multithreaded programming and its effect on the design of operating systems. Finally, we explore how the Windows and Linux operating systems support threads at the kernel level.\\n',\n",
              " 'A thread is a basic unit of CPU utilization; it comprises a thread ID, a program counter, a register set, and a stack. It shares with other threads belonging to the same process its code section, data section, and other operating-system resources, such as open files and signals. A traditional (or heavyweight) process has a single thread of control. If a process has multiple threads of control, it can perform more than one task at a time. Figure 4.1 illustrates the difference between a traditional single-threaded process and a multithreaded process.\\n',\n",
              " 'threads of control. A web browser might have one thread display images or text while another thread retrieves data from the network, for example. A word processor may have a thread for displaying graphics, another thread for responding to keystrokes from the user, and a third thread for performing spelling and grammar checking in the background. Applications can also be designed to leverage processing capabilities on multicore systems. Such applications can perform several CPU-intensive tasks in parallel across the multiple computing cores.\\n',\n",
              " '   In certain situations, a single application may be required to perform several similar tasks. For example, a web server accepts client requests for web pages, images, sound, and so forth. A busy web server may have several (perhaps thousands of) clients concurrently accessing it. If the web server ran as a traditional single-threaded process, it would be able to service only one client at a time, and a client might have to wait a very long time for its request to be serviced.\\n',\n",
              " '   One solution is to have the server run as a single process that accepts requests. When the server receives a request, it creates a separate process to service that request. In fact, this process-creation method was in common use before threads became popular. Process creation is time consuming and resource intensive, however. If the new process will perform the same tasks as the existing process, why incur all that overhead? It is generally more efficient to use one process that contains multiple threads. If the web-server process is multithreaded, the server will create a separate thread that listens for client requests. When a request is made, rather than creating another process, the server creates a new thread to service the request and resume listening for additional requests. This is illustrated in Figure 4.2.\\n',\n",
              " '    Threads also play a vital role in remote procedure call (RPC) systems. Recall from Chapter 3 that RPCs allow interprocess communication by providing a communication mechanism similar to ordinary function or procedure calls. Typically, RPC servers are multithreaded. When a server receives a message, it\\n',\n",
              " '   Finally, most operating-system kernels are now multithreaded. Several threads operate in the kernel, and each thread performs a specific task, such as managing devices, managing memory, or interrupt handling. For example, Solaris has a set of threads in the kernel specifically for interrupt handling; Linux uses a kernel thread for managing the amount of free memory in the system.\\n',\n",
              " '1. Responsiveness. Multithreading an interactive application may allow a program to continue running even if part of it is blocked or is performing a lengthy operation, thereby increasing responsiveness to the user. This quality is especially useful in designing user interfaces. For instance, consider what happens when a user clicks a button that results in the performance of a time-consuming operation. A single-threaded application would be unresponsive to the user until the operation had completed. In contrast, if the time-consuming operation is performed in a separate thread, the application remains responsive to the user.\\n',\n",
              " '2. Resource sharing. Processes can only share resources through techniques such as shared memory and message passing. Such techniques must be explicitly arranged by the programmer. However, threads share the memory and the resources of the process to which they belong by default. The benefit of sharing code and data is that it allows an application to have several different threads of activity within the same address space.\\n',\n",
              " '3. Economy. Allocating memory and resources for process creation is costly. Because threads share the resources of the process to which they belong, it is more economical to create and context-switch threads. Empirically gauging the difference in overhead can be difficult, but in general it is significantly more time consuming to create and manage processes than threads. In Solaris, for example, creating a process is about thirty times\\n',\n",
              " '4. Scalability. The benefits of multithreading can be even greater in a multiprocessor architecture, where threads may be running in parallel on different processing cores. A single-threaded process can run on only one processor, regardless how many are available. We explore this issue further in the following section.\\n',\n",
              " 'Earlier in the history of computer design, in response to the need for more computing performance, single-CPU systems evolved into multi-CPU systems. A more recent, similar trend in system design is to place multiple computing cores on a single chip. Each core appears as a separate processor to the operating system (Section 1.3.2). Whether the cores appear across CPU chips or within CPU chips, we call these systems multicore or multiprocessor systems. Multithreaded programming provides a mechanism for more efficient use of these multiple computing cores and improved concurrency. Consider an application with four threads. On a system with a single computing core, concurrency merely means that the execution of the threads will be interleaved over time (Figure 4.3), because the processing core is capable of executing only one thread at a time. On a system with multiple cores, however, concurrency means that the threads can run in parallel, because the system can assign a separate thread to each core (Figure 4.4).\\n',\n",
              " '   Notice the distinction between parallelism and concurrency in this discus- sion. A system is parallel if it can perform more than one task simultaneously. In contrast, a concurrent system supports more than one task by allowing all the tasks to make progress. Thus, it is possible to have concurrency without parallelism. Before the advent of SMP and multicore architectures, most com- puter systems had only a single processor. CPU schedulers were designed to provide the illusion of parallelism by rapidly switching between processes in\\n',\n",
              " 'Amdahls Law is a formula that identifies potential performance gains from adding additional computing cores to an application that has both serial (nonparallel) and parallel components. If S is the portion of the application that must be performed serially on a system with N processing cores, the formula appears as follows:\\n',\n",
              " 'As an example, assume we have an application that is 75 percent parallel and 25 percent serial. If we run this application on a system with two processing cores, we can get a speedup of 1.6 times. If we add two additional cores (for a total of four), the speedup is 2.28 times.\\n',\n",
              " '  One interesting fact about Amdahls Law is that as N approaches infinity, the speedup converges to 1/S. For example, if 40 percent of an application is performed serially, the maximum speedup is 2.5 times, regardless of the number of processing cores we add. This is the fundamental principle behind Amdahls Law: the serial portion of an application can have a disproportionate effect on the performance we gain by adding additional computing cores.\\n',\n",
              " '  Some argue that Amdahls Law does not take into account the hardware performance enhancements used in the design of contemporary multicore systems. Such arguments suggest Amdahls Law may cease to be applicable as the number of processing cores continues to increase on modern computer systems.\\n',\n",
              " '   As systems have grown from tens of threads to thousands of threads, CPU designers have improved system performance by adding hardware to improve thread performance. Modern Intel CPUs frequently support two threads per core, while the Oracle T4 CPU supports eight threads per core. This support means that multiple threads can be loaded into the core for fast switching. Multicore computers will no doubt continue to increase in core counts and hardware thread support.\\n',\n",
              " 'The trend towards multicore systems continues to place pressure on system designers and application programmers to make better use of the multiple computing cores. Designers of operating systems must write scheduling algorithms that use multiple processing cores to allow the parallel execution shown in Figure 4.4. For application programmers, the challenge is to modify existing programs as well as design new programs that are multithreaded.\\n',\n",
              " '1. Identifying tasks. This involves examining applications to find areas that can be divided into separate, concurrent tasks. Ideally, tasks are independent of one another and thus can run in parallel on individual cores.\\n',\n",
              " '2. Balance. While identifying tasks that can run in parallel, programmers must also ensure that the tasks perform equal work of equal value. In some instances, a certain task may not contribute as much value to the overall process as other tasks. Using a separate execution core to run that task may not be worth the cost.\\n',\n",
              " '4. Data dependency. The data accessed by the tasks must be examined for dependencies between two or more tasks. When one task depends on data from another, programmers must ensure that the execution of the tasks is synchronized to accommodate the data dependency. We examine such strategies in Chapter 5.\\n',\n",
              " '5. Testing and debugging. When a program is running in parallel on multiple cores, many different execution paths are possible. Testing and debugging such concurrent programs is inherently more difficult than testing and debugging single-threaded applications.\\n',\n",
              " 'Because of these challenges, many software developers argue that the advent of multicore systems will require an entirely new approach to designing software systems in the future. (Similarly, many computer science educators believe that software development must be taught with increased emphasis on parallel programming.)\\n',\n",
              " 'In general, there are two types of parallelism: data parallelism and task parallelism. Data parallelism focuses on distributing subsets of the same data across multiple computing cores and performing the same operation on each core. Consider, for example, summing the contents of an array of size N. On a single-core system, one thread would simply sum the elements [0] . . . [N 1]. On a dual-core system, however, thread A, running on core 0, could sum the elements [0] . . . [N/2 1] while thread B, running on core 1, could sum the elements [N/2] . . . [N 1]. The two threads would be running in parallel on separate computing cores.\\n',\n",
              " '   Task parallelism involves distributing not data but tasks (threads) across multiple computing cores. Each thread is performing a unique operation. Different threads may be operating on the same data, or they may be operating on different data. Consider again our example above. In contrast to that situation, an example of task parallelism might involve two threads, each performing a unique statistical operation on the array of elements. The threads again are operating in parallel on separate computing cores, but each is performing a unique operation.\\n',\n",
              " '   Fundamentally, then, data parallelism involves the distribution of data across multiple cores and task parallelism on the distribution of tasks across multiple cores. In practice, however, few applications strictly follow either data or task parallelism. In most instances, applications use a hybrid of these two strategies.\\n',\n",
              " 'Our discussion so far has treated threads in a generic sense. However, support for threads may be provided either at the user level, for user threads, or by the kernel, for kernel threads. User threads are supported above the kernel and are managed without kernel support, whereas kernel threads are supported and managed directly by the operating system. Virtually all contemporary operating systems including Windows, Linux, Mac OS X, and Solaris support kernel threads.\\n',\n",
              " '   Ultimately, a relationship must exist between user threads and kernel threads. In this section, we look at three common ways of establishing such a relationship: the many-to-one model, the one-to-one model, and the many-to- many model.\\n',\n",
              " 'The many-to-one model (Figure 4.5) maps many user-level threads to one kernel thread. Thread management is done by the thread library in user space, so it is efficient (we discuss thread libraries in Section 4.4). However, the entire process will block if a thread makes a blocking system call. Also, because only one thread can access the kernel at a time, multiple threads are unable to run in parallel on multicore systems. Green threads  a thread library available for Solaris systems and adopted in early versions of Java used the many-to-one model. However, very few systems continue to use the model because of its inability to take advantage of multiple processing cores.\\n',\n",
              " 'The one-to-one model (Figure 4.6) maps each user thread to a kernel thread. It provides more concurrency than the many-to-one model by allowing another thread to run when a thread makes a blocking system call. It also allows multiple threads to run in parallel on multiprocessors. The only drawback to this model is that creating a user thread requires creating the corresponding kernel thread. Because the overhead of creating kernel threads can burden the performance of an application, most implementations of this model restrict the number of threads supported by the system. Linux, along with the family of Windows operating systems, implement the one-to-one model.\\n',\n",
              " 'The many-to-many model (Figure 4.7) multiplexes many user-level threads to a smaller or equal number of kernel threads. The number of kernel threads may be specific to either a particular application or a particular machine (an application may be allocated more kernel threads on a multiprocessor than on a single processor).\\n',\n",
              " '   Lets consider the effect of this design on concurrency. Whereas the many- to-one model allows the developer to create as many user threads as she wishes, it does not result in true concurrency, because the kernel can schedule only one thread at a time. The one-to-one model allows greater concurrency, but the developer has to be careful not to create too many threads within an application (and in some instances may be limited in the number of threads she can\\n',\n",
              " 'create). The many-to-many model suffers from neither of these shortcomings: developers can create as many user threads as necessary, and the corresponding kernel threads can run in parallel on a multiprocessor. Also, when a thread performs a blocking system call, the kernel can schedule another thread for execution.\\n',\n",
              " '   One variation on the many-to-many model still multiplexes many user- level threads to a smaller or equal number of kernel threads but also allows a user-level thread to be bound to a kernel thread. This variation is sometimes referred to as the two-level model (Figure 4.8). The Solaris operating system supported the two-level model in versions older than Solaris 9. However, beginning with Solaris 9, this system uses the one-to-one model.\\n',\n",
              " 'A thread library provides the programmer with an API for creating and managing threads. There are two primary ways of implementing a thread library. The first approach is to provide a library entirely in user space with no kernel support. All code and data structures for the library exist in user space. This means that invoking a function in the library results in a local function call in user space and not a system call.\\n',\n",
              " '   The second approach is to implement a kernel-level library supported directly by the operating system. In this case, code and data structures for the library exist in kernel space. Invoking a function in the API for the library typically results in a system call to the kernel.\\n',\n",
              " '    Three main thread libraries are in use today: POSIX Pthreads, Windows, and Java. Pthreads, the threads extension of the POSIX standard, may be provided as either a user-level or a kernel-level library. The Windows thread library is a kernel-level library available on Windows systems. The Java thread API allows threads to be created and managed directly in Java programs. However, because in most instances the JVM is running on top of a host operating system, the Java thread API is generally implemented using a thread library available on the host system. This means that on Windows systems, Java threads are typically implemented using the Windows API; UNIX and Linux systems often use Pthreads.\\n',\n",
              " '    For POSIX and Windows threading, any data declared globally that is, declared outside of any function  are shared among all threads belonging to the same process. Because Java has no notion of global data, access to shared data must be explicitly arranged between threads. Data declared local to a function are typically stored on the stack. Since each thread has its own stack, each thread has its own copy of local data.\\n',\n",
              " '   In the remainder of this section, we describe basic thread creation using these three thread libraries. As an illustrative example, we design a multi- threaded program that performs the summation of a non-negative integer in a separate thread using the well-known summation function:\\n',\n",
              " 'For example, if N were 5, this function would represent the summation of integers from 0 to 5, which is 15. Each of the three programs will be run with the upper bounds of the summation entered on the command line. Thus, if the user enters 8, the summation of the integer values from 0 to 8 will be output.\\n',\n",
              " '   Before we proceed with our examples of thread creation, we introduce two general strategies for creating multiple threads: asynchronous threading and synchronous threading. With asynchronous threading, once the parent creates a child thread, the parent resumes its execution, so that the parent and child execute concurrently. Each thread runs independently of every other thread, and the parent thread need not know when its child terminates. Because the threads are independent, there is typically little data sharing between threads. Asynchronous threading is the strategy used in the multithreaded server illustrated in Figure 4.2.\\n',\n",
              " 'the so-called fork-join strategy. Here, the threads created by the parent perform work concurrently, but the parent cannot continue until this work has been completed. Once each thread has finished its work, it terminates and joins with its parent. Only after all of the children have joined can the parent resume execution. Typically, synchronous threading involves significant data sharing among threads. For example, the parent thread may combine the results calculated by its various children. All of the following examples use synchronous threading.\\n',\n",
              " 'Pthreads refers to the POSIX standard (IEEE 1003.1c) defining an API for thread creation and synchronization. This is a speciflcation for thread behavior, not an implementation. Operating-system designers may implement the specification in any way they wish. Numerous systems implement the Pthreads specification; most are UNIX-type systems, including Linux, Mac OS X, and Solaris. Although Windows doesnt support Pthreads natively, some third- party implementations for Windows are available.\\n',\n",
              " '    The C program shown in Figure 4.9 demonstrates the basic Pthreads API for constructing a multithreaded program that calculates the summation of a non- negative integer in a separate thread. In a Pthreads program, separate threads\\n',\n",
              " 'begin execution in a specified function. In Figure 4.9, this is the runner() function. When this program begins, a single thread of control begins in main(). After some initialization, main() creates a second thread that begins control in the runner() function. Both threads share the global data sum.\\n',\n",
              " 'the identifier for the thread we will create. Each thread has a set of attributes, including stack size and scheduling information. The pthread attr t attr declaration represents the attributes for the thread. We set the attributes in the function call pthread attr init(&attr). Because we did not explicitly set any attributes, we use the default attributes provided. (In Chapter 6, we discuss some of the scheduling attributes provided by the Pthreads API.) A separate thread is created with the pthread create() function call. In addition to passing the thread identifier and the attributes for the thread, we also pass the name of the function where the new thread will begin execution  in this case, the runner() function. Last, we pass the integer parameter that was provided on the command line, argv[1].\\n',\n",
              " '   At this point, the program has two threads: the initial (or parent) thread in main() and the summation (or child) thread performing the summation operation in the runner() function. This program follows the fork-join strategy described earlier: after creating the summation thread, the parent thread will wait for it to terminate by calling the pthread join() function. The summation thread will terminate when it calls the function pthread exit(). Once the summation thread has returned, the parent thread will output the value of the shared data sum.\\n',\n",
              " '   This example program creates only a single thread. With the growing dominance of multicore systems, writing programs containing several threads has become increasingly common. A simple method for waiting on several threads using the pthread join() function is to enclose the operation within a simple for loop. For example, you can join on ten threads using the Pthread code shown in Figure 4.10.\\n',\n",
              " 'The technique for creating threads using the Windows thread library is similar to the Pthreads technique in several ways. We illustrate the Windows thread API in the C program shown in Figure 4.11. Notice that we must include the windows.h header file when using the Windows API.\\n',\n",
              " '   Just as in the Pthreads version shown in Figure 4.9, data shared by the separate threads in this case, Sum are declared globally (the DWORD data type is an unsigned 32-bit integer). We also define the Summation() function that is to be performed in a separate thread. This function is passed a pointer to a void, which Windows defines as LPVOID. The thread performing this function sets the global data Sum to the value of the summation from 0 to the parameter passed to Summation().\\n',\n",
              " '   Threads are created in the Windows API using the CreateThread() function, and  just as in Pthreads  a set of attributes for the thread is passed to this function. These attributes include security information, the size of the stack, and a flag that can be set to indicate if the thread is to start in a suspended state. In this program, we use the default values for these attributes. (The default values do not initially set the thread to a suspended state and instead make it eligible to be run by the CPU scheduler.) Once the summation thread is created, the parent must wait for it to complete before outputting the value of Sum, as the value is set by the summation thread. Recall that the Pthread program (Figure 4.9) had the parent thread wait for the summation thread using the pthread join() statement. We perform the equivalent of this in the Windows API using the WaitForSingleObject() function, which causes the creating thread to block until the summation thread has exited.\\n',\n",
              " 'Threads are the fundamental model of program execution in a Java program, and the Java language and its API provide a rich set of features for the creation and management of threads. All Java programs comprise at least a single thread of control even a simple Java program consisting of only a main() method runs as a single thread in the JVM. Java threads are available on any system that provides a JVM including Windows, Linux, and Mac OS X. The Java thread API is available for Android applications as well.\\n',\n",
              " '   There are two techniques for creating threads in a Java program. One approach is to create a new class that is derived from the Thread class and to override its run() method. An alternative and more commonly used technique is to define a class that implements the Runnable interface. The Runnable interface is defined as follows:\\n',\n",
              " '   Figure 4.12 shows the Java version of a multithreaded program that determines the summation of a non-negative integer. The Summation class implements the Runnable interface. Thread creation is performed by creating an object instance of the Thread class and passing the constructor a Runnable object.\\n',\n",
              " '2. It calls the run() method, making the thread eligible to be run by the JVM. (Note again that we never call the run() method directly. Rather, we call the start() method, and it calls the run() method on our behalf.)\\n',\n",
              " '   When the summation program runs, the JVM creates two threads. The first is the parent thread, which starts execution in the main() method. The second thread is created when the start() method on the Thread object is invoked. This child thread begins execution in the run() method of the Summation class. After outputting the value of the summation, this thread terminates when it exits from its run() method.\\n',\n",
              " '    Data sharing between threads occurs easily in Windows and Pthreads, since shared data are simply declared globally. As a pure object-oriented language, Java has no such notion of global data. If two or more threads are to share data in a Java program, the sharing occurs by passing references to the shared object to the appropriate threads. In the Java program shown in Figure 4.12, the main thread and the summation thread share the object instance of the Sum class. This shared object is referenced through the appropriate getSum() and setSum() methods. (You might wonder why we dont use an Integer object rather than designing a new sum class. The reason is that the Integer class is immutable that is, once its value is set, it cannot change.)\\n',\n",
              " '   Recall that the parent threads in the Pthreads and Windows libraries use pthread join() and  WaitForSingleObject()  (respectively)  to  wait for the summation threads to finish before proceeding. The join() method in Java provides similar functionality. (Notice that join() can throw an InterruptedException, which we choose to ignore.) If the parent must wait for several threads to finish, the join() method can be enclosed in a for loop similar to that shown for Pthreads in Figure 4.10.\\n',\n",
              " 'With the continued growth of multicore processing, applications containing hundreds  or even thousands  of threads are looming on the horizon. Designing such applications is not a trivial undertaking: programmers must address not only the challenges outlined in Section 4.2 but additional difficulties as well. These difficulties, which relate to program correctness, are covered in Chapters 5 and 7.\\n',\n",
              " 'threading from application developers to compilers and run-time libraries. This strategy, termed implicit threading, is a popular trend today. In this section, we explore three alternative approaches for designing multithreaded programs that can take advantage of multicore processors through implicit threading.\\n',\n",
              " 'In Section 4.1, we described a multithreaded web server. In this situation, whenever the server receives a request, it creates a separate thread to service the request. Whereas creating a separate thread is certainly superior to creating a separate process, a multithreaded server nonetheless has potential problems. The first issue concerns the amount of time required to create the thread, together with the fact that the thread will be discarded once it has completed its work. The second issue is more troublesome. If we allow all concurrent requests to be serviced in a new thread, we have not placed a bound on the number of threads concurrently active in the system. Unlimited threads could exhaust system resources, such as CPU time or memory. One solution to this problem is to use a thread pool.\\n',\n",
              " '   The general idea behind a thread pool is to create a number of threads at process startup and place them into a pool, where they sit and wait for work. When a server receives a request, it awakens a thread from this pool if one is available and passes it the request for service. Once the thread completes its service, it returns to the pool and awaits more work. If the pool contains no available thread, the server waits until one becomes free.\\n',\n",
              " '3. Separating the task to be performed from the mechanics of creating the task allows us to use different strategies for running the task. For example, the task could be scheduled to execute after a time delay or to execute periodically.\\n',\n",
              " '   The number of threads in the pool can be set heuristically based on factors such as the number of CPUs in the system, the amount of physical memory, and the expected number of concurrent client requests. More sophisticated thread-pool architectures can dynamically adjust the number of threads in the pool according to usage patterns. Such architectures provide the further benefit of having a smaller pool  thereby consuming less memory  when the load on the system is low. We discuss one such architecture, Apples Grand Central Dispatch, later in this section.\\n',\n",
              " '   The Windows API provides several functions related to thread pools. Using the thread pool API is similar to creating a thread with the Thread Create() function, as described in Section 4.4.2. Here, a function that is to run as a separate thread is defined. Such a function may appear as follows:\\n',\n",
              " 'A pointer to PoolFunction() is passed to one of the functions in the thread pool API, and a thread from the pool executes this function. One such member in the thread pool API is the QueueUserWorkItem() function, which is passed three parameters:\\n',\n",
              " '    Other members in the Windows thread pool API include utilities that invoke functions at periodic intervals or when an asynchronous I/O request completes. The java.util.concurrent package in the Java API provides a thread-pool utility as well.\\n',\n",
              " 'OpenMP is a set of compiler directives as well as an API for programs written in C, C++, or FORTRAN that provides support for parallel programming in shared-memory environments. OpenMP identifies parallel regions as blocks of code that may run in parallel. Application developers insert compiler directives into their code at parallel regions, and these directives instruct the OpenMP run-time library to execute the region in parallel. The following C program illustrates a compiler directive above the parallel region containing the printf() statement:\\n',\n",
              " 'it creates as many threads are there are processing cores in the system. Thus, for a dual-core system, two threads are created, for a quad-core system, four are created; and so forth. All the threads then simultaneously execute the parallel region. As each thread exits the parallel region, it is terminated.\\n',\n",
              " '   OpenMP provides several additional directives for running code regions in parallel, including parallelizing loops. For example, assume we have two arrays a and b of size N. We wish to sum their contents and place the results in array c. We can have this task run in parallel by using the following code segment, which contains the compiler directive for parallelizing for loops:\\n',\n",
              " 'In addition to providing directives for parallelization, OpenMP allows devel- opers to choose among several levels of parallelism. For example, they can set the number of threads manually. It also allows developers to identify whether data are shared between threads or are private to a thread. OpenMP is available on several open-source and commercial compilers for Linux, Windows, and Mac OS X systems. We encourage readers interested in learning more about OpenMP to consult the bibliography at the end of the chapter.\\n',\n",
              " 'Grand Central Dispatch (GCD) a technology for Apples Mac OS X and iOS operating systems is a combination of extensions to the C language, an API, and a run-time library that allows application developers to identify sections of code to run in parallel. Like OpenMP, GCD manages most of the details of threading.\\n',\n",
              " '    GCD identifies extensions to the C and C++ languages known as blocks.A block is simply a self-contained unit of work. It is specified by a caret  inserted in front of a pair of braces { }.A simple example of a block is shown below:\\n',\n",
              " '    GCD schedules blocks for run-time execution by placing them on a dispatch queue. When it removes a block from a queue, it assigns the block to an available thread from the thread pool it manages. GCD identifies two types of dispatch queues: serial and concurrent.\\n',\n",
              " '    Blocks placed on a serial queue are removed in FIFO order. Once a block has been removed from the queue, it must complete execution before another block is removed. Each process has its own serial queue (known as its main queue). Developers can create additional serial queues that are local to particular processes. Serial queues are useful for ensuring the sequential execution of several tasks.\\n',\n",
              " '   Blocks placed on a concurrent queue are also removed in FIFO order, but several blocks may be removed at a time, thus allowing multiple blocks to execute in parallel. There are three system-wide concurrent dispatch queues, and they are distinguished according to priority: low, default, and high. Priorities represent an approximation of the relative importance of blocks. Quite simply, blocks with a higher priority should be placed on the high- priority dispatch queue.\\n',\n",
              " 'Internally, GCDs thread pool is composed of POSIX threads. GCD actively manages the pool, allowing the number of threads to grow and shrink according to application demand and system capacity.\\n',\n",
              " 'Thread pools, OpenMP, and Grand Central Dispatch are just a few of many emerging technologies for managing multithreaded applications. Other com- mercial approaches include parallel and concurrent libraries, such as Intels Threading Building Blocks (TBB) and several products from Microsoft. The Java language and API have seen significant movement toward supporting concur- rent programming as well. A notable example is the java.util.concurrent package, which supports implicit thread creation and management.\\n',\n",
              " 'In Chapter 3, we described how the fork() system call is used to create a separate, duplicate process. The semantics of the fork() and exec() system calls change in a multithreaded program.\\n',\n",
              " '   If one thread in a program calls fork(), does the new process duplicate all threads, or is the new process single-threaded? Some UNIX systems have chosen to have two versions of fork(), one that duplicates all threads and another that duplicates only the thread that invoked the fork() system call.\\n',\n",
              " '   The exec() system call typically works in the same way as described in Chapter 3. That is, if a thread invokes the exec() system call, the program specified in the parameter to exec() will replace the entire process including all threads.\\n',\n",
              " '   Which of the two versions of fork() to use depends on the application. If exec() is called immediately after forking, then duplicating all threads is unnecessary, as the program specified in the parameters to exec() will replace the process. In this instance, duplicating only the calling thread is appropriate. If, however, the separate process does not call exec() after forking, the separate process should duplicate all threads.\\n',\n",
              " '   Examples of synchronous signal include illegal memory access and divi- sion by 0. If a running program performs either of these actions, a signal is generated. Synchronous signals are delivered to the same process that performed the operation that caused the signal (that is the reason they are considered synchronous).\\n',\n",
              " '   When a signal is generated by an event external to a running process, that process receives the signal asynchronously. Examples of such signals include terminating a process with specific keystrokes (such as <control><C>) and having a timer expire. Typically, an asynchronous signal is sent to another process.\\n',\n",
              " '   Every signal has a default signal handler that the kernel runs when handling that signal. This default action can be overridden by a user-defined signal handler that is called to handle the signal. Signals are handled in different ways. Some signals (such as changing the size of a window) are simply ignored; others (such as an illegal memory access) are handled by terminating the program.\\n',\n",
              " '   Handling signals in single-threaded programs is straightforward: signals are always delivered to a process. However, delivering signals is more complicated in multithreaded programs, where a process may have several threads. Where, then, should a signal be delivered?\\n',\n",
              " '    The method for delivering a signal depends on the type of signal generated. For example, synchronous signals need to be delivered to the thread causing the signal and not to other threads in the process. However, the situation with asynchronous signals is not as clear. Some asynchronous signals  such as a signal that terminates a process (<control><C>, for example) should be sent to all threads.\\n',\n",
              " 'This function specifies the process (pid) to which a particular signal (signal) is to be delivered. Most multithreaded versions of UNIX allow a thread to specify which signals it will accept and which it will block. Therefore, in some cases, an asynchronous signal may be delivered only to those threads that are not blocking it. However, because signals need to be handled only once, a signal is typically delivered only to the first thread found that is not blocking it. POSIX Pthreads provides the following function, which allows a signal to be delivered to a specified thread (tid):\\n',\n",
              " '   Although Windows does not explicitly provide support for signals, it allows us to emulate them using asynchronous procedure calls (APCs). The APC facility enables a user thread to specify a function that is to be called when the user thread receives notification of a particular event. As indicated by its name, an APC is roughly equivalent to an asynchronous signal in UNIX. However, whereas UNIX must contend with how to deal with signals in a multithreaded environment, the APC facility is more straightforward, since an APC is delivered to a particular thread rather than a process.\\n',\n",
              " 'Thread cancellation involves terminating a thread before it has completed. For example, if multiple threads are concurrently searching through a database and one thread returns the result, the remaining threads might be canceled. Another situation might occur when a user presses a button on a web browser that stops a web page from loading any further. Often, a web page loads using several threads each image is loaded in a separate thread. When a user presses the stop button on the browser, all threads loading the page are canceled.\\n',\n",
              " '   The difficulty with cancellation occurs in situations where resources have been allocated to a canceled thread or where a thread is canceled while in the midst of updating data it is sharing with other threads. This becomes especially troublesome with asynchronous cancellation. Often, the operating system will reclaim system resources from a canceled thread but will not reclaim all resources. Therefore, canceling a thread asynchronously may not free a necessary system-wide resource.\\n',\n",
              " '   With deferred cancellation, in contrast, one thread indicates that a target thread is to be canceled, but cancellation occurs only after the target thread has checked a flag to determine whether or not it should be canceled. The thread can perform this check at a point at which it can be canceled safely.\\n',\n",
              " '   In Pthreads, thread cancellation is initiated using the pthread cancel() function. The identifier of the target thread is passed as a parameter to the function. The following code illustrates creating  and then canceling  a thread:\\n',\n",
              " '   Invoking pthread cancel()indicates only a request to cancel the target thread, however; actual cancellation depends on how the target thread is set up to handle the request. Pthreads supports three cancellation modes. Each mode is defined as a state and a type, as illustrated in the table below. A thread may set its cancellation state and type using an API.\\n',\n",
              " '   As the table illustrates, Pthreads allows threads to disable or enable cancellation. Obviously, a thread cannot be canceled if cancellation is disabled. However, cancellation requests remain pending, so the thread can later enable cancellation and respond to the request.\\n',\n",
              " '   The default cancellation type is deferred cancellation. Here, cancellation occurs only when a thread reaches a cancellation point. One technique for establishing a cancellation point is to invoke the pthread testcancel() function. If a cancellation request is found to be pending, a function known as a cleanup handler is invoked. This function allows any resources a thread may have acquired to be released before the thread is terminated.\\n',\n",
              " '   Because of the issues described earlier, asynchronous cancellation is not recommended in Pthreads documentation. Thus, we do not cover it here. An interesting note is that on Linux systems, thread cancellation using the Pthreads API is handled through signals (Section 4.6.2).\\n',\n",
              " 'Threads belonging to a process share the data of the process. Indeed, this data sharing provides one of the benefits of multithreaded programming. However, in some circumstances, each thread might need its own copy of certain data. We will call such data thread-local storage (or TLS.) For example, in a transaction-processing system, we might service each transaction in a separate thread. Furthermore, each transaction might be assigned a unique identifier. To associate each thread with its unique identifier, we could use thread-local storage.\\n',\n",
              " '   It is easy to confuse TLS with local variables. However, local variables are visible only during a single function invocation, whereas TLS data are visible across function invocations. In some ways, TLS is similar to static data. The difference is that TLS data are unique to each thread. Most thread libraries  including Windows and Pthreads  provide some form of support for thread-local storage; Java provides support as well.\\n',\n",
              " 'A final issue to be considered with multithreaded programs concerns com- munication between the kernel and the thread library, which may be required by the many-to-many and two-level models discussed in Section 4.3.3. Such coordination allows the number of kernel threads to be dynamically adjusted to help ensure the best performance.\\n',\n",
              " '   Many systems implementing either the many-to-many or the two-level model place an intermediate data structure between the user and kernel threads. This data structure typically known as a lightweight process, or LWP is shown in Figure 4.13. To the user-thread library, the LWP appears to be a virtual processor on which the application can schedule a user thread to run. Each LWP is attached to a kernel thread, and it is kernel threads that the\\n',\n",
              " 'operating system schedules to run on physical processors. If a kernel thread blocks (such as while waiting for an I/O operation to complete), the LWP blocks as well. Up the chain, the user-level thread attached to the LWP also blocks.\\n',\n",
              " '    An application may require any number of LWPs to run efficiently. Consider a CPU-bound application running on a single processor. In this scenario, only one thread can run at at a time, so one LWP is sufficient. An application that is I/O-intensive may require multiple LWPs to execute, however. Typically, an LWP is required for each concurrent blocking system call. Suppose, for example, that five different file-read requests occur simultaneously. Five LWPs are needed, because all could be waiting for I/O completion in the kernel. If a process has only four LWPs, then the fifth request must wait for one of the LWPs to return from the kernel.\\n',\n",
              " '   One scheme for communication between the user-thread library and the kernel is known as scheduler activation. It works as follows: The kernel provides an application with a set of virtual processors (LWPs), and the application can schedule user threads onto an available virtual processor. Furthermore, the kernel must inform an application about certain events. This procedure is known as an upcall. Upcalls are handled by the thread library with an upcall handler, and upcall handlers must run on a virtual processor. One event that triggers an upcall occurs when an application thread is about to block. In this scenario, the kernel makes an upcall to the application informing it that a thread is about to block and identifying the specific thread. The kernel then allocates a new virtual processor to the application. The application runs an upcall handler on this new virtual processor, which saves the state of the blocking thread and relinquishes the virtual processor on which the blocking thread is running. The upcall handler then schedules another thread that is eligible to run on the new virtual processor. When the event that the blocking thread was waiting for occurs, the kernel makes another upcall to the thread library informing it that the previously blocked thread is now eligible to run. The upcall handler for this event also requires a virtual processor, and the kernel may allocate a new virtual processor or preempt one of the user threads and run the upcall handler on its virtual processor. After marking the unblocked thread as eligible to run, the application schedules an eligible thread to run on an available virtual processor.\\n',\n",
              " 'Windows implements the Windows API, which is the primary API for the family of Microsoft operating systems (Windows 98, NT, 2000, and XP, as well as Windows 7). Indeed, much of what is mentioned in this section applies to this entire family of operating systems.\\n',\n",
              " '   The key components of the ETHREAD include a pointer to the process to which the thread belongs and the address of the routine in which the thread starts control. The ETHREAD also contains a pointer to the corresponding KTHREAD.\\n',\n",
              " '   The KTHREAD includes scheduling and synchronization information for the thread. In addition, the KTHREAD includes the kernel stack (used when the thread is running in kernel mode) and a pointer to the TEB.\\n',\n",
              " '   The ETHREAD and the KTHREAD exist entirely in kernel space; this means that only the kernel can access them. The TEB is a user-space data structure that is accessed when the thread is running in user mode. Among other fields, the TEB contains the thread identifier, a user-mode stack, and an array for thread-local storage. The structure of a Windows thread is illustrated in Figure 4.14.\\n',\n",
              " 'Linux provides the fork() system call with the traditional functionality of duplicating a process, as described in Chapter 3. Linux also provides the ability to create threads using the clone() system call. However, Linux does not distinguish between processes and threads. In fact, Linux uses the term task\\n',\n",
              " '   When clone() is invoked, it is passed a set of flags that determine how much sharing is to take place between the parent and child tasks. Some of these flags are listed in Figure 4.15. For example, suppose that clone() is passed the flags CLONE FS, CLONE VM, CLONE SIGHAND, and CLONE FILES. The parent and child tasks will then share the same file-system information (such as the current working directory), the same memory space, the same signal handlers,\\n',\n",
              " 'and the same set of open files. Using clone() in this fashion is equivalent to creating a thread as described in this chapter, since the parent task shares most of its resources with its child task. However, if none of these flags is set when clone() is invoked, no sharing takes place, resulting in functionality similar to that provided by the fork() system call.\\n',\n",
              " '   The varying level of sharing is possible because of the way a task is represented in the Linux kernel. A unique kernel data structure (specifically, struct task struct) exists for each task in the system. This data structure, instead of storing data for the task, contains pointers to other data structures where these data are stored for example, data structures that represent the list of open files, signal-handling information, and virtual memory. When fork() is invoked, a new task is created, along with a copy of all the associated data\\n',\n",
              " 'structures of the parent process. A new task is also created when the clone() system call is made. However, rather than copying all data structures, the new task points to the data structures of the parent task, depending on the set of flags passed to clone().\\n',\n",
              " 'A thread is a flow of control within a process. A multithreaded process contains several different flows of control within the same address space. The benefits of multithreading include increased responsiveness to the user, resource sharing within the process, economy, and scalability factors, such as more efficient use of multiple processing cores.\\n',\n",
              " '   User-level threads are threads that are visible to the programmer and are unknown to the kernel. The operating-system kernel supports and manages kernel-level threads. In general, user-level threads are faster to create and manage than are kernel threads, because no intervention from the kernel is required.\\n',\n",
              " '   Three different types of models relate user and kernel threads. The many- to-one model maps many user threads to a single kernel thread. The one-to-one model maps each user thread to a corresponding kernel thread. The many-to- many model multiplexes many user threads to a smaller or equal number of kernel threads.\\n',\n",
              " '   Thread libraries provide the application programmer with an API for creating and managing threads. Three primary thread libraries are in common use: POSIX Pthreads, Windows threads, and Java threads.\\n',\n",
              " '   In addition to explicitly creating threads using the API provided by a library, we can use implicit threading, in which the creation and management of threading is transferred to compilers and run-time libraries. Strategies for implicit threading include thread pools, OpenMP, and Grand Central Dispatch. Multithreaded programs introduce many challenges for programmers, including the semantics of the fork() and exec() system calls. Other issues include signal handling, thread cancellation, thread-local storage, and\\n',\n",
              " '4.5 Assume that an operating system maps user-level threads to the kernel using the many-to-many model and that the mapping is done through LWPs. Furthermore, the system allows developers to create real-time threads for use in real-time systems. Is it necessary to bind a real-time thread to an LWP? Explain.\\n',\n",
              " '4.10 In Chapter 3, we discussed Googles Chrome browser and its practice of opening each new website in a separate process. Would the same benefits have been achieved if instead Chrome had been designed to open each new website in a separate thread? Explain.\\n',\n",
              " '4.14 A system with two dual-core processors has four processors available for scheduling. A CPU-intensive application is running on this system. All input is performed at program start-up, when a single file must be opened. Similarly, all output is performed just before the program\\n',\n",
              " 'terminates, when the program results must be written to a single file. Between startup and termination, the program is entirely CPU- bound. Your task is to improve the performance of this application by multithreading it. The application runs on a system that uses the one-to-one threading model (each user thread maps to a kernel thread).\\n',\n",
              " '4.16 As described in Section 4.7.2, Linux does not distinguish between processes and threads. Instead, Linux treats both in the same way, allowing a task to be more akin to a process or a thread depending on the set of flags passed to the clone() system call. However, other operating systems, such as Windows, treat processes and threads differently. Typically, such systems use a notation in which the data structure for a process contains pointers to the separate threads belonging to the process. Contrast these two approaches for modeling processes and threads within the kernel.\\n',\n",
              " '4.18 Consider a multicore system and a multithreaded program written using the many-to-many threading model. Let the number of user-level threads in the program be greater than the number of processing cores in the system. Discuss the performance implications of the following scenarios.\\n',\n",
              " '4.20 Modify programming problem Exercise 3.20 from Chapter 3, which asks you to design a pid manager. This modification will consist of writing a multithreaded program that tests your solution to Exercise 3.20. You will create a number of threads for example, 100  and each thread will request a pid, sleep for a random period of time, and then release the pid. (Sleeping for a random period of time approximates the typical pid usage in which a pid is assigned to a new process, the process executes and then terminates, and the pid is released on the processs termination.) On UNIX and Linux systems, sleeping is accomplished through the sleep() function, which is passed an integer value representing the number of seconds to sleep. This problem will be modified in Chapter 5.\\n',\n",
              " '4.21 Write a multithreaded program that calculates various statistical values for a list of numbers. This program will be passed a series of numbers on the command line and will then create three separate worker threads. One thread will determine the average of the numbers, the second will determine the maximum value, and the third will determine the minimum value. For example, suppose your program is passed the integers\\n',\n",
              " 'The variables representing the average, minimum, and maximum values will be stored globally. The worker threads will set these values, and the parent thread will output the values once the workers have exited. (We could obviously expand this program by creating additional threads that determine other statistical values, such as median and standard deviation.)\\n',\n",
              " '4.22 An interesting way of calculating  is to use a technique known as Monte Carlo, which involves randomization. This technique works as follows: Suppose you have a circle inscribed within a square, as shown in Figure\\n',\n",
              " '4.18. (Assume that the radius of this circle is 1.) First, generate a series of random points as simple (x, y) coordinates. These points must fall within the Cartesian coordinates that bound the square. Of the total number of random points that are generated, some will occur within the circle. Next, estimate  by performing the following calculation:\\n',\n",
              " 'Write a multithreaded version of this algorithm that creates a separate thread to generate a number of random points. The thread will count the number of points that occur within the circle and store that result in a global variable. When this thread has exited, the parent thread will calculate and output the estimated value of . It is worth experimenting with the number of random points generated. As a general rule, the greater the number of points, the closer the approximation to .\\n',\n",
              " 'In the source-code download for this text, we provide a sample program that provides a technique for generating random numbers, as well as determining if the random (x, y) point occurs within the circle.\\n',\n",
              " 'Readers interested in the details of the Monte Carlo method for esti- mating  should consult the bibliography at the end of this chapter. In Chapter 5, we modify this exercise using relevant material from that chapter.\\n',\n",
              " '4.23 Repeat Exercise 4.22, but instead of using a separate thread to generate random points, use OpenMP to parallelize the generation of points. Be careful not to place the calculcation of  in the parallel region, since you want to calculcate  only once.\\n',\n",
              " '4.24 Write a multithreaded program that outputs prime numbers. This program should work as follows: The user will run the program and will enter a number on the command line. The program will then create a separate thread that outputs all the prime numbers less than or equal to the number entered by the user.\\n',\n",
              " 'Write a multithreaded program that generates the Fibonacci sequence. This program should work as follows: On the command line, the user will enter the number of Fibonacci numbers that the program is to generate. The program will then create a separate thread that will generate the Fibonacci numbers, placing the sequence in data that can be shared by the threads (an array is probably the most convenient data structure). When the thread finishes execution, the parent thread will output the sequence generated by the child thread. Because the parent thread cannot begin outputting the Fibonacci sequence until the child thread finishes, the parent thread will have to wait for the child thread to finish. Use the techniques described in Section 4.4 to meet this requirement.\\n',\n",
              " '4.27 Exercise 3.25 in Chapter 3 involves designing an echo server using the Java threading API. This server is single-threaded, meaning that the server cannot respond to concurrent echo clients until the current client exits. Modify the solution to Exercise 3.25 so that the echo server services each client in a separate request.\\n',\n",
              " '   This would result in a total of eleven separate threads for validating a Sudoku puzzle. However, you are welcome to create even more threads for this project. For example, rather than creating one thread that checks all nine\\n',\n",
              " 'The parent thread will create the worker threads, passing each worker the location that it must check in the Sudoku grid. This step will require passing several parameters to each thread. The easiest approach is to create a data structure using a struct. For example,a structure to pass the row and column where a thread must begin validating would appear as follows:\\n',\n",
              " 'The data pointer will be passed to either the pthread create() (Pthreads) function or the CreateThread() (Windows) function, which in turn will pass it as a parameter to the function that is to run as a separate thread.\\n',\n",
              " 'check, it must pass its results back to the parent. One good way to handle this is to create an array of integer values that is visible to each thread. The ith index in this array corresponds to the ith worker thread. If a worker sets its corresponding value to 1, it is indicating that its region of the Sudoku puzzle is valid. A value of 0 would indicate otherwise. When all worker threads have completed, the parent thread checks each entry in the result array to determine if the Sudoku puzzle is valid.\\n',\n",
              " 'Write a multithreaded sorting program that works as follows: A list of integers is divided into two smaller lists of equal size. Two separate threads (which we will term sorting threads) sort each sublist using a sorting algorithm of your choice. The two sublists are then merged by a third thread  a merging thread\\n',\n",
              " '   Because global data are shared cross all threads, perhaps the easiest way to set up the data is to create a global array. Each sorting thread will work on one half of this array. A second global array of the same size as the unsorted integer array will also be established. The merging thread will then merge the two sublists into this second array. Graphically, this program is structured according to Figure 4.20.\\n',\n",
              " '   This programming project will require passing parameters to each of the sorting threads. In particular, it will be necessary to identify the starting index from which each thread is to begin sorting. Refer to the instructions in Project 1 for details on passing parameters to a thread.\\n',\n",
              " 'Threads have had a long evolution, starting as cheap concurrency in programming languages and moving to lightweight processes, with early examples that included the Thoth system ([Cheriton et al. (1979)]) and the Pilot\\n',\n",
              " 'system ([Redell et al. (1980)]). [Binding (1985)] described moving threads into the UNIX kernel. Mach ([Accetta et al. (1986)], [Tevanian et al. (1987)]), and V ([Cheriton (1988)]) made extensive use of threads, and eventually almost all major operating systems implemented them in some form or another.\\n',\n",
              " '   [Vahalia (1996)] covers threading in several versions of UNIX. [McDougall and Mauro (2007)] describes developments in threading the Solaris kernel. [Russinovich and Solomon (2009)] discuss threading in the Windows operating system family. [Mauerer (2008)] and [Love (2010)] explain how Linux handles threading, and [Singh (2007)] covers threads in Mac OS X.\\n',\n",
              " '   Information on Pthreads programming is given in [Lewis and Berg (1998)] and [Butenhof (1997)]. [Oaks and Wong (1999)] and [Lewis and Berg (2000)] discuss multithreading in Java. [Goetz et al. (2006)] present a detailed discussion of concurrent programming in Java. [Hart (2005)] describes multithreading using Windows. Details on using OpenMP can be found at http://openmp.org.\\n',\n",
              " '   An analysis of an optimal thread-pool size can be found in [Ling et al. (2000)]. Scheduler activations were first presented in [Anderson et al. (1991)], and [Williams (2002)] discusses scheduler activations in the NetBSD system.\\n',\n",
              " '   [Breshears (2009)] and [Pacheco (2011)] cover parallel programming in detail. [Hill and Marty (2008)] examine Amdahls Law with respect to multicore systems. The Monte Carlo technique for estimating  is further discussed in http://math.fullerton.edu/mathews/n2003/montecarlopimod.html.\\n',\n",
              " 'H. M. Levy, Scheduler Activations: Effective Kernel Support for the User-Level Management of Parallelism, Proceedings of the ACM Symposium on Operating Systems Principles (1991), pages 95109.\\n',\n",
              " '[Cheriton et al. (1979)] D. R. Cheriton, M. A. Malcolm, L. S. Melen, and G. R. Sager, Thoth, a Portable Real-Time Operating System, Communications of the ACM, Volume 22, Number2 (1979), pages 105115.\\n',\n",
              " '[Redell et al. (1980)] D. D. Redell, Y. K. Dalal, T. R. Horsley, H. C. Lauer, W. C. Lynch, P. R. McJones, H. G. Murray, and S. P. Purcell, Pilot: An Operating System for a Personal Computer, Communications of the ACM, Volume 23, Number 2 (1980), pages 8192.\\n',\n",
              " 'A cooperating process is one that can affect or be affected by other processes executing in the system. Cooperating processes can either directly share a logical address space (that is, both code and data) or be allowed to share data only through files or messages. The former case is achieved through the use of threads, discussed in Chapter 4. Concurrent access to shared data may result in data inconsistency, however. In this chapter, we discuss various mechanisms to ensure the orderly execution of cooperating processes that share a logical address space, so that data consistency is maintained.\\n',\n",
              " 'Weve already seen that processes can execute concurrently or in parallel. Section 3.2.2 introduced the role of process scheduling and described how the CPU scheduler switches rapidly between processes to provide concurrent execution. This means that one process may only partially complete execution before another process is scheduled. In fact, a process may be interrupted at any point in its instruction stream, and the processing core may be assigned to execute instructions of another process. Additionally, Section 4.2 introduced parallel execution, in which two instruction streams (representing different processes) execute simultaneously on separate processing cores. In this chapter,\\n',\n",
              " '   Lets consider an example of how this can happen. In Chapter 3, we devel- oped a model of a system consisting of cooperating sequential processes or threads, all running asynchronously and possibly sharing data. We illustrated this model with the producer consumer problem, which is representative of operating systems. Specifically, in Section 3.4.1, we described how a bounded buffer could be used to enable processes to share memory.\\n',\n",
              " '   We now return to our consideration of the bounded buffer. As we pointed out, our original solution allowed at most BUFFER SIZE   1 items in the buffer at the same time. Suppose we want to modify the algorithm to remedy this deficiency. One possibility is to add an integer variable counter, initialized to\\n',\n",
              " '0. counter is incremented every time we add a new item to the buffer and is decremented every time we remove one item from the buffer. The code for the producer process can be modified as follows:\\n',\n",
              " '   Although the producer and consumer routines shown above are correct separately, they may not function correctly when executed concurrently. As an illustration, suppose that the value of the variable counter is currently 5 and that the producer and consumer processes concurrently execute the statements counter++ and counter--. Following the execution of these two statements, the value of the variable counter may be 4, 5, or 6! The only correct result, though, is counter == 5, which is generated correctly if the producer and consumer execute separately.\\n',\n",
              " 'where again register2 is one of the local CPU registers. Even though register1 and register2 may be the same physical register (an accumulator, say), remember that the contents of this register will be saved and restored by the interrupt handler (Section 1.2.3).\\n',\n",
              " '   The concurrent execution of counter++ and counter-- is equivalent to a sequential execution in which the lower-level statements presented previously are interleaved in some arbitrary order (but the order within each high-level statement is preserved). One such interleaving is the following:\\n',\n",
              " 'T0:\\tproducer\\texecute\\tregister1 = counter\\t{register1 = 5} T1:\\tproducer\\texecute\\tregister1 = register1 + 1\\t{register1 = 6} T2:\\tconsumer\\texecute\\tregister2 = counter\\t{register2 = 5} T3:\\tconsumer\\texecute\\tregister2 = register2 ? 1\\t{register2 = 4} T4:\\tproducer\\texecute\\tcounter = register1\\t{counter = 6} T5:\\tconsumer\\texecute\\tcounter = register2\\t{counter = 4}\\n',\n",
              " 'Notice that we have arrived at the incorrect state counter == 4, indicating that four buffers are full, when, in fact, five buffers are full. If we reversed the order of the statements at T4 and T5, we would arrive at the incorrect state counter == 6.\\n',\n",
              " '   We would arrive at this incorrect state because we allowed both processes to manipulate the variable counter concurrently. A situation like this, where several processes access and manipulate the same data concurrently and the outcome of the execution depends on the particular order in which the access takes place, is called a race condition. To guard against the race condition above, we need to ensure that only one process at a time can be manipulating the variable counter. To make such a guarantee, we require that the processes be synchronized in some way.\\n',\n",
              " '   Situations such as the one just described occur frequently in operating systems as different parts of the system manipulate resources. Furthermore, as we have emphasized in earlier chapters, the growing importance of multicore systems has brought an increased emphasis on developing multithreaded applications. In such applications, several threads which are quite possibly sharing data are running in parallel on different  processing cores. Clearly,\\n',\n",
              " 'we want any changes that result from such activities not to interfere with one another. Because of the importance of this issue, we devote a major portion of this chapter to process synchronization and coordination among cooperating processes.\\n',\n",
              " 'We begin our consideration of process synchronization by discussing the so- called critical-section problem. Consider a system consisting of n processes P0, P1, ..., Pn?1 . Each process has a segment of code, called a critical section, in which the process may be changing common variables, updating a table, writing a file, and so on. The important feature of the system is that, when one process is executing in its critical section, no other process is allowed to execute in its critical section. That is, no two processes are executing in their critical sections at the same time. The critical-section problem is to design a protocol that the processes can use to cooperate. Each process must request permission to enter its critical section. The section of code implementing this request is the entry section. The critical section may be followed by an exit section. The remaining code is the remainder section. The general structure of a typical process Pi is shown in Figure 5.1. The entry section and exit section are enclosed in boxes to highlight these important segments of code.\\n',\n",
              " '2. Progress. If no process is executing in its critical section and some processes wish to enter their critical sections, then only those processes that are not executing in their remainder sections can participate in deciding which will enter its critical section next, and this selection cannot be postponed indefinitely.\\n',\n",
              " '   At a given point in time, many kernel-mode processes may be active in the operating system. As a result, the code implementing an operating system (kernel code) is subject to several possible race conditions. Consider as an example a kernel data structure that maintains a list of all open files in the system. This list must be modified when a new file is opened or closed (adding the file to the list or removing it from the list). If two processes were to open files simultaneously, the separate updates to this list could result in a race condition. Other kernel data structures that are prone to possible race conditions include structures for maintaining memory allocation, for maintaining process lists, and for interrupt handling. It is up to kernel developers to ensure that the operating system is free from such race conditions.\\n',\n",
              " '   Two general approaches are used to handle critical sections in operating systems: preemptive kernels and nonpreemptive kernels. A preemptive kernel allows a process to be preempted while it is running in kernel mode. A nonpreemptive kernel does not allow a process running in kernel mode to be preempted; a kernel-mode process will run until it exits kernel mode, blocks, or voluntarily yields control of the CPU.\\n',\n",
              " '   Obviously, a nonpreemptive kernel is essentially free from race conditions on kernel data structures, as only one process is active in the kernel at a time. We cannot say the same about preemptive kernels, so they must be carefully designed to ensure that shared kernel data are free from race conditions. Preemptive kernels are especially difficult to design for SMP architectures, since in these environments it is possible for two kernel-mode processes to run simultaneously on different processors.\\n',\n",
              " '    Why, then, would anyone favor a preemptive kernel over a nonpreemptive one? A preemptive kernel may be more responsive, since there is less risk that a kernel-mode process will run for an arbitrarily long period before relinquishing the processor to waiting processes. (Of course, this risk can also be minimized by designing kernel code that does not behave in this way.) Furthermore, a preemptive kernel is more suitable for real-time programming, as it will allow a real-time process to preempt a process currently running in the kernel. Later in this chapter, we explore how various operating systems manage preemption within the kernel.\\n',\n",
              " 'Next, we illustrate a classic software-based solution to the critical-section problem known as Petersons solution. Because of the way modern computer architectures perform basic machine-language instructions, such as load and store, there are no guarantees that Petersons solution will work correctly on such architectures. However, we present the solution because it provides a good algorithmic description of solving the critical-section problem and illustrates some of the complexities involved in designing software that addresses the requirements of mutual exclusion, progress, and bounded waiting.\\n',\n",
              " '   Petersons solution is restricted to two processes that alternate execution between their critical sections and remainder sections. The processes are numbered P0 and P1. For convenience, when presenting Pi , we use Pj to denote the other process; that is, j equals 1     i.\\n',\n",
              " 'The variable turn indicates whose turn it is to enter its critical section. That is, if turn  ==  i, then process  Pi  is allowed to execute in its critical section. The flag array is used to indicate if a process is ready to enter its critical section. For example, if flag[i] is true, this value indicates that Pi is ready to enter its critical section. With an explanation of these data structures complete, we are now ready to describe the algorithm shown in Figure 5.2.\\n',\n",
              " '   To enter the critical section, process Pi first sets flag[i] to be true and then sets turn to the value j, thereby asserting that if the other process wishes to enter the critical section, it can do so. If both processes try to enter at the same time, turn will be set to both i and j at roughly the same time. Only one of these assignments will last; the other will occur but will be overwritten immediately. The eventual value of turn determines which of the two processes is allowed to enter its critical section first.\\n',\n",
              " '   To prove property 1, we note that each Pi enters its critical section only if  either  flag[j]  ==  false  or  turn  ==  i.  Also  note  that,  if  both  processes can be executing in their critical sections at the same time, then flag[0] == flag[1] == true. These two observations imply that P0 and P1 could not have successfully executed their while statements at about the same time, since the\\n',\n",
              " 'say, Pj must have successfully executed the while statement, whereas Pi had to execute at least one additional statement (turn == j). However, at that time, flag[j] == true and turn == j, and this condition will persist as long as Pj is in its critical section; as a result, mutual exclusion is preserved.\\n',\n",
              " '   To prove properties 2 and 3, we note that a process Pi can be prevented from entering the critical section only if it is stuck in the while loop with the condition flag[j] == true and turn == j; this loop is the only one possible. If Pj is not ready to enter the critical section, then flag[j] == false, and Pi can enter its critical section. If Pj has set flag[j] to true and is also executing in its while statement, then either turn == i or turn == j. If turn == i, then Pi will enter the critical section. If turn == j, then Pj will enter the critical section. However, once Pj exits its critical section, it will reset flag[j] to false, allowing Pi to enter its critical section. If Pj resets flag[j] to true, it must also set turn to i. Thus, since Pi does not change the value of the variable turn while executing the while statement, Pi will enter the critical section (progress) after at most one entry by Pj (bounded waiting).\\n',\n",
              " 'We have just described one software-based solution to the critical-section problem. However, as mentioned, software-based solutions such as Petersons are not guaranteed to work on modern computer architectures. In the following discussions, we explore several more solutions to the critical-section problem using techniques ranging from hardware to software-based APIs available to both kernel developers and application programmers. All these solutions are based on the premise of locking that is, protecting critical regions through the use of locks. As we shall see, the designs of such locks can be quite sophisticated.\\n',\n",
              " '    We start by presenting some simple hardware instructions that are available on many systems and showing how they can be used effectively in solving the critical-section problem. Hardware features can make any programming task easier and improve system efficiency.\\n',\n",
              " '   The critical-section problem could be solved simply in a single-processor environment if we could prevent interrupts from occurring while a shared variable was being modified. In this way, we could be sure that the current sequence of instructions would be allowed to execute in order without pre- emption. No other instructions would be run, so no unexpected modifications could be made to the shared variable. This is often the approach taken by nonpreemptive kernels.\\n',\n",
              " '   Unfortunately, this solution is not as feasible in a multiprocessor environ- ment. Disabling interrupts on a multiprocessor can be time consuming, since the message is passed to all the processors. This message passing delays entry into each critical section, and system efficiency decreases. Also consider the effect on a systems clock if the clock is kept updated by interrupts.\\n',\n",
              " '   Many modern computer systems therefore provide special hardware instructions that allow us either to test and modify the content of a word or to swap the contents of two words atomically that is, as one uninterruptible unit. We can use these special instructions to solve the critical-section problem in a relatively simple manner. Rather than discussing one specific instruction for one specific machine, we abstract the main concepts behind these types of instructions by describing the test and set() and compare and swap() instructions.\\n',\n",
              " '   The test and set() instruction can be defined as shown in Figure 5.3. The important characteristic of this instruction is that it is executed atomically. Thus, if two test and set() instructions are executed simultaneously (each on a different CPU), they will be executed sequentially in some arbitrary order. If the machine supports the test and set() instruction, then we can implement mutual exclusion by declaring a boolean variable lock, initialized to false. The structure of process Pi is shown in Figure 5.4.\\n',\n",
              " '   The compare and swap() instruction, in contrast to the test and set() instruction, operates on three operands; it is defined in Figure 5.5. The operand value is set to new value  only if the expression (*value  ==  exected)  is true. Regardless, compare and swap() always returns the original value of the variable value. Like the test and set() instruction, compare and swap() is\\n',\n",
              " 'executed atomically. Mutual exclusion can be provided as follows: a global variable (lock) is declared and is initialized to 0. The first process that invokes compare and swap() will set lock to 1. It will then enter its critical section, because the original value of lock was equal to the expected value of 0. Subsequent calls to compare and swap() will not succeed, because lock now is not equal to the expected value of 0. When a process exits its critical section, it sets lock back to 0, which allows another process to enter its critical section. The structure of process Pi is shown in Figure 5.6.\\n',\n",
              " '   Although these algorithms satisfy the mutual-exclusion requirement, they do not satisfy the bounded-waiting requirement. In Figure 5.7, we present another algorithm using the test and set() instruction that satisfies all the critical-section requirements. The common data structures are\\n',\n",
              " 'These data structures are initialized to false. To prove that the mutual- exclusion requirement is met, we note that process Pi can enter its critical section  only  if  either  waiting[i] ==  false  or  key  ==  false. The  value of key can become false only if the test and set() is executed. The first process to execute the test and set() will find key == false; all others must wait. The variable waiting[i] can become false only if another process leaves its critical section; only one waiting[i] is set to false, maintaining the mutual-exclusion requirement.\\n',\n",
              " '    To prove that the progress requirement is met, we note that the arguments presented for mutual exclusion also apply here, since a process exiting the critical section either sets lock to false or sets waiting[j] to false. Both allow a process that is waiting to enter its critical section to proceed.\\n',\n",
              " '   To prove that the bounded-waiting requirement is met, we note that, when a process leaves its critical section, it scans the array waiting in the cyclic ordering (i + 1, i + 2, ..., n 1, 0, ..., i 1). It designates the first process in this ordering that is in the entry section (waiting[j] == true) as the next one to enter the critical section. Any process waiting to enter its critical section will thus do so within n 1 turns.\\n',\n",
              " 'The hardware-based solutions to the critical-section problem presented in Section 5.4 are complicated as well as generally inaccessible to application programmers. Instead, operating-systems designers build software tools to solve the critical-section problem. The simplest of these tools is the mutex lock. (In fact, the term mutex is short for mutual exclusion.) We use the mutex lock to protect critical regions and thus prevent race conditions. That is, a process must acquire the lock before entering a critical section; it releases the lock when it exits the critical section. The acquire()function acquires the lock, and the release() function releases the lock, as illustrated in Figure 5.8.\\n',\n",
              " '   A mutex lock has a boolean variable available whose value indicates if the lock is available or not. If the lock is available, a call to acquire() succeeds, and the lock is then considered unavailable. A process that attempts to acquire an unavailable lock is blocked until the lock is released.\\n',\n",
              " '   Calls to either acquire() or release() must be performed atomically. Thus, mutex locks are often implemented using one of the hardware mecha- nisms described in Section 5.4, and we leave the description of this technique as an exercise.\\n',\n",
              " '   The main disadvantage of the implementation given here is that it requires busy waiting. While a process is in its critical section, any other process that tries to enter its critical section must loop continuously in the call to acquire(). In fact, this type of mutex lock is also called a spinlock because the process spins while waiting for the lock to become available. (We see the same issue with the code examples illustrating the test and set() instruction and the compare and swap() instruction.) This continual looping is clearly a problem in a real multiprogramming system, where a single CPU is shared among many processes. Busy waiting wastes CPU cycles that some other process might be able to use productively.\\n',\n",
              " '   Spinlocks do have an advantage, however, in that no context switch is required when a process must wait on a lock, and a context switch may take considerable time. Thus, when locks are expected to be held for short times, spinlocks are useful. They are often employed on multiprocessor systems where one thread can spin on one processor while another thread performs its critical section on another processor.\\n',\n",
              " '   Later in this chapter (Section 5.7), we examine how mutex locks can be used to solve classical synchronization problems. We also discuss how these locks are used in several operating systems, as well as in Pthreads.\\n',\n",
              " '   A semaphore S is an integer variable that, apart from initialization, is accessed only through two standard atomic operations: wait() and signal(). The wait() operation was originally termed P (from the Dutch proberen, to test); signal() was originally called V (from verhogen, to increment). The definition of wait() is as follows:\\n',\n",
              " '   All modifications to the integer value of the semaphore in the wait() and signal() operations must be executed indivisibly. That is, when one process modifies the semaphore value, no other process can simultaneously modify that same semaphore value. In addition, in the case of wait(S), the testing of the integer value of S (S 0), as well as its possible modification (S--), must be executed without interruption. We shall see how these operations can be implemented in Section 5.6.2. First, lets see how semaphores can be used.\\n',\n",
              " 'Operating systems often distinguish between counting and binary semaphores. The value of a counting semaphore can range over an unrestricted domain. The value of a binary semaphore can range only between 0 and 1. Thus, binary semaphores behave similarly to mutex locks. In fact, on systems that do not provide mutex locks, binary semaphores can be used instead for providing mutual exclusion.\\n',\n",
              " '   Counting semaphores can be used to control access to a given resource consisting of a finite number of instances. The semaphore is initialized to the number of resources available. Each process that wishes to use a resource performs a wait() operation on the semaphore (thereby decrementing the count). When a process releases a resource, it performs a signal() operation (incrementing the count). When the count for the semaphore goes to 0, all resources are being used. After that, processes that wish to use a resource will block until the count becomes greater than 0.\\n',\n",
              " '   We can also use semaphores to solve various synchronization problems. For example, consider two concurrently running processes: P1 with a statement S1 and P2 with a statement S2. Suppose we require that S2 be executed only after S1 has completed. We can implement this scheme readily by letting P1 and P2 share a common semaphore synch, initialized to 0. In process P1, we insert the statements\\n',\n",
              " 'Recall that the implementation of mutex locks discussed in Section 5.5 suffers from busy waiting. The definitions of the wait() and signal() semaphore operations just described present the same problem. To overcome the need for busy waiting, we can modify the definition of the wait() and signal() operations as follows: When a process executes the wait() operation and finds that the semaphore value is not positive, it must wait. However, rather than engaging in busy waiting, the process can block itself. The block operation places a process into a waiting queue associated with the semaphore, and the state of the process is switched to the waiting state. Then control is transferred to the CPU scheduler, which selects another process to execute.\\n',\n",
              " '   A process that is blocked, waiting on a semaphore S, should be restarted when some other process executes a signal() operation. The process is restarted by a wakeup() operation, which changes the process from the waiting state to the ready state. The process is then placed in the ready queue. (The CPU may or may not be switched from the running process to the newly ready process, depending on the CPU-scheduling algorithm.)\\n',\n",
              " 'Each semaphore has an integer value and a list of processes list. When a process must wait on a semaphore, it is added to the list of processes. A signal() operation removes one process from the list of waiting processes and awakens that process.\\n',\n",
              " 'The block() operation suspends the process that invokes it. The wakeup(P) operation resumes the execution of a blocked process P. These two operations are provided by the operating system as basic system calls.\\n',\n",
              " '   Note that in this implementation, semaphore values may be negative, whereas semaphore values are never negative under the classical definition of semaphores with busy waiting. If a semaphore value is negative, its magnitude is the number of processes waiting on that semaphore. This fact results from switching the order of the decrement and the test in the implementation of the wait() operation.\\n',\n",
              " '   The list of waiting processes can be easily implemented by a link field in each process control block (PCB). Each semaphore contains an integer value and a pointer to a list of PCBs. One way to add and remove processes from the list so as to ensure bounded waiting is to use a FIFO queue, where the semaphore contains both head and tail pointers to the queue. In general, however, the list can use any queueing strategy. Correct usage of semaphores does not depend on a particular queueing strategy for the semaphore lists.\\n',\n",
              " '   It is critical that semaphore operations be executed atomically. We must guarantee that no two processes can execute wait() and signal() operations on the same semaphore at the same time. This is a critical-section problem; and in a single-processor environment, we can solve it by simply inhibiting interrupts during the time the wait() and signal() operations are executing. This scheme works in a single-processor environment because, once interrupts are inhibited, instructions from different processes cannot be interleaved. Only the currently running process executes until interrupts are reenabled and the scheduler can regain control.\\n',\n",
              " '   In a multiprocessor environment, interrupts must be disabled on every pro- cessor. Otherwise, instructions from different processes (running on different processors) may be interleaved in some arbitrary way. Disabling interrupts on every processor can be a difficult task and furthermore can seriously diminish performance. Therefore, SMP systems must provide alternative locking tech- niques  such as compare and swap() or spinlocks  to ensure that wait() and signal() are performed atomically.\\n',\n",
              " '   It is important to admit that we have not completely eliminated busy waiting with this definition of the wait() and signal() operations. Rather, we have moved busy waiting from the entry section to the critical sections of application programs. Furthermore, we have limited busy waiting to the critical sections of the wait() and signal() operations, and these sections are short (if properly coded, they should be no more than about ten instructions). Thus, the critical section is almost never occupied, and busy waiting occurs\\n',\n",
              " 'rarely, and then for only a short time. An entirely different situation exists with application programs whose critical sections may be long (minutes or even hours) or may almost always be occupied. In such cases, busy waiting is extremely inefficient.\\n',\n",
              " 'The implementation of a semaphore with a waiting queue may result in a situation where two or more processes are waiting indefinitely for an event that can be caused only by one of the waiting processes. The event in question is the execution of a signal() operation. When such a state is reached, these processes are said to be deadlocked.\\n',\n",
              " '   Suppose that P0 executes wait(S) and then P1 executes wait(Q). When P0 executes wait(Q), it must wait until P1 executes signal(Q). Similarly, when P1 executes wait(S), it must wait until P0 executes signal(S). Since these signal() operations cannot be executed, P0 and P1 are deadlocked.\\n',\n",
              " '   We say that a set of processes is in a deadlocked state when every process in the set is waiting for an event that can be caused only by another process in the set. The events with which we are mainly concerned here are resource acquisition and release. Other types of events may result in deadlocks, as we show in Chapter 7. In that chapter, we describe various mechanisms for dealing with the deadlock problem.\\n',\n",
              " '    Another problem related to deadlocks is indefinite blocking or starvation, a situation in which processes wait indefinitely within the semaphore. Indefi- nite blocking may occur if we remove processes from the list associated with a semaphore in LIFO (last-in, first-out) order.\\n',\n",
              " 'A scheduling challenge arises when a higher-priority process needs to read or modify kernel data that are currently being accessed by a lower-priority process or a chain of lower-priority processes. Since kernel data are typically protected with a lock, the higher-priority process will have to wait for a lower-priority one to finish with the resource. The situation becomes more complicated if the lower-priority process is preempted in favor of another process with a higher priority.\\n',\n",
              " 'Priority inversion can be more than a scheduling inconvenience. On systems with tight time constraints such as real-time systems priority inversion can cause a process to take longer than it should to accomplish a task. When that happens, other failures can cascade, resulting in system failure.\\n',\n",
              " '   Consider the Mars Pathfinder, a NASA space probe that landed a robot, the Sojourner rover, on Mars in 1997 to conduct experiments. Shortly after the Sojourner began operating, it started to experience frequent computer resets. Each reset reinitialized all hardware and software, including communica- tions. If the problem had not been solved, the Sojourner would have failed in its mission.\\n',\n",
              " '  The problem was caused by the fact that one high-priority task, bc dist, was taking longer than expected to complete its work. This task was being forced to wait for a shared resource that was held by the lower-priority ASI/MET task, which in turn was preempted by multiple medium-priority tasks. The bc dist task would stall waiting for the shared resource, and ultimately the bc sched task would discover the problem and perform the reset. The Sojourner was suffering from a typical case of priority inversion.\\n',\n",
              " '   The operating system on the Sojourner was the VxWorks real-time operat- ing system, which had a global variable to enable priority inheritance on all semaphores. After testing, the variable was set on the Sojourner (on Mars!), and the problem was solved.\\n',\n",
              " 'resource R, which is currently being accessed by process L. Ordinarily, process H would wait for L to finish using resource R. However, now suppose that process M becomes runnable, thereby preempting process L. Indirectly, a process with a lower priority process M has affected how long process H must wait for L to relinquish resource R.\\n',\n",
              " '    This problem is known as priority inversion. It occurs only in systems with more than two priorities, so one solution is to have only two priorities. That is insufficient for most general-purpose operating systems, however. Typically these systems solve the problem by implementing a priority-inheritance protocol. According to this protocol, all processes that are accessing resources needed by a higher-priority process inherit the higher priority until they are finished with the resources in question. When they are finished, their priorities revert to their original values. In the example above, a priority-inheritance protocol would allow process L to temporarily inherit the priority of process H, thereby preventing process M from preempting its execution. When process L had finished using resource R, it would relinquish its inherited priority from H and assume its original priority. Because resource R would now be available, process H  not M would run next.\\n',\n",
              " 'In this section, we present a number of synchronization problems as examples of a large class of concurrency-control problems. These problems are used for testing nearly every newly proposed synchronization scheme. In our solutions to the problems, we use semaphores for synchronization, since that is the traditional way to present such solutions. However, actual implementations of these solutions could use mutex locks in place of binary semaphores.\\n',\n",
              " 'The bounded-buffer problem was introduced in Section 5.1; it is commonly used to illustrate the power of synchronization primitives. Here, we present a general structure of this scheme without committing ourselves to any particular implementation. We provide a related programming project in the exercises at the end of the chapter.\\n',\n",
              " 'We assume that the pool consists of n buffers, each capable of holding one item. The mutex semaphore provides mutual exclusion for accesses to the buffer pool and is initialized to the value 1. The empty and full semaphores count the number of empty and full buffers. The semaphore empty is initialized to the value n; the semaphore full is initialized to the value 0.\\n',\n",
              " '   The code for the producer process is shown in Figure 5.9, and the code for the consumer process is shown in Figure 5.10. Note the symmetry between the producer and the consumer. We can interpret this code as the producer producing full buffers for the consumer or as the consumer producing empty buffers for the producer.\\n',\n",
              " 'Suppose that a database is to be shared among several concurrent processes. Some of these processes may want only to read the database, whereas others may want to update (that is, to read and write) the database. We distinguish between these two types of processes by referring to the former as readers and to the latter as writers. Obviously, if two readers access the shared data simultaneously, no adverse effects will result. However, if a writer and some other process (either a reader or a writer) access the database simultaneously, chaos may ensue.\\n',\n",
              " '   To ensure that these difficulties do not arise, we require that the writers have exclusive access to the shared database while writing to the database. This synchronization problem is referred to as the readers writers problem. Since it was originally stated, it has been used to test nearly every new synchronization primitive. The readers writers problem has several variations, all involving priorities. The simplest one, referred to as the flrst readers  writers problem, requires that no reader be kept waiting unless a writer has already obtained permission to use the shared object. In other words, no reader should wait for other readers to finish simply because a writer is waiting. The second readers\\n',\n",
              " ' writers problem requires that, once a writer is ready, that writer perform its write as soon as possible. In other words, if a writer is waiting to access the object, no new readers may start reading.\\n',\n",
              " '   A solution to either problem may result in starvation. In the first case, writers may starve; in the second case, readers may starve. For this reason, other variants of the problem have been proposed. Next, we present a solution to the first readers writers problem. See the bibliographical notes at the end of the chapter for references describing starvation-free solutions to the second readers  writers problem.\\n',\n",
              " 'processes. The mutex semaphore is used to ensure mutual exclusion when the variable read count is updated. The read count variable keeps track of how many processes are currently reading the object. The semaphore rw mutex functions as a mutual exclusion semaphore for the writers. It is also used by the first or last reader that enters or exits the critical section. It is not used by readers who enter or exit while other readers are in their critical sections.\\n',\n",
              " '   The code for a writer process is shown in Figure 5.11; the code for a reader process is shown in Figure 5.12. Note that, if a writer is in the critical section and n readers are waiting, then one reader is queued on rw mutex, and n 1 readers are queued on mutex. Also observe that, when a writer executes signal(rw mutex), we may resume the execution of either the waiting readers or a single waiting writer. The selection is made by the scheduler.\\n',\n",
              " '    The readers writers problem and its solutions have been generalized to provide reader  writer locks on some systems. Acquiring a reader writer lock requires specifying the mode of the lock: either read or write access. When a process wishes only to read shared data, it requests the reader writer lock in read mode. A process wishing to modify the shared data must request the lock in write mode. Multiple processes are permitted to concurrently acquire a reader  writer lock in read mode, but only one process may acquire the lock for writing, as exclusive access is required for writers.\\n',\n",
              " ' In applications that have more readers than writers. This is because reader writer locks generally require more overhead to establish than semaphores or mutual-exclusion locks. The increased concurrency of allowing multiple readers compensates for the overhead involved in setting up the reader  writer lock.\\n',\n",
              " 'Consider five philosophers who spend their lives thinking and eating. The philosophers share a circular table surrounded by five chairs, each belonging to one philosopher. In the center of the table is a bowl of rice, and the table is laid with five single chopsticks (Figure 5.13). When a philosopher thinks, she does not interact with her colleagues. From time to time, a philosopher gets hungry and tries to pick up the two chopsticks that are closest to her (the chopsticks that are between her and her left and right neighbors).A philosopher may pick up only one chopstick at a time. Obviously, she cannot pick up a chopstick that is already in the hand of a neighbor. When a hungry philosopher has both her chopsticks at the same time, she eats without releasing the chopsticks. When she is finished eating, she puts down both chopsticks and starts thinking again. The dining-philosophers problem is considered a classic synchronization problem neither because of its practical importance nor because computer scientists dislike philosophers but because it is an example of a large class of concurrency-control problems. It is a simple representation of the need to allocate several resources among several processes in a deadlock-free and\\n',\n",
              " '   One simple solution is to represent each chopstick with a semaphore. A philosopher tries to grab a chopstick by executing a wait() operation on that semaphore. She releases her chopsticks by executing the signal() operation on the appropriate semaphores. Thus, the shared data are\\n',\n",
              " '   Although this solution guarantees that no two neighbors are eating simultaneously, it nevertheless must be rejected because it could create a deadlock. Suppose that all five philosophers become hungry at the same time and each grabs her left chopstick. All the elements of chopstick will now be equal to 0. When each philosopher tries to grab her right chopstick, she will be delayed forever.\\n',\n",
              " ' Use an asymmetric solution that is, an odd-numbered philosopher picks up first her left chopstick and then her right chopstick, whereas an even- numbered philosopher picks up her right chopstick and then her left chopstick.\\n',\n",
              " '   In Section 5.8, we present a solution to the dining-philosophers problem that ensures freedom from deadlocks. Note, however, that any satisfactory solution to the dining-philosophers problem must guard against the possibility that one of the philosophers will starve to death. A deadlock-free solution does not necessarily eliminate the possibility of starvation.\\n',\n",
              " 'Although semaphores provide a  convenient and effective mechanism  for process synchronization, using them incorrectly can result in timing errors that are difficult to detect, since these errors happen only if particular execution sequences take place and these sequences do not always occur.\\n',\n",
              " '   We have seen an example of such errors in the use of counters in our solution to the producer consumer problem (Section 5.1). In that example, the timing problem happened only rarely, and even then the counter value\\n',\n",
              " '   Unfortunately, such timing errors can still occur when semaphores are used. To illustrate how, we review the semaphore solution to the critical-section problem. All processes share a semaphore variable mutex, which is initialized to 1. Each process must execute wait(mutex) before entering the critical section and signal(mutex) afterward. If this sequence is not observed, two processes may be in their critical sections simultaneously. Next, we examine the various difficulties that may result. Note that these difficulties will arise even if a single process is not well behaved. This situation may be caused by an honest programming error or an uncooperative programmer.\\n',\n",
              " 'In this situation, several processes may be executing in their critical sections simultaneously, violating the mutual-exclusion requirement. This error may be discovered only if several processes are simultaneously active in their critical sections. Note that this situation may not always be reproducible.\\n',\n",
              " 'These examples illustrate that various types of errors can be generated easily when programmers use semaphores incorrectly to solve the critical-section problem. Similar problems may arise in the other synchronization models discussed in Section 5.7.\\n',\n",
              " '   To deal with such errors, researchers have developed high-level language constructs. In this section, we describe one fundamental high-level synchro- nization construct  the monitor type.\\n',\n",
              " 'An abstract data type  or ADT encapsulates data with a set of functions to operate on that data that are independent of any specific implementation of the ADT. A monitor type is an ADT that includes a set of programmer- defined operations that are provided with mutual exclusion within the monitor. The monitor type also declares the variables whose values define the state of an instance of that type, along with the bodies of functions that operate on those variables. The syntax of a monitor type is shown in Figure 5.15. The representation of a monitor type cannot be used directly by the various processes. Thus, a function defined within a monitor can access only those variables declared locally within the monitor and its formal parameters. Similarly, the local variables of a monitor can be accessed by only the local functions.\\n',\n",
              " '   The monitor construct ensures that only one process at a time is active within the monitor. Consequently, the programmer does not need to code this synchronization constraint explicitly (Figure 5.16). However, the monitor construct, as defined so far, is not sufficiently powerful for modeling some synchronization schemes. For this purpose, we need to define additional syn- chronization mechanisms. These mechanisms are provided by the condition construct. A programmer who needs to write a tailor-made synchronization scheme can define one or more variables of type condition:\\n',\n",
              " '   The x.signal() operation resumes exactly one suspended process. If no process is suspended, then the signal() operation has no effect; that is, the state of x is the same as if the operation had never been executed (Figure 5.17). Contrast this operation with the signal() operation associated with semaphores, which always affects the state of the semaphore.\\n',\n",
              " '   Now suppose that, when the x.signal() operation is invoked by a process P, there exists a suspended process Q associated with condition x. Clearly, if the suspended process Q is allowed to resume its execution, the signaling process P must wait. Otherwise, both P and Q would be active simultaneously within the monitor. Note, however, that conceptually both processes can continue with their execution. Two possibilities exist:\\n',\n",
              " '   There are reasonable arguments in favor of adopting either option. On the one hand, since P was already executing in the monitor, the signal-and- continue method seems more reasonable. On the other, if we allow thread P to continue, then by the time Q is resumed, the logical condition for which Q was waiting may no longer hold. A compromise between these two choices was adopted in the language Concurrent Pascal. When thread P executes the signal operation, it immediately leaves the monitor. Hence, Q is immediately resumed.\\n',\n",
              " '   Many programming languages have incorporated the idea of the monitor as described in this section, including Java and C# (pronounced C-sharp). Other languages such as Erlang provide some type of concurrency support using a similar mechanism.\\n',\n",
              " 'Next, we illustrate monitor concepts by presenting a deadlock-free solution to the dining-philosophers problem. This solution imposes the restriction that a philosopher may pick up her chopsticks only if both of them are available. To code this solution, we need to distinguish among three states in which we may find a philosopher. For this purpose, we introduce the following data structure:\\n',\n",
              " '    We are now in a position to describe our solution to the dining-philosophers problem. The distribution of the chopsticks is controlled by the monitor Din- ingPhilosophers, whose definition is shown in Figure 5.18. Each philosopher, before starting to eat, must invoke the operation pickup(). This act may result in the suspension of the philosopher process. After the successful completion of the operation, the philosopher may eat. Following this, the philosopher invokes the putdown() operation. Thus, philosopher i must invoke the operations pickup() and putdown() in the following sequence:\\n',\n",
              " '    It is easy to show that this solution ensures that no two neighbors are eating simultaneously and that no deadlocks will occur. We note, however, that it is possible for a philosopher to starve to death. We do not present a solution to this problem but rather leave it as an exercise for you.\\n',\n",
              " 'We now consider a possible implementation of the monitor mechanism using semaphores. For each monitor, a semaphore mutex (initialized to 1) is provided. A process must execute wait(mutex) before entering the monitor and must execute signal(mutex) after leaving the monitor.\\n',\n",
              " '   Since a signaling process must wait until the resumed process either leaves or waits, an additional semaphore, next, is introduced, initialized to 0. The signaling processes can use next to suspend themselves. An integer variable next count is also provided to count the number of processes suspended on next. Thus, each external function F is replaced by\\n',\n",
              " '   We can now describe how condition variables are implemented as well. For each condition x, we introduce a semaphore x sem and an integer variable x count, both initialized to 0. The operation x.wait() can now be implemented as\\n',\n",
              " '   This implementation is applicable to the definitions of monitors given by both Hoare and Brinch-Hansen (see the bibliographical notes at the end of the chapter). In some cases, however, the generality of the implementation is unnecessary, and a significant improvement in efficiency is possible. We leave this problem to you in Exercise 5.30.\\n',\n",
              " 'We turn now to the subject of process-resumption order within a monitor. If several processes are suspended on condition x, and an x.signal() operation is executed by some process, then how do we determine which of the suspended processes should be resumed next? One simple solution is to use a first-come, first-served (FCFS) ordering, so that the process that has been waiting the longest is resumed first. In many circumstances, however, such a simple scheduling scheme is not adequate. For this purpose, the conditional-wait construct can be used. This construct has the form\\n',\n",
              " 'where c is an integer expression that is evaluated when the wait() operation is executed. The value of c, which is called a priority number, is then stored with the name of the process that is suspended. When x.signal() is executed, the process with the smallest priority number is resumed next.\\n',\n",
              " '   To illustrate this new mechanism, consider the ResourceAllocator mon- itor shown in Figure 5.19, which controls the allocation of a single resource among competing processes. Each process, when requesting an allocation of this resource, specifies the maximum time it plans to use the resource. The mon- itor allocates the resource to the process that has the shortest time-allocation request. A process that needs to access the resource in question must observe the following sequence:\\n',\n",
              " '   The same difficulties are encountered with the use of semaphores, and these difficulties are similar in nature to those that encouraged us to develop the monitor constructs in the first place. Previously, we had to worry about the correct use of semaphores. Now, we have to worry about the correct use of higher-level programmer-defined operations, with which the compiler can no longer assist us.\\n',\n",
              " '   One possible solution to the current problem is to include the resource- access operations within the ResourceAllocator monitor. However, using this solution will mean that scheduling is done according to the built-in monitor-scheduling algorithm rather than the one we have coded.\\n',\n",
              " '   To ensure that the processes observe the appropriate sequences, we must inspect all the programs that make use of the ResourceAllocator monitor and its managed resource. We must check two conditions to establish the correctness of this system. First, user processes must always make their calls on the monitor in a correct sequence. Second, we must be sure that an uncooperative process does not simply ignore the mutual-exclusion gateway provided by the monitor and try to access the shared resource directly, without using the access protocols. Only if these two conditions can be ensured can we guarantee that no time-dependent errors will occur and that the scheduling algorithm will not be defeated.\\n',\n",
              " 'Java provides a monitor-like concurrency mechanism for thread synchro- nization. Every object in Java has associated with it a single lock. When a method is declared to be synchronized, calling the method requires owning the lock for the object. We declare a synchronized method by placing the synchronized keyword in the method definition. The following defines safeMethod() as synchronized, for example:\\n',\n",
              " 'Invoking sc.safeMethod() method requires owning the lock on the object instance sc. If the lock is already owned by another thread, the thread calling the synchronized method blocks and is placed in the entry set for the objects lock. The entry set represents the set of threads waiting for the lock to become available. If the lock is available when a synchronized method is called, the calling thread becomes the owner of the objects lock and can enter the method. The lock is released when the thread exits the method. A thread from the entry set is then selected as the new owner of the lock.\\n',\n",
              " '  Java also provides wait() and notify() methods, which are similar in function to the wait() and signal() statements for a monitor. The Java API provides support for semaphores, condition variables, and mutex locks (among other concurrency mechanisms) in the java.util.concurrent package.\\n',\n",
              " '   Although this inspection may be possible for a small, static system, it is not reasonable for a large system or a dynamic system. This access-control problem can be solved only through the use of the additional mechanisms that are described in Chapter 14.\\n',\n",
              " 'We next describe the synchronization mechanisms provided by the Windows, Linux, and Solaris operating systems, as well as the Pthreads API. We have chosen these three operating systems because they provide good examples of different approaches to synchronizing the kernel, and we have included the\\n',\n",
              " 'Pthreads API because it is widely used for thread creation and synchronization by developers on UNIX and Linux systems. As you will see in this section, the synchronization methods available in these differing systems vary in subtle and significant ways.\\n',\n",
              " 'The Windows operating system is a multithreaded kernel that provides support for real-time applications and multiple processors. When the Windows kernel accesses a global resource on a single-processor system, it temporarily masks interrupts for all interrupt handlers that may also access the global resource. On a multiprocessor system, Windows protects access to global resources using spinlocks, although the kernel uses spinlocks only to protect short code segments. Furthermore, for reasons of efficiency, the kernel ensures that a thread will never be preempted while holding a spinlock.\\n',\n",
              " '   For thread synchronization outside the kernel, Windows provides dis- patcher objects. Using a dispatcher object, threads synchronize according to several different mechanisms, including mutex locks, semaphores, events, and timers. The system protects shared data by requiring a thread to gain ownership of a mutex to access the data and to release ownership when it is finished. Semaphores behave as described in Section 5.6. Events are similar to condition variables; that is, they may notify a waiting thread when a desired condition occurs. Finally, timers are used to notify one (or more than one) thread that a specified amount of time has expired.\\n',\n",
              " '   Dispatcher objects may be in either a signaled state or a nonsignaled state. An object in a signaled state is available, and a thread will not block when acquiring the object. An object in a nonsignaled state is not available, and a thread will block when attempting to acquire the object. We illustrate the state transitions of a mutex lock dispatcher object in Figure 5.20.\\n',\n",
              " '   A relationship exists between the state of a dispatcher object and the state of a thread. When a thread blocks on a nonsignaled dispatcher object, its state changes from ready to waiting, and the thread is placed in a waiting queue for that object. When the state for the dispatcher object moves to signaled, the kernel checks whether any threads are waiting on the object. If so, the kernel moves one thread  or possibly more  from the waiting state to the ready state, where they can resume executing. The number of threads the kernel selects from the waiting queue depends on the type of dispatcher object for which it is waiting. The kernel will select only one thread from the waiting queue for a mutex, since a mutex object may be owned by only a single\\n',\n",
              " '   We can use a mutex lock as an illustration of dispatcher objects and thread states. If a thread tries to acquire a mutex dispatcher object that is in a nonsignaled state, that thread will be suspended and placed in a waiting queue for the mutex object. When the mutex moves to the signaled state (because another thread has released the lock on the mutex), the thread waiting at the front of the queue will be moved from the waiting state to the ready state and will acquire the mutex lock.\\n',\n",
              " '   A critical-section object is a user-mode mutex that can often be acquired and released without  kernel intervention. On a multiprocessor system, a critical-section object first uses a spinlock while waiting for the other thread to release the object. If it spins too long, the acquiring thread will then allocate a kernel mutex and yield its CPU. Critical-section objects are particularly efficient because the kernel mutex is allocated only when there is contention for the object. In practice, there is very little contention, so the savings are significant.\\n',\n",
              " 'Prior to Version 2.6, Linux was a nonpreemptive kernel, meaning that a process running in kernel mode could not be preempted even if a higher-priority process became available to run. Now, however, the Linux kernel is fully preemptive, so a task can be preempted when it is running in the kernel.\\n',\n",
              " '   Linux provides several different mechanisms for synchronization in the kernel. As most computer architectures provide instructions for atomic ver- sions of simple math operations, the simplest synchronization technique within the Linux kernel is an atomic integer, which is represented using the opaque data type atomic t. As the name implies, all math operations using atomic integers are performed without interruption. The following code illustrates declaring an atomic integer counter and then performing various atomic operations:\\n',\n",
              " 'atomic add(10, &counter); /* counter = counter + 10 */ atomic sub(4, &counter); /* counter = counter - 4 */ atomic inc(&counter);  /*  counter  =  counter  +  1  */ value = atomic read(&counter); /* value = 12 */\\n',\n",
              " ' such as a counter needs to be updated, since atomic operations do not require the overhead of locking mechanisms. However, their usage is limited to these sorts of scenarios. In situations where there are several variables contributing to a possible race condition, more sophisticated locking tools must be used.\\n',\n",
              " 'a critical section and the mutex unlock() function after exiting the critical section. If the mutex lock is unavailable, a task calling mutex lock() is put into a sleep state and is awakened when the locks owner invokes mutex unlock(). Linux also provides spinlocks and semaphores (as well as reader writer versions of these two locks) for locking in the kernel. On SMP machines, the fundamental locking mechanism is a spinlock, and the kernel is designed so that the spinlock is held only for short durations. On single-processor machines, such as embedded systems with only a single processing core, spinlocks are inappropriate for use and are replaced by enabling and disabling kernel preemption. That is, on single-processor systems, rather than holding a spinlock, the kernel disables kernel preemption; and rather than releasing the\\n',\n",
              " '   Linux uses an interesting approach to disable and enable kernel preemp- tion. It provides two simple system calls preempt disable() and pre- empt enable()for disabling and enabling kernel preemption. The kernel is not preemptible, however, if a task running in the kernel is holding a lock. To enforce this rule, each task in the system has a thread-info structure containing a counter, preempt count, to indicate the number of locks being held by the task. When a lock is acquired, preempt count is incremented. It is decremented when a lock is released. If the value of preempt count for the task currently running in the kernel is greater than 0, it is not safe to preempt the kernel, as this task currently holds a lock. If the count is 0, the kernel can safely be interrupted (assuming there are no outstanding calls to preempt disable()).\\n',\n",
              " '    Spinlocks along with enabling and disabling kernel preemption are used in the kernel only when a lock (or disabling kernel preemption) is held for a short duration. When a lock must be held for a longer period, semaphores or mutex locks are appropriate for use.\\n',\n",
              " 'To control access to critical sections, Solaris provides adaptive mutex locks, condition variables, semaphores, reader writer locks, and turnstiles. Solaris implements semaphores and condition variables essentially as they are pre- sented in Sections 5.6 and 5.7 In this section, we describe adaptive mutex locks, reader  writer locks, and turnstiles.\\n',\n",
              " '   An adaptive mutex protects access to every critical data item. On a multiprocessor system, an adaptive mutex starts as a standard semaphore implemented as a spinlock. If the data are locked and therefore already in use, the adaptive mutex does one of two things. If the lock is held by a thread that is currently running on another CPU, the thread spins while waiting for the lock to become available, because the thread holding the lock is likely to finish soon. If the thread holding the lock is not currently in run state, the thread\\n',\n",
              " 'blocks, going to sleep until it is awakened by the release of the lock. It is put to sleep so that it will not spin while waiting, since the lock will not be freed very soon. A lock held by a sleeping thread is likely to be in this category. On a single-processor system, the thread holding the lock is never running if the lock is being tested by another thread, because only one thread can run at a time. Therefore, on this type of system, threads always sleep rather than spin if they encounter a lock.\\n',\n",
              " '   Solaris uses the adaptive-mutex method to protect only data that are accessed by short code segments. That is, a mutex is used if a lock will be held for less than a few hundred instructions. If the code segment is longer than that, the spin-waiting method is exceedingly inefficient. For these longer code segments, condition variables and semaphores are used. If the desired lock is already held, the thread issues a wait and sleeps. When a thread frees the lock, it issues a signal to the next sleeping thread in the queue. The extra cost of putting a thread to sleep and waking it, and of the associated context switches, is less than the cost of wasting several hundred instructions waiting in a spinlock.\\n',\n",
              " '   Reader writer locks are used to protect data that are accessed frequently but are usually accessed in a read-only manner. In these circumstances, reader  writer locks are more efficient than semaphores, because multiple threads can read data concurrently, whereas semaphores always serialize access to the data. Reader writer locks are relatively expensive to implement, so again they are used only on long sections of code.\\n',\n",
              " '   Solaris uses turnstiles to order the list of threads waiting to acquire either an adaptive mutex or a reader writer lock. A turnstile is a queue structure containing threads blocked on a lock. For example, if one thread currently owns the lock for a synchronized object, all other threads trying to acquire the lock will block and enter the turnstile for that lock. When the lock is released, the kernel selects a thread from the turnstile as the next owner of the lock. Each synchronized object with at least one thread blocked on the objects lock requires a separate turnstile. However, rather than associating a turnstile with each synchronized object, Solaris gives each kernel thread its own turnstile. Because a thread can be blocked only on one object at a time, this is more efficient than having a turnstile for each object.\\n',\n",
              " '   The turnstile for the first thread to block on a synchronized object becomes the turnstile for the object itself. Threads subsequently blocking on the lock will be added to this turnstile. When the initial thread ultimately releases the lock, it gains a new turnstile from a list of free turnstiles maintained by the kernel. To prevent a priority inversion, turnstiles are organized according to a priority- inheritance protocol. This means that if a lower-priority thread currently holds a lock on which a higher-priority thread is blocked, the thread with the lower priority will temporarily inherit the priority of the higher-priority thread. Upon releasing the lock, the thread will revert to its original priority.\\n',\n",
              " '   Note that the locking mechanisms used by the kernel are implemented for user-level threads as well, so the same types of locks are available inside and outside the kernel. A crucial implementation difference is the priority- inheritance protocol. Kernel-locking routines adhere to the kernel priority- inheritance methods used by the scheduler, as described in Section 5.6.4. User-level thread-locking mechanisms do not provide this functionality.\\n',\n",
              " '   To optimize Solaris performance, developers have refined and fine-tuned the locking methods. Because locks are used frequently and typically are used for crucial kernel functions, tuning their implementation and use can produce great performance gains.\\n',\n",
              " 'Although the locking mechanisms used in Solaris are available to user-level threads as well as kernel threads, basically the synchronization methods discussed thus far pertain to synchronization within the kernel. In contrast, the Pthreads API is available for programmers at the user level and is not part of any particular kernel. This API provides mutex locks, condition variables, and read  write locks for thread synchronization.\\n',\n",
              " '   Mutex locks represent the fundamental synchronization technique used with Pthreads. A mutex lock is used to protect critical sections of code  that is, a thread acquires the lock before entering a critical section and releases it upon exiting the critical section. Pthreads uses the pthread mutex t data type for mutex locks. A mutex is created with the pthread mutex init() function. The first parameter is a pointer to the mutex. By passing NULL as a second parameter, we initialize the mutex to its default attributes. This is illustrated below:\\n',\n",
              " '   The mutex is acquired and  released with the pthread mutex lock() and pthread mutex unlock() functions. If the mutex lock is unavailable when pthread mutex lock() is invoked, the calling thread is blocked until the owner invokes pthread mutex unlock(). The following code illustrates protecting a critical section with mutex locks:\\n',\n",
              " 'All mutex functions return a value of 0 with correct operation; if an error occurs, these functions return a nonzero error code. Condition variables and read  write locks behave similarly to the way they are described in Sections 5.8 and 5.7.2, respectively.\\n',\n",
              " '    Many systems that implement Pthreads also provide semaphores, although semaphores are not part of the Pthreads standard and instead belong to the POSIX SEM extension. POSIX specifies two types  of semaphores named and\\n',\n",
              " 'unnamed. The fundamental distinction between the two is that a named semaphore has an actual name in the file system and can be shared by multiple unrelated processes. Unnamed semaphores can be used only by threads belonging to the same process. In this section, we describe unnamed semaphores.\\n',\n",
              " 'In this example, by passing the flag 0, we are indicating that this semaphore can be shared only by threads belonging to the process that created the semaphore. A nonzero value would allow other processes to access the semaphore as well. In addition, we initialize the semaphore to the value 1.\\n',\n",
              " '   In Section 5.6, we described the classical wait() and signal() semaphore operations. Pthreads names these operations sem wait() and sem post(), respectively. The following code sample illustrates protecting a critical section using the semaphore created above:\\n',\n",
              " '   There are other extensions to the Pthreads API  including spinlocks  but it is important to note that not all extensions are considered portable from one implementation to another. We provide several programming problems and projects at the end of this chapter that use Pthreads mutex locks and condition variables as well as POSIX semaphores.\\n',\n",
              " 'cores. However, multithreaded applications present an increased risk of race conditions and deadlocks. Traditionally, techniques such as mutex locks, semaphores, and monitors have been used to address these issues, but as the number of processing cores increases, it becomes increasingly difficult to design multithreaded applications that are free from race conditions and deadlocks.\\n',\n",
              " 'Quite often in computer science, ideas from one area of study can be used to solve problems in other areas. The concept of transactional memory originated in database theory, for example, yet it provides a strategy for process synchronization. A memory transaction is a sequence of memory read write operations that are atomic. If all operations in a transaction are completed, the memory transaction is committed. Otherwise, the operations must be aborted and rolled back. The benefits of transactional memory can be obtained through features added to a programming language.\\n',\n",
              " '    Consider an example. Suppose we have a function update() that modifies shared data. Traditionally, this function would be written using mutex locks (or semaphores) such as the following:\\n',\n",
              " 'However, using synchronization mechanisms such as mutex locks and semaphores involves many potential problems, including deadlock. Addition- ally, as the number of threads increases, traditional locking scales less well, because the level of contention among threads for lock ownership becomes very high.\\n',\n",
              " '   As an alternative to traditional locking methods, new features that take advantage of transactional memory can be added to a programming language. In our example, suppose we add the construct atomic S , which ensures that the operations in S execute as a transaction. This allows us to rewrite the update() function as follows:\\n',\n",
              " 'guaranteeing atomicity. Additionally, because no locks are involved, deadlock is not possible. Furthermore, a transactional memory system can identify which statements in atomic blocks can be executed concurrently, such as concurrent read access to a shared variable. It is, of course, possible for a programmer to identify these situations and use reader writer locks, but the task becomes increasingly difficult as the number of threads within an application grows.\\n',\n",
              " '    Transactional memory can be implemented in either software or hardware. Software transactional memory (STM), as the name suggests, implements transactional memory exclusively in software no special hardware is needed. STM works by inserting instrumentation code inside transaction blocks. The code is inserted by a compiler and manages each transaction by examining where statements may run concurrently and where specific low-level locking is required. Hardware transactional memory (HTM) uses hardware cache hierarchies and cache coherency protocols to manage and resolve conflicts involving shared data residing in separate processors caches. HTM requires no special code instrumentation and thus has less overhead than STM. However, HTM does require that existing cache hierarchies and cache coherency protocols be modified to support transactional memory.\\n',\n",
              " '   Transactional memory has existed for several years without widespread implementation. However, the growth of multicore systems and the associ- ated emphasis on concurrent and parallel programming have prompted a significant amount of research in this area on the part of both academics and commercial software and hardware vendors.\\n',\n",
              " 'In Section 4.5.2, we provided an overview of OpenMP and its support of parallel programming in a shared-memory environment. Recall that OpenMP includes a set of compiler directives and an API. Any code following the compiler directive #pragma omp parallel is identified as a parallel region and is performed by a number of threads equal to the number of processing cores in the system. The advantage of OpenMP (and similar tools) is that thread creation and management are handled by the OpenMP library and are not the responsibility of application developers.\\n',\n",
              " '   Along with its #pragma omp parallel compiler directive, OpenMP pro- vides the compiler directive #pragma omp critical, which specifies the code region following the directive as a critical section in which only one thread may be active at a time. In this way, OpenMP provides support for ensuring that threads do not generate race conditions.\\n',\n",
              " 'The critical-section compiler directive behaves much like a binary semaphore or mutex lock, ensuring that only one thread at a time is active in the critical section. If a thread attempts to enter a critical section when another thread is currently active in that section (that is, owns the section), the calling thread is blocked until the owner thread exits. If multiple critical sections must be used, each critical section can be assigned a separate name, and a rule can specify that no more than one thread may be active in a critical section of the same name simultaneously.\\n',\n",
              " '   An advantage of using the critical-section compiler directive in OpenMP is that it is generally considered easier to use than standard mutex locks. However, a disadvantage is that application developers must still identify possible race conditions and adequately protect shared data using the compiler directive. Additionally, because the critical-section compiler directive behaves much like a mutex lock, deadlock is still possible when two or more critical sections are identified.\\n',\n",
              " 'Most well-known programming languages such as C, C++, Java, and C# are known as imperative (or procedural) languages. Imperative languages are used for implementing algorithms that are state-based. In these languages, the flow of the algorithm is crucial to its correct operation, and state is represented with variables and other data structures. Of course, program state is mutable, as variables may be assigned different values over time.\\n',\n",
              " '   With the current emphasis on concurrent and parallel programming for multicore systems, there has been greater focus on functional programming languages, which follow a programming paradigm much different from that offered by imperative languages. The fundamental difference between imperative and functional languages is that functional languages do not maintain state. That is, once a variable has been defined and assigned a value, its value is immutable  it cannot change. Because functional languages disallow mutable state, they need not be concerned with issues such as race conditions and deadlocks. Essentially, most of the problems addressed in this chapter are nonexistent in functional languages.\\n',\n",
              " '   Several functional languages are presently in use, and we briefly mention two of them here: Erlang and Scala. The Erlang language has gained significant attention because of its support for concurrency and the ease with which it can be used to develop applications that run on parallel systems. Scala is a functional language that is also object-oriented. In fact, much of the syntax of Scala is similar to the popular object-oriented languages Java and C#. Readers\\n',\n",
              " 'interested in Erlang and Scala, and in further details about functional languages in general, are encouraged to consult the bibliography at the end of this chapter for additional references.\\n',\n",
              " 'Given a collection of cooperating sequential processes that share data, mutual exclusion must be provided to ensure that a critical section of code is used by only one process or thread at a time. Typically, computer hardware provides several operations that ensure mutual exclusion. However, such hardware- based solutions are too complicated for most developers to use. Mutex locks and semaphores overcome this obstacle. Both tools can be used to solve various synchronization problems and can be implemented efficiently, especially if hardware support for atomic operations is available.\\n',\n",
              " '   Various synchronization problems (such as the bounded-buffer problem, the readers writers problem, and the dining-philosophers problem) are impor- tant mainly because they are examples of a large class of concurrency-control problems. These problems are used to test nearly every newly proposed synchronization scheme.\\n',\n",
              " '   The operating system must provide the means to guard against timing errors, and several language constructs have been proposed to deal with these problems. Monitors provide a synchronization mechanism for sharing abstract data types. A condition variable provides a method by which a monitor function can block its execution until it is signaled to continue.\\n',\n",
              " '    Operating systems also provide support for synchronization. For example, Windows, Linux, and Solaris provide mechanisms such as semaphores, mutex locks, spinlocks, and condition variables to control access to shared data. The Pthreads API provides support for mutex locks and semaphores, as well as condition variables.\\n',\n",
              " '   Several alternative approaches focus on synchronization for multicore systems. One approach uses transactional memory, which may address syn- chronization issues using either software or hardware techniques. Another approach uses the compiler extensions offered by OpenMP. Finally, func- tional programming languages address synchronization issues by disallowing mutability.\\n',\n",
              " '5.2 Explain why Windows, Linux, and Solaris implement multiple locking mechanisms. Describe the circumstances under which they use spin- locks, mutex locks, semaphores, adaptive mutex locks, and condition variables. In each case, explain why the mechanism is needed.\\n',\n",
              " '5.7 Race conditions are possible in many computer systems. Consider a banking system that maintains an account balance with two functions: deposit(amount) and withdraw(amount). These two functions are passed the amount that is to be deposited or withdrawn from the bank account balance. Assume that a husband and wife share a bank account. Concurrently, the husband calls the withdraw() function and the wife calls deposit(). Describe how a race condition is possible and what might be done to prevent the race condition from occurring.\\n',\n",
              " 'The structure of process  Pi  (i == 0 or 1) is shown in Figure 5.21. The other process is  Pj  (j == 1 or 0). Prove that the algorithm satisfies all three requirements for the critical-section problem.\\n',\n",
              " '5.9 The first known correct software solution to the critical-section problem for n processes with a lower bound on waiting of n 1 turns was presented by Eisenberg and McGuire. The processes share the following variables:\\n',\n",
              " 'All the elements of flag are initially idle. The initial value of turn is immaterial (between 0 and n-1). The structure of process Pi is shown in Figure 5.22. Prove that the algorithm satisfies all three requirements for the critical-section problem.\\n',\n",
              " '5.10 Explain why implementing synchronization primitives by disabling interrupts is not appropriate in a single-processor system if the syn- chronization primitives are to be used in user-level programs.\\n',\n",
              " '(available == 0) indicates that the lock is available, and a value of 1 indicates that the lock is unavailable. Using this struct, illustrate how the following functions can be implemented using the test and set() and compare and swap() instructions:\\n',\n",
              " '5.16 The implementation of mutex locks provided in Section 5.5 suffers from busy waiting. Describe what changes would be necessary so that a process waiting to acquire a mutex lock would be blocked and placed into a waiting queue until the lock became available.\\n',\n",
              " '5.17 Assume that a system has multiple processing cores. For each of the following scenarios, describe which is a better locking mechanism  a spinlock or a mutex lock where waiting processes sleep while waiting for the lock to become available:\\n',\n",
              " '5.18 Assume that a context switch takes T time. Suggest an upper bound (in terms of T ) for holding a spinlock. If the spinlock is held for any longer, a mutex lock (where waiting threads are put to sleep) is a better alternative.\\n',\n",
              " '5.19 A multithreaded web server wishes to keep track of the number of requests it services (known as hits). Consider the two following strategies to prevent a race condition on the variable hits. The first strategy is to use a basic mutex lock when updating hits:\\n',\n",
              " '5.21 Servers can be designed to limit the number of open connections. For example, a server may wish to have only N socket connections at any point in time. As soon as N connections are made, the server will not accept another incoming connection until an existing connection is released. Explain how semaphores can be used by a server to limit the number of concurrent connections.\\n',\n",
              " '5.22 Windows Vista provides a lightweight synchronization tool called slim reader  writer locks. Whereas most implementations of reader writer locks favor either readers or writers, or perhaps order waiting threads using a FIFO policy, slim reader writer locks favor neither readers nor writers, nor are waiting threads ordered in a FIFO queue. Explain the benefits of providing such a synchronization tool.\\n',\n",
              " '5.23 Show how to implement the wait() and signal() semaphore oper- ations in multiprocessor environments using the test and set() instruction. The solution should exhibit minimal busy waiting.\\n',\n",
              " '5.24 Exercise 4.26 requires the parent thread to wait for the child thread to finish its execution before printing out the computed values. If we let the parent thread access the Fibonacci numbers as soon as they have been computed by the child thread  rather than waiting for the child thread to terminate  what changes would be necessary to the solution for this exercise? Implement your modified solution.\\n',\n",
              " '5.28 Discuss the tradeoff between fairness and throughput of operations in the readers writers problem. Propose a method for solving the readers  writers problem without causing starvation.\\n',\n",
              " '5.30 Suppose the signal() statement can appear only as the last statement in a monitor function. Suggest how the implementation described in Section 5.8 can be simplified in this situation.\\n',\n",
              " '5.31 Consider a system consisting of processes P1, P2, ..., Pn, each of which has a unique priority number. Write a monitor that allocates three identical printers to these processes, using the priority numbers for deciding the order of allocation.\\n',\n",
              " '5.32 A file is to be shared among different processes, each of which has a unique number. The file can be accessed simultaneously by several processes, subject to the following constraint: the sum of all unique numbers associated with all the processes currently accessing the file must be less than n. Write a monitor to coordinate access to the file.\\n',\n",
              " '5.33 When a signal is performed on a condition inside a monitor, the signaling process can either continue its execution or transfer control to the process that is signaled. How would the solution to the preceding exercise differ with these two different ways in which signaling can be performed?\\n',\n",
              " '5.34 Suppose we replace the wait() and signal() operations of moni- tors with a single construct await(B), where B is a general Boolean expression that causes the process executing it to wait until B becomes true.\\n',\n",
              " '5.35 Design an algorithm for a monitor that implements an alarm clock that enables a calling program to delay itself for a specified number of time units (ticks). You may assume the existence of a real hardware clock that invokes a function tick() in your monitor at regular intervals.\\n',\n",
              " '5.36 Programming Exercise 3.20 required you to design a PID manager that allocated a unique process identifier to each process. Exercise 4.20 required you to modify your solution to Exercise 3.20 by writing a program that created a number of threads that requested and released process identifiers. Now modify your solution to Exercise 4.20 by ensuring that the data structure used to represent the availability of process identifiers is safe from race conditions. Use Pthreads mutex locks, described in Section 5.9.4.\\n',\n",
              " '5.37 Assume that a finite number of resources of a single resource type must be managed. Processes may ask for a number of these resources and will return them once finished. As an example, many commercial software packages provide a given number of licenses, indicating the number of applications that may run concurrently. When the application is started, the license count is decremented. When the application is terminated, the license count is incremented. If all licenses are in use, requests to start the application are denied. Such requests will only be granted when an existing license holder terminates the application and a license is returned.\\n',\n",
              " '   The following program segment is used to manage a finite number of instances of an available resource. The maximum number of resources and the number of available resources are declared as follows:\\n',\n",
              " 'c. Using a semaphore or mutex lock, fix the race condition. It is permissible to modify the decrease count() function so that the calling process is blocked until sufficient resources are available.\\n',\n",
              " '5.38 The decrease count() function in the previous exercise currently returns 0 if sufficient resources are available and 1 otherwise. This leads to awkward programming for a process that wishes to obtain a number of resources:\\n',\n",
              " 'Rewrite the resource-manager code segment using a monitor and condition variables so that the decrease count() function suspends the process until sufficient resources are available. This will allow a process to invoke decrease count() by simply calling\\n',\n",
              " '5.39 Exercise 4.22 asked you to design a multithreaded program that esti- mated  using the Monte Carlo technique. In that exercise, you were asked to create a single thread that generated random points, storing the result in a global variable. Once that thread exited, the parent thread performed the calcuation that estimated the value of . Modify that program so that you create several threads, each of which generates random points and determines if the points fall within the circle. Each thread will have to update the global count of all points that fall within the circle. Protect against race conditions on updates to the shared global variable by using mutex locks.\\n',\n",
              " '5.40 Exercise 4.23 asked you to design a program using OpenMP that estimated  using the Monte Carlo technique. Examine your solution to that program looking for any possible race conditions. If you identify a race condition, protect against it using the strategy outlined in Section 5.10.2.\\n',\n",
              " '5.41 A barrier is a tool for synchronizing the activity of a number of threads. When a thread reaches a barrier point, it cannot proceed until all other threads have reached this point as well. When the last thread reaches the barrier point, all threads are released and can resume concurrent execution.\\n',\n",
              " 'The return value of each function is used to identify error conditions. Each function will return 0 under normal operation and will return 1 if an error occurs. A testing harness is provided in the source code\\n',\n",
              " 'A university computer science department has a teaching assistant (TA) who helps undergraduate students with their programming assignments during regular office hours. The TAs office is rather small and has room for only one desk with a chair and computer. There are three chairs in the hallway outside the office where students can sit and wait if the TA is currently helping another student. When there are no students who need help during office hours, the TA sits at the desk and takes a nap. If a student arrives during office hours and finds the TA sleeping, the student must awaken the TA to ask for help. If a student arrives and finds the TA currently helping another student, the student sits on one of the chairs in the hallway and waits. If no chairs are available, the student will come back at a later time.\\n',\n",
              " 'Using Pthreads (Section 4.4.1), begin by creating n students. Each will run as a separate thread. The TA will run as a separate thread as well. Student threads will alternate between programming for a period of time and seeking help from the TA. If the TA is available, they will obtain help. Otherwise, they will either sit in a chair in the hallway or, if no chairs are available, will resume programming and will seek help at a later time. If a student arrives and notices that the TA is sleeping, the student must notify the TA using a semaphore. When the TA finishes helping a student, the TA must check to see if there are students waiting for help in the hallway. If so, the TA must help each of these students in turn. If no students are present, the TA may return to napping.\\n',\n",
              " 'In Section 5.7.3, we provide an outline of a solution to the dining-philosophers problem using monitors. This problem will require implementing a solution using Pthreads mutex locks and condition variables.\\n',\n",
              " 'Begin by creating five philosophers, each identified by a number 0 . . 4. Each philosopher will run as a separate thread. Thread creation using Pthreads is covered in Section 4.4.1. Philosophers alternate between thinking and eating. To simulate both activities, have the thread sleep for a random period between one and three seconds. When a philosopher wishes to eat, she invokes the function\\n',\n",
              " '5.8. However, in that section, condition variables are used within the context of a monitor, which provides a locking mechanism to ensure data integrity. Since Pthreads is typically used in C programs and since C does not have a monitor we accomplish locking by associating a condition variable with a mutex lock. Pthreads mutex locks are covered in Section 5.9.4. We cover Pthreads condition variables here.\\n',\n",
              " '   Condition variables in Pthreads use the pthread cond t data type and are initialized using the pthread cond init() function. The following code creates and initializes a condition variable as well as its associated mutex lock:\\n',\n",
              " '   The pthread cond wait() function is used for waiting on a condition variable. The following code illustrates how a thread can wait for the condition a == b to become true using a Pthread condition variable:\\n',\n",
              " '   The mutex lock associated with the condition variable must be locked before the pthread cond wait() function is called, since it is used to protect the data in the conditional clause from a possible race condition. Once this lock is acquired, the thread can check the condition. If the condition is not true, the thread then invokes pthread cond wait(), passing the mutex lock and the condition variable as parameters. Calling pthread cond wait() releases the mutex lock, thereby allowing another thread to access the shared data and possibly update its value so that the condition clause evaluates to true. (To protect against program errors, it is important to place the conditional clause within a loop so that the condition is rechecked after being signaled.)\\n',\n",
              " '   A   thread   that   modifies   the   shared    data    can    invoke    the pthread cond signal()  function, thereby signaling   one   thread   waiting on the condition variable. This is illustrated below:\\n',\n",
              " '   It is important to note that the call to pthread cond signal() does not release the mutex lock. It is the subsequent call to pthread mutex unlock() that releases the mutex. Once the mutex lock is released, the signaled thread becomes the owner of the mutex lock and returns control from the call to pthread cond wait().\\n',\n",
              " 'In Section 5.7.1, we presented a semaphore-based solution to the producer consumer problem using a bounded buffer. In this project, you will design a programming solution to the bounded-buffer problem using the producer and consumer processes shown in Figures 5.9 and 5.10. The solution presented in Section 5.7.1 uses three semaphores: empty and full, which count the number of empty and full slots in the buffer, and mutex, which is a binary (or mutual- exclusion) semaphore that protects the actual insertion or removal of items in the buffer. For this project, you will use standard counting semaphores for empty and full and a mutex lock, rather than a binary semaphore, to represent mutex. The producer and consumer running as separate threads will move items to and from a buffer that is synchronized with the empty, full, and mutex structures. You can solve this problem using either Pthreads or the Windows API.\\n',\n",
              " 'Internally, the buffer will consist of a fixed-size array of type buffer item (which will be defined using a typedef). The array of buffer item objects will be manipulated as a circular queue. The definition of buffer item, along with the size of the buffer, can be stored in a header file such as the following:\\n',\n",
              " 'The buffer will be manipulated with two functions, insert item() and remove item(), which are called by the producer and consumer threads, respectively. A skeleton outlining these functions appears in Figure 5.24.\\n',\n",
              " '   The main() function will initialize the buffer and create the separate producer and consumer threads. Once it has created the producer and consumer threads, the main() function will sleep for a period of time and, upon awakening, will terminate the application. The main() function will be passed three parameters on the command line:\\n',\n",
              " 'The producer thread will alternate between sleeping for a random period of time and inserting a random integer into the buffer. Random numbers will be produced using the rand() function, which produces random integers between 0 and RAND MAX. The consumer will also sleep for a random period of time and, upon awakening, will attempt to remove an item from the buffer. An outline of the producer and consumer threads appears in Figure 5.26.\\n',\n",
              " ...]"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "DMrOKb2HeAHJ"
      },
      "outputs": [],
      "source": [
        "dataDict={'context':s}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "TwaKzKXmeAHK"
      },
      "outputs": [],
      "source": [
        "data=pd.DataFrame(dataDict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fkoeLqIGeAHL",
        "outputId": "1da361f4-d158-46d5-c01f-9a8de0d75b86"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Internally, operating systems vary greatly ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Because an operating system is large and co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>An operating system is a program that manages ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Before we can explore the details of compu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Because an operating system is large and co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3856</th>\n",
              "      <td>[Rashid and Robertson (1981)] R. Rashid and G....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3857</th>\n",
              "      <td>[Tevanian et al. (1987b)] A. Tevanian, Jr., R....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3858</th>\n",
              "      <td>Figure 1.11: From Hennesy and Patterson, Comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3859</th>\n",
              "      <td>Figure 12.9: From Leffler/McKusick/Karels/Qua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3860</th>\n",
              "      <td>Figures 17.5, 17.6, and 17.8: From Halsall, D...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3861 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                context\n",
              "0        Internally, operating systems vary greatly ...\n",
              "1        Because an operating system is large and co...\n",
              "2     An operating system is a program that manages ...\n",
              "3         Before we can explore the details of compu...\n",
              "4        Because an operating system is large and co...\n",
              "...                                                 ...\n",
              "3856  [Rashid and Robertson (1981)] R. Rashid and G....\n",
              "3857  [Tevanian et al. (1987b)] A. Tevanian, Jr., R....\n",
              "3858   Figure 1.11: From Hennesy and Patterson, Comp...\n",
              "3859   Figure 12.9: From Leffler/McKusick/Karels/Qua...\n",
              "3860   Figures 17.5, 17.6, and 17.8: From Halsall, D...\n",
              "\n",
              "[3861 rows x 1 columns]"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "rjBxdyT8eAHL"
      },
      "outputs": [],
      "source": [
        "train,val=train_test_split(data,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "iERvmJwyeAHM"
      },
      "outputs": [],
      "source": [
        "device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "QKw1ik042p7g"
      },
      "outputs": [],
      "source": [
        "def replace_linear_with_quantized(model):\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            quantized_layer = bnb.nn.Linear8bitLt(\n",
        "                module.in_features, module.out_features, bias=module.bias is not None\n",
        "            )\n",
        "            setattr(model, name, quantized_layer)\n",
        "        else:\n",
        "            replace_linear_with_quantized(module)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429,
          "referenced_widgets": [
            "968a7ee1eed349b58a07f65c7171ec25",
            "95ecaea34477439aa3d513357a9e1fed",
            "cdee43a350284239b95e0846dd65f5d3",
            "39ad91c9e9054e368bc834285e73a034",
            "46f96d19d53b449191ca5c48e11ac9e5",
            "ccf7c751578948d3b1acef6a80c910cb",
            "d45cd1355ef34f0b849efbd1063f75e9",
            "37de3204be71461781e159c8073a527d",
            "d528510b18174f4cb8ec25df6823bae5",
            "83d607d76ec1482dbdc0f928862c1d29",
            "b32cacceea6e45f4a168ecc7c831b9b5",
            "9caab121ba834f73acfb64b41766d8f0",
            "dc426d061c754be8b07232e0ecfb250e",
            "64f31b01a4e54421a7762fb989a02682",
            "93c670676fa54cb986855267bd1e99bb",
            "46e024d7dee646cb9ac7ff24a4f305e9",
            "b128a09e09834c80ac9a06caeb51405a",
            "2fe0498f8dd3437eafcfd5ebac0c9a12",
            "94e4a21a8505418a9bae0787793e3bc6",
            "16dc106cbdcd4fc2b488d40aa5dd9cb9",
            "132fa1a7778d4e2b9724762e02d5caa5",
            "6dc438adeecc464fb23d9f7d35fa19b0",
            "780d9f175c094ff1838a21609a0f6a16",
            "18c00b17204a43b5933a585ca6fe1709",
            "f61e39d0001342ab814b7846404254b7",
            "5dc4e43d0f7d4ce483c20a0062479728",
            "63a34540eb79438795e01b6d0cb09409",
            "ef10752385864568ad161de490e66d00",
            "19fdb98f58364729b08d0afa173a8288",
            "5454d148b0fa4c15850945391defd1f8",
            "f276485b7fd14a43b03f32d68aa3f6d5",
            "7c30683a258449ad91c83045b5540917",
            "2c54bc07c60647498fd66a1802bf9fa2",
            "90016f41ded64f2ea47024ccf8e07330",
            "6f37d7dd04a94c0584c5a75627a1ce26",
            "a7cec87970c7414baee4016de38e4b50",
            "6f0a9baf6cbf454980d380a058cbe7da",
            "364c8e5116834ebfb3d207328a03ed0b",
            "1b5910f6d99c4506a5ad39a7967e580e",
            "b5da88da852142c29d4febec72f8dbb0",
            "ca4a09b42ef749a697a0596527b6a560",
            "841b4dad5da741e68fbc8df590d0e4c7",
            "36134711e6fa4fb9b7889b54b98b64d9",
            "952aab2645944dd6a8407c981d6639ba",
            "a08ed7f6aee641a7a13f32490a9d7d42",
            "0f5978e0628d4a5a8a4e5bb7cddb99f4",
            "7d61b299408d41b4af6f849ecb544861",
            "6be4c5e7bfec46f0aeb674c5b9971eed",
            "e8fe5a3f063844fba0dfbc28ed12375c",
            "bbc655168f654b65874177e2cb2a90f9",
            "9ce35ba7be0c4e249af62e8fc06cb6b2",
            "3cbd3e2c2f1a4fd1ac82f594fbb2d1c9",
            "2b445da530ee4c968cff1f4f23809449",
            "2cbc823aa51845a3bf49424bbd7390e3",
            "3fe5ca7c802443a5ba6a1e99be84c45a",
            "83e7cc23b26c430388dc27988efec952",
            "c9785f258a9c44c1991bb2d9f31e6ceb",
            "094e2cb072c448fc955193aac5ed9cc9",
            "94928d381d5647e3a67a38384f58d2d5",
            "0e57a414cb954a36a2f95e2211f30ac0",
            "77bb15531efb4fab9e1b066d307d0e60",
            "cc9cc33751194c7fb331363770d718dc",
            "1fd907728ec547179d309868fa4785ca",
            "a74bff5d8efa4a0e995096af655cdcf0",
            "81d3fc1c95bc4ede9908588674c88a0a",
            "76183fb7970348e49ca633affe45b876",
            "18ac5b9cf89144078be559c1cc69afc0",
            "ca6291a586c34c2ebc5025f657cca2cb",
            "af9cabc910d94b92ba34f00dda644e4f",
            "656a6399de6e4a368b400b04a18c67cf",
            "0cd192bc71e348feae99d82a91e2272a",
            "927514161df242d1998f112cf5ae0f22",
            "abf239eb95c74afeaa6de1ad6f20860a",
            "7f062ac5a24945429c901ba6c1a9c8fa",
            "80f6b725374848e896c78c380df8a761",
            "741a1dadfef348a2978498b6de519f61",
            "5af09f96b6104d2092347f496ea17513",
            "5ac2ed6f76214a448c96b8243bac455b",
            "dd2b7dd4846a4e01b3dd00ac955dce77",
            "54803b403ad8429893f7984a00d0a295",
            "b03fd632eaaf4547a68792c93806d5c3",
            "a3ce4a361f4d474baaa89f6f97a236e7",
            "b8b1948f0c5b4dfdbb2217ca1e934d1d",
            "1f49c43e786845eea22a3e64601527f7",
            "2cf10a6e9c684fd3b4c2b096a52421da",
            "bea86f43b4054122a332638a79c71f54",
            "edac2586274545c198256949ab98db91",
            "600b8f7e52004a52b456a23bc33bf470",
            "809024fe2d1843758b692ddb1b345508",
            "561ff545431c439383c99d725da73261",
            "8ac9aae4acab4270a4289b180acf2251",
            "a0129d439d4d4ff1bec1ecbc936d7a28",
            "f105d7e9329047dabbbaba12c436d108",
            "0a22f0b0f49c486199b1fe21dbddc5c8",
            "a288dfd190b44c9e8f7d638afdda963a",
            "9b9e4a60a93841e68945f6a7149ea921",
            "b152d142cbd04e7dbf63643b4262019e",
            "da8389e6eda1454e877694c340e51054",
            "8c8bca6276db4fb3a48c23abde0ee305"
          ]
        },
        "id": "NFeVPQHweAHM",
        "outputId": "9be2a3f4-49e6-4752-bc56-c760ab8c5147"
      },
      "outputs": [],
      "source": [
        "model=BlenderbotForCausalLM.from_pretrained('facebook/blenderbot-400M-distill').to(device)\n",
        "tokenizer=AutoTokenizer.from_pretrained('facebook/blenderbot-400M-distill')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "xEPL8lWA2plx"
      },
      "outputs": [],
      "source": [
        "\n",
        "replace_linear_with_quantized(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "jTiF4fiaeAHM"
      },
      "outputs": [],
      "source": [
        "def prep(examples):\n",
        "    inputs=[]\n",
        "    mask=[]\n",
        "    labels=[]\n",
        "    for prompt in examples['context']:\n",
        "\n",
        "        input=tokenizer(str(prompt),max_length=256,truncation=True,padding='max_length',return_tensors='pt')\n",
        "        inputs.append(input['input_ids'])\n",
        "        mask.append(input['attention_mask'])\n",
        "        labels.append(input['input_ids'])\n",
        "    return inputs,mask,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "fi3pCAl9eAHM"
      },
      "outputs": [],
      "source": [
        "trainInputs, trainMasks, trainLabels =prep(train)\n",
        "valinp,valmask,vallabel=prep(val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRl-XbJHeAHN",
        "outputId": "1317ebe5-3a41-4f05-f93d-e64a936efd08"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Sid\\AppData\\Local\\Temp\\ipykernel_8796\\1426310643.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  trainInputs = torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in trainInputs], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
            "C:\\Users\\Sid\\AppData\\Local\\Temp\\ipykernel_8796\\1426310643.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  trainMasks = torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in trainMasks], batch_first=True, padding_value=0).to(device)\n",
            "C:\\Users\\Sid\\AppData\\Local\\Temp\\ipykernel_8796\\1426310643.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  trainLabels = torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in trainLabels], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
            "C:\\Users\\Sid\\AppData\\Local\\Temp\\ipykernel_8796\\1426310643.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  valinp      =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in valinp], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
            "C:\\Users\\Sid\\AppData\\Local\\Temp\\ipykernel_8796\\1426310643.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  valmask     =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in valmask], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
            "C:\\Users\\Sid\\AppData\\Local\\Temp\\ipykernel_8796\\1426310643.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  vallabel    =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in vallabel], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n"
          ]
        }
      ],
      "source": [
        "trainInputs = torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in trainInputs], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
        "trainMasks = torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in trainMasks], batch_first=True, padding_value=0).to(device)\n",
        "trainLabels = torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in trainLabels], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
        "valinp      =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in valinp], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
        "valmask     =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in valmask], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
        "vallabel    =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in vallabel], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "5O5s5ldneAHN"
      },
      "outputs": [],
      "source": [
        "trainData=TensorDataset(trainInputs,trainMasks,trainLabels)\n",
        "trainData=DataLoader(trainData,shuffle=True,batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "4k6rp3SVeAHO"
      },
      "outputs": [],
      "source": [
        "valDataset=TensorDataset(valinp,valmask,vallabel)\n",
        "valDataloader=DataLoader(valDataset,batch_size=4,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N0JD_NkeAHP",
        "outputId": "12ce6378-01da-4d14-86aa-001099c56bfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BlenderbotConfig {\n",
              "  \"_name_or_path\": \"facebook/blenderbot-400M-distill\",\n",
              "  \"activation_dropout\": 0.0,\n",
              "  \"activation_function\": \"gelu\",\n",
              "  \"add_bias_logits\": false,\n",
              "  \"add_final_layer_norm\": true,\n",
              "  \"architectures\": [\n",
              "    \"BlenderbotForConditionalGeneration\"\n",
              "  ],\n",
              "  \"attention_dropout\": 0.0,\n",
              "  \"bos_token_id\": 1,\n",
              "  \"classif_dropout\": 0.0,\n",
              "  \"classifier_dropout\": 0.0,\n",
              "  \"d_model\": 1280,\n",
              "  \"decoder_attention_heads\": 32,\n",
              "  \"decoder_ffn_dim\": 5120,\n",
              "  \"decoder_layerdrop\": 0.0,\n",
              "  \"decoder_layers\": 12,\n",
              "  \"decoder_start_token_id\": 1,\n",
              "  \"do_blenderbot_90_layernorm\": true,\n",
              "  \"dropout\": 0.1,\n",
              "  \"encoder_attention_heads\": 32,\n",
              "  \"encoder_ffn_dim\": 5120,\n",
              "  \"encoder_layerdrop\": 0.0,\n",
              "  \"encoder_layers\": 2,\n",
              "  \"encoder_no_repeat_ngram_size\": 3,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"extra_layer_norm\": false,\n",
              "  \"extra_pos_embeddings\": 0,\n",
              "  \"force_bos_token_to_be_generated\": false,\n",
              "  \"forced_eos_token_id\": 2,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"id2label\": {\n",
              "    \"0\": \"LABEL_0\",\n",
              "    \"1\": \"LABEL_1\",\n",
              "    \"2\": \"LABEL_2\"\n",
              "  },\n",
              "  \"init_std\": 0.02,\n",
              "  \"is_decoder\": true,\n",
              "  \"is_encoder_decoder\": false,\n",
              "  \"label2id\": {\n",
              "    \"LABEL_0\": 0,\n",
              "    \"LABEL_1\": 1,\n",
              "    \"LABEL_2\": 2\n",
              "  },\n",
              "  \"layernorm_variant\": \"prelayernorm\",\n",
              "  \"length_penalty\": 0.65,\n",
              "  \"max_length\": 60,\n",
              "  \"max_position_embeddings\": 128,\n",
              "  \"min_length\": 20,\n",
              "  \"model_type\": \"blenderbot\",\n",
              "  \"no_repeat_ngram_size\": 3,\n",
              "  \"normalize_before\": true,\n",
              "  \"normalize_embedding\": false,\n",
              "  \"num_beams\": 10,\n",
              "  \"num_hidden_layers\": 2,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"scale_embedding\": true,\n",
              "  \"static_position_embeddings\": false,\n",
              "  \"transformers_version\": \"4.42.3\",\n",
              "  \"unk_token_id\": 3,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 8008\n",
              "}"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "N1JSHxypeAHQ"
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=64,                                # Adapter size or other fine-tuning parameter\n",
        "    lora_alpha=32,                       # Adapter initialization strength\n",
        "    target_modules=[\n",
        "    \"model.shared\",                       # Shared modules across encoder and decoder\n",
        "    \"model.encoder.layers\",               # Encoder layers for processing input sequences\n",
        "    \"model.encoder.self_attn.q_proj\",     # Attention projection for encoder self-attention query\n",
        "    \"model.encoder.self_attn.v_proj\",     # Attention projection for encoder self-attention value\n",
        "    \"model.decoder.layers.0.self_attn.q_proj\", # Example of accessing a specific Linear layer\n",
        "    \"model.decoder.layers.0.self_attn.v_proj\", # Example of accessing another specific Linear layer\n",
        "],\n",
        "    lora_dropout=0.05,                   # Dropout rate for LORA\n",
        "    bias=\"none\",                         # Bias setting (e.g., none, fixed, adapt)\n",
        "    task_type=TaskType.CAUSAL_LM         # Task type for causal language modeling (adjust if necessary)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "tpos_igxeAHQ"
      },
      "outputs": [],
      "source": [
        "model=get_peft_model(model,lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LNUjcqBeAHQ",
        "outputId": "d6e7cdc0-690d-47c0-b2da-986ca0f97c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 327,680 || all params: 335,859,200 || trainable%: 0.0976\n"
          ]
        }
      ],
      "source": [
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "6rdbiX-ZeAHR"
      },
      "outputs": [],
      "source": [
        "batchSize=4\n",
        "learningRate=2e-5\n",
        "epochs=400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QAFcrU3eAHS",
        "outputId": "69d0cb7e-d007-432e-b186-dc4dc091a573"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer  = AdamW(model.parameters(),lr=learningRate)\n",
        "criterion  = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBidB44aeAHT",
        "outputId": "c564038a-72e7-4d71-eb03-48590ff087bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in c:\\users\\sid\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.66.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\sid\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEPRECATION: pytorch-lightning 1.5.10 has a non-standard dependency specifier torch>=1.7.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "bpcXUeU4eAHT"
      },
      "outputs": [],
      "source": [
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "wandb.watch(model)\n",
        "wandb.config[\"learning_rate\"] = learningRate\n",
        "wandb.config[\"batch_size\"] = batchSize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "yEF47UF7eAHU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "def train(model,optimizer,criterion,DataLoader):\n",
        "    from tqdm.auto import tqdm\n",
        "    model.train()\n",
        "    tloss=0\n",
        "    tcorrect=0 # Initialize a variable to store the number of correct predictions\n",
        "    total_samples = 0\n",
        "    all_preds = []\n",
        "    all_labels = [] # Initialize a variable to store the total number of samples\n",
        "    for batch,(inputs,mask,lab)in enumerate(DataLoader):\n",
        "        inputs=inputs.to(device)\n",
        "        mask=mask.to(device)\n",
        "        label=lab.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs=model(input_ids=inputs,attention_mask=mask,labels=label)\n",
        "        loss=outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        tloss+=loss.item()\n",
        "        preds = torch.argmax(outputs.logits, dim=-1)\n",
        "        \n",
        "            \n",
        "        all_preds.extend(preds.cpu().numpy().flatten())\n",
        "        all_labels.extend(label.cpu().numpy().flatten())\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "    accuracy =accuracy_score(all_labels, all_preds)\n",
        "\n",
        "\n",
        "    return tloss/len(DataLoader),accuracy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "SBjZxhv3eAHU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 4.2125\n",
            "Validation Precision: 0.0001\n",
            "Validation Recall: 0.0002\n",
            "Validation Accuracy: 0.5287\n",
            "Validation BLEU score: 0.0000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "\n",
        "def validate(model, dataloader, criterion, device, tokenizer):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_references = []\n",
        "    all_hypotheses = []\n",
        "    \n",
        "    smoothing_function = SmoothingFunction().method1  # Choose an appropriate smoothing method\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch, (inputs, mask, lab) in enumerate(dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            mask = mask.to(device)\n",
        "            labels = lab.to(device)\n",
        "            \n",
        "            outputs = model(input_ids=inputs, attention_mask=mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "            preds = torch.argmax(outputs.logits, dim=-1)\n",
        "            all_preds.extend(preds.cpu().numpy().flatten())\n",
        "            all_labels.extend(labels.cpu().numpy().flatten())\n",
        "            # Assuming labels and preds are sequences for BLEU score\n",
        "            for ref, hyp in zip(labels, preds):\n",
        "                ref_tokens = ref.cpu().numpy().tolist()\n",
        "                hyp_tokens = hyp.cpu().numpy().tolist()\n",
        "                all_references.append([tokenizer.decode(x, skip_special_tokens=True).split()for  x in ref_tokens])\n",
        "                all_hypotheses.append(tokenizer.decode(hyp_tokens, skip_special_tokens=True).split())\n",
        "    \n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    \n",
        "    # Calculate precision, recall, accuracy\n",
        "    precision = precision_score(all_labels, all_preds, average='macro')\n",
        "    recall = recall_score(all_labels, all_preds, average='macro')\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    \n",
        "    # Calculate BLEU score with smoothing\n",
        "    bleu_score = corpus_bleu(all_references, all_hypotheses, smoothing_function=smoothing_function)\n",
        "    \n",
        "    return avg_loss,precision, recall, accuracy, bleu_score\n",
        "\n",
        "# Example usage\n",
        "# Assuming you have the following variables defined:\n",
        "# model, criterion, val_dataloader, device, tokenizer\n",
        "\n",
        "avg_loss, precision, recall, accuracy, bleu_score = validate(model, valDataloader, criterion, device, tokenizer)\n",
        "print(f\"Validation loss: {avg_loss:.4f}\")\n",
        "print(f\"Validation Precision: {precision:.4f}\")\n",
        "print(f\"Validation Recall: {recall:.4f}\")\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Validation BLEU score: {bleu_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "8b6tQX1seAHU",
        "outputId": "1cd593b4-0c2f-4bd3-f4d9-0eb9f8a6ad28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(trainData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZuS0RKu3-lm",
        "outputId": "15b52452-dafd-44a5-8ecb-7e2934a110db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): BlenderbotForCausalLM(\n",
              "      (model): BlenderbotDecoderWrapper(\n",
              "        (decoder): BlenderbotDecoder(\n",
              "          (embed_tokens): BlenderbotScaledWordEmbedding(8008, 1280, padding_idx=0)\n",
              "          (embed_positions): BlenderbotLearnedPositionalEmbedding(128, 1280)\n",
              "          (layers): ModuleList(\n",
              "            (0): BlenderbotDecoderLayer(\n",
              "              (self_attn): BlenderbotAttention(\n",
              "                (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "                (v_proj): lora.Linear(\n",
              "                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.05, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=64, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=64, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                )\n",
              "                (q_proj): lora.Linear(\n",
              "                  (base_layer): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "                  (lora_dropout): ModuleDict(\n",
              "                    (default): Dropout(p=0.05, inplace=False)\n",
              "                  )\n",
              "                  (lora_A): ModuleDict(\n",
              "                    (default): Linear(in_features=1280, out_features=64, bias=False)\n",
              "                  )\n",
              "                  (lora_B): ModuleDict(\n",
              "                    (default): Linear(in_features=64, out_features=1280, bias=False)\n",
              "                  )\n",
              "                  (lora_embedding_A): ParameterDict()\n",
              "                  (lora_embedding_B): ParameterDict()\n",
              "                )\n",
              "                (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "              )\n",
              "              (activation_fn): GELUActivation()\n",
              "              (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "              (encoder_attn): BlenderbotAttention(\n",
              "                (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "                (v_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "                (q_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "                (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "              )\n",
              "              (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "              (fc1): Linear8bitLt(in_features=1280, out_features=5120, bias=True)\n",
              "              (fc2): Linear8bitLt(in_features=5120, out_features=1280, bias=True)\n",
              "              (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "            (1-11): 11 x BlenderbotDecoderLayer(\n",
              "              (self_attn): BlenderbotAttention(\n",
              "                (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "                (v_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "                (q_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "                (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "              )\n",
              "              (activation_fn): GELUActivation()\n",
              "              (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "              (encoder_attn): BlenderbotAttention(\n",
              "                (k_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "                (v_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "                (q_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "                (out_proj): Linear8bitLt(in_features=1280, out_features=1280, bias=True)\n",
              "              )\n",
              "              (encoder_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "              (fc1): Linear8bitLt(in_features=1280, out_features=5120, bias=True)\n",
              "              (fc2): Linear8bitLt(in_features=5120, out_features=1280, bias=True)\n",
              "              (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "            )\n",
              "          )\n",
              "          (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (lm_head): Linear8bitLt(in_features=1280, out_features=8008, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-b5FOBzqFIA"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0p3BhCGeAHV",
        "outputId": "29822ee8-b775-49c3-e092-3857db76764b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   0%|          | 0/400 [00:00<?, ?it/s]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Train Loss': 4.183987753496644, 'Train Accuracy': 0.5313754857512953, 'Validation Loss': 4.222996884141087, 'Validation Accuracy': 0.00011642140324440986, 'Precision': 0.0002089427496865859, 'Recall': 0.5287469267598344, 'Bleu Score': 3.459808787090618e-08}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   0%|          | 1/400 [01:55<12:48:51, 115.62s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 2, 'Train Loss': 4.1294359894088615, 'Train Accuracy': 0.5313754857512953, 'Validation Loss': 4.156163770305223, 'Validation Accuracy': 0.00012447776696918, 'Precision': 0.00023501762632197415, 'Recall': 0.5287469267598344, 'Bleu Score': 7.017436003425787e-84}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   0%|          | 2/400 [04:01<13:27:15, 121.70s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 3, 'Train Loss': 4.077875599676733, 'Train Accuracy': 0.5313754857512953, 'Validation Loss': 4.099624786495177, 'Validation Accuracy': 0.00012552041156503068, 'Precision': 0.00023736055067647758, 'Recall': 0.5287469267598344, 'Bleu Score': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   1%|          | 3/400 [06:13<13:55:18, 126.24s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 4, 'Train Loss': 4.0352610369413595, 'Train Accuracy': 0.5313754857512953, 'Validation Loss': 4.054379669102755, 'Validation Accuracy': 0.0001255072143314267, 'Precision': 0.00023736055067647758, 'Recall': 0.5287469267598344, 'Bleu Score': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   1%|          | 4/400 [08:29<14:18:37, 130.10s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 5, 'Train Loss': 3.9797366333929873, 'Train Accuracy': 0.5313754857512953, 'Validation Loss': 4.001372737332809, 'Validation Accuracy': 0.0001255209192063648, 'Precision': 0.00023736055067647758, 'Recall': 0.5287469267598344, 'Bleu Score': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   1%|▏         | 5/400 [10:40<14:18:20, 130.38s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 6, 'Train Loss': 3.915212762783904, 'Train Accuracy': 0.5313754857512953, 'Validation Loss': 3.9328549469798064, 'Validation Accuracy': 0.00012562608943273432, 'Precision': 0.00023736055067647758, 'Recall': 0.5287469267598344, 'Bleu Score': 3.86634498523152e-141}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   2%|▏         | 6/400 [12:51<14:19:10, 130.84s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 7, 'Train Loss': 3.85548911470076, 'Train Accuracy': 0.5345504101899827, 'Validation Loss': 3.8719960401866063, 'Validation Accuracy': 0.00013247067106920559, 'Precision': 0.00023736055067647758, 'Recall': 0.5287469267598344, 'Bleu Score': 1.9769327618423397e-07}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   2%|▏         | 7/400 [15:03<14:18:17, 131.04s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 8, 'Train Loss': 3.8070531538507555, 'Train Accuracy': 0.5408193005181348, 'Validation Loss': 3.8141011866656216, 'Validation Accuracy': 0.00021039352913157047, 'Precision': 0.0003473197542397061, 'Recall': 0.537796810300207, 'Bleu Score': 1.9131368613474312e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   2%|▏         | 8/400 [17:14<14:16:44, 131.13s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 9, 'Train Loss': 3.7760016819390145, 'Train Accuracy': 0.540925895941278, 'Validation Loss': 3.7745878863925775, 'Validation Accuracy': 0.00024040752568811448, 'Precision': 0.00030000486906035437, 'Recall': 0.5339026915113871, 'Bleu Score': 3.519361497369987e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   2%|▏         | 9/400 [19:22<14:08:24, 130.19s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 10, 'Train Loss': 3.7561896143697244, 'Train Accuracy': 0.5418623164939551, 'Validation Loss': 3.752119437722135, 'Validation Accuracy': 0.00024179237445513645, 'Precision': 0.00030924183522205545, 'Recall': 0.534662914078675, 'Bleu Score': 3.531497763128491e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   2%|▎         | 10/400 [21:30<14:01:18, 129.43s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 11, 'Train Loss': 3.7421678494024015, 'Train Accuracy': 0.5424951424870467, 'Validation Loss': 3.73799829148064, 'Validation Accuracy': 0.00024177193661432524, 'Precision': 0.0003078762982432178, 'Recall': 0.5345456457039337, 'Bleu Score': 3.5254928658581815e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   3%|▎         | 11/400 [23:38<13:56:13, 128.98s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 12, 'Train Loss': 3.7309895752213937, 'Train Accuracy': 0.5430564550949913, 'Validation Loss': 3.7268536608081217, 'Validation Accuracy': 0.00024259498176391794, 'Precision': 0.0003197533811199932, 'Recall': 0.5354999676501035, 'Bleu Score': 3.5347822839851606e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   3%|▎         | 12/400 [25:45<13:50:44, 128.47s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 13, 'Train Loss': 3.721014516294332, 'Train Accuracy': 0.5446243523316062, 'Validation Loss': 3.716696308664054, 'Validation Accuracy': 0.00024741765625537, 'Precision': 0.00040333149856700614, 'Recall': 0.5423702769151139, 'Bleu Score': 3.564110374174517e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   3%|▎         | 13/400 [27:53<13:46:55, 128.20s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 14, 'Train Loss': 3.7111342358325725, 'Train Accuracy': 0.5448105569948186, 'Validation Loss': 3.702884296247782, 'Validation Accuracy': 0.00024619314720099984, 'Precision': 0.00034910251092658257, 'Recall': 0.5375258799171843, 'Bleu Score': 1.9792123180099113e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   4%|▎         | 14/400 [30:04<13:50:22, 129.07s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 15, 'Train Loss': 3.7005961260742906, 'Train Accuracy': 0.546159866148532, 'Validation Loss': 3.6918299276966695, 'Validation Accuracy': 0.0002492406135768689, 'Precision': 0.00037587407027371355, 'Recall': 0.5395073110766045, 'Bleu Score': 1.9949521600979644e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   4%|▍         | 15/400 [31:58<13:19:34, 124.61s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 16, 'Train Loss': 3.6880704403252893, 'Train Accuracy': 0.547270347582038, 'Validation Loss': 3.6796954116545435, 'Validation Accuracy': 0.0002527528978498383, 'Precision': 0.00039100747539469455, 'Recall': 0.5403403209109731, 'Bleu Score': 1.9911880924905616e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   4%|▍         | 16/400 [34:07<13:25:12, 125.81s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 17, 'Train Loss': 3.6734717099706113, 'Train Accuracy': 0.5484671848013817, 'Validation Loss': 3.6620490245582644, 'Validation Accuracy': 0.0002625173497673063, 'Precision': 0.0004129365973329978, 'Recall': 0.5416828416149069, 'Bleu Score': 1.9339331777244342e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   4%|▍         | 17/400 [36:18<13:33:24, 127.43s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 18, 'Train Loss': 3.6551161958367784, 'Train Accuracy': 0.5520860319516407, 'Validation Loss': 3.647848090357032, 'Validation Accuracy': 0.0002732129741799891, 'Precision': 0.00044197042421243344, 'Recall': 0.5432841614906833, 'Bleu Score': 1.8300601429264742e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   4%|▍         | 18/400 [38:28<13:36:22, 128.23s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 19, 'Train Loss': 3.633853563781601, 'Train Accuracy': 0.5603505505181348, 'Validation Loss': 3.628586665165326, 'Validation Accuracy': 0.0005101768461044177, 'Precision': 0.0007166779379726321, 'Recall': 0.5522895639233955, 'Bleu Score': 1.0355833680987956e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   5%|▍         | 19/400 [40:38<13:37:34, 128.75s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 20, 'Train Loss': 3.6097668033937063, 'Train Accuracy': 0.5687041234887737, 'Validation Loss': 3.6015653920567727, 'Validation Accuracy': 0.00045580946064641267, 'Precision': 0.0007736922900810717, 'Recall': 0.5570005175983437, 'Bleu Score': 1.6857727188457655e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   5%|▌         | 20/400 [42:50<13:41:54, 129.77s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 21, 'Train Loss': 3.582428878842138, 'Train Accuracy': 0.5730030224525043, 'Validation Loss': 3.570168243952034, 'Validation Accuracy': 0.00045073109914902835, 'Precision': 0.0009079005940776849, 'Recall': 0.5670775103519669, 'Bleu Score': 7.220399708179779e-06}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   5%|▌         | 21/400 [45:02<13:43:33, 130.38s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 22, 'Train Loss': 3.5536023511741703, 'Train Accuracy': 0.5746869602763385, 'Validation Loss': 3.5404427283066364, 'Validation Accuracy': 0.0004539150541072296, 'Precision': 0.0009439915092792042, 'Recall': 0.5697382893374742, 'Bleu Score': 1.2648253522122215e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   6%|▌         | 22/400 [47:12<13:40:39, 130.26s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 23, 'Train Loss': 3.525174446856778, 'Train Accuracy': 0.5769848337651122, 'Validation Loss': 3.5060227897541583, 'Validation Accuracy': 0.00047343975460626103, 'Precision': 0.0009908990945110949, 'Recall': 0.5732280344202898, 'Bleu Score': 3.894950671987509e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   6%|▌         | 23/400 [49:22<13:37:46, 130.15s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 24, 'Train Loss': 3.498226616264048, 'Train Accuracy': 0.5806387629533679, 'Validation Loss': 3.477519243709312, 'Validation Accuracy': 0.000526674292420684, 'Precision': 0.001110640751760162, 'Recall': 0.5786466420807453, 'Bleu Score': 7.972694734975912e-05}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   6%|▌         | 24/400 [51:29<13:29:48, 129.23s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 25, 'Train Loss': 3.4716379877941383, 'Train Accuracy': 0.5851144214162349, 'Validation Loss': 3.452145912430503, 'Validation Accuracy': 0.0005674754673202229, 'Precision': 0.0012726669884704953, 'Recall': 0.5844615359730849, 'Bleu Score': 0.00012746591843363982}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   6%|▋         | 25/400 [53:37<13:24:54, 128.78s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 26, 'Train Loss': 3.445864798778987, 'Train Accuracy': 0.5893053756476684, 'Validation Loss': 3.4225977289775185, 'Validation Accuracy': 0.0006435829680017844, 'Precision': 0.0014317035767537848, 'Recall': 0.5893140204451346, 'Bleu Score': 0.00014550759027543795}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   6%|▋         | 26/400 [55:44<13:20:51, 128.48s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 27, 'Train Loss': 3.4223694539531158, 'Train Accuracy': 0.5935314119170985, 'Validation Loss': 3.4015072441298115, 'Validation Accuracy': 0.0006819412519115681, 'Precision': 0.001566111977722388, 'Recall': 0.5928037655279503, 'Bleu Score': 0.00016288972269724658}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   7%|▋         | 27/400 [57:54<13:20:41, 128.80s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 28, 'Train Loss': 3.3987016261282545, 'Train Accuracy': 0.5979382556131261, 'Validation Loss': 3.369206668424212, 'Validation Accuracy': 0.0007413334163316657, 'Precision': 0.0016523762303284923, 'Recall': 0.5953027950310559, 'Bleu Score': 0.00017260258653418263}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   7%|▋         | 28/400 [1:00:04<13:20:03, 129.04s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 29, 'Train Loss': 3.374925068399524, 'Train Accuracy': 0.603242389896373, 'Validation Loss': 3.3467803942270518, 'Validation Accuracy': 0.0008402150273266355, 'Precision': 0.0018122488870914559, 'Recall': 0.5995001940993789, 'Bleu Score': 0.00043458891509931964}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   7%|▋         | 29/400 [1:02:11<13:14:56, 128.56s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 30, 'Train Loss': 3.352634492006091, 'Train Accuracy': 0.6089634607081175, 'Validation Loss': 3.3188563925175627, 'Validation Accuracy': 0.0009544585576604413, 'Precision': 0.0020142785345802073, 'Recall': 0.6049592391304348, 'Bleu Score': 0.0006031086347214952}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   8%|▊         | 30/400 [1:04:18<13:10:44, 128.23s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 31, 'Train Loss': 3.3310412310105004, 'Train Accuracy': 0.6144052245250432, 'Validation Loss': 3.296379968647129, 'Validation Accuracy': 0.001099959350791679, 'Precision': 0.002234597711264385, 'Recall': 0.6111865942028986, 'Bleu Score': 0.0007250770527396127}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   8%|▊         | 31/400 [1:06:26<13:07:45, 128.09s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 32, 'Train Loss': 3.3106942944105158, 'Train Accuracy': 0.6198294473229706, 'Validation Loss': 3.2730537987937613, 'Validation Accuracy': 0.0012111653929410952, 'Precision': 0.0024436511349771746, 'Recall': 0.6170621441511387, 'Bleu Score': 0.0021679462432791117}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   8%|▊         | 32/400 [1:08:34<13:04:06, 127.85s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 33, 'Train Loss': 3.2900556467514672, 'Train Accuracy': 0.6245250431778929, 'Validation Loss': 3.2560886095378025, 'Validation Accuracy': 0.0013850518398500287, 'Precision': 0.0026131049261585624, 'Recall': 0.621392986542443, 'Bleu Score': 0.0032146686943564577}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   8%|▊         | 33/400 [1:10:41<13:01:00, 127.68s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 34, 'Train Loss': 3.2704580865841546, 'Train Accuracy': 0.62895347582038, 'Validation Loss': 3.227220450551057, 'Validation Accuracy': 0.0016404457971413542, 'Precision': 0.00280433445538222, 'Recall': 0.625485248447205, 'Bleu Score': 0.0039095572316359}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   8%|▊         | 34/400 [1:12:51<13:02:56, 128.35s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 35, 'Train Loss': 3.2510422519228075, 'Train Accuracy': 0.6331903065630398, 'Validation Loss': 3.2124960762410124, 'Validation Accuracy': 0.0020120513327915065, 'Precision': 0.003117946797138875, 'Recall': 0.6307380628881988, 'Bleu Score': 0.005215783603292832}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   9%|▉         | 35/400 [1:15:00<13:01:43, 128.50s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 36, 'Train Loss': 3.2322450077665446, 'Train Accuracy': 0.6365689766839379, 'Validation Loss': 3.1872954004067036, 'Validation Accuracy': 0.0022755177918307606, 'Precision': 0.0033459006025703783, 'Recall': 0.6344016886645962, 'Bleu Score': 0.006037660757453131}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   9%|▉         | 36/400 [1:17:07<12:57:11, 128.11s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 37, 'Train Loss': 3.213474417918295, 'Train Accuracy': 0.6396400043177893, 'Validation Loss': 3.1680595485632086, 'Validation Accuracy': 0.002231360041724191, 'Precision': 0.003506956391439983, 'Recall': 0.6371878234989649, 'Bleu Score': 0.006741074789928651}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):   9%|▉         | 37/400 [1:19:15<12:54:30, 128.02s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 38, 'Train Loss': 3.195387881928386, 'Train Accuracy': 0.6417341321243524, 'Validation Loss': 3.1469380392515953, 'Validation Accuracy': 0.002198549553284954, 'Precision': 0.003597549246352084, 'Recall': 0.6390155926501035, 'Bleu Score': 0.007036155058988261}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  10%|▉         | 38/400 [1:21:22<12:50:25, 127.69s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 39, 'Train Loss': 3.178625751595471, 'Train Accuracy': 0.6435597474093264, 'Validation Loss': 3.131189454685558, 'Validation Accuracy': 0.0021679416690244657, 'Precision': 0.00369046532768264, 'Recall': 0.6412841291407867, 'Bleu Score': 0.007533867531986995}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  10%|▉         | 39/400 [1:23:28<12:46:32, 127.40s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 40, 'Train Loss': 3.161479811971359, 'Train Accuracy': 0.6452693221070812, 'Validation Loss': 3.111213723982661, 'Validation Accuracy': 0.002185404063946333, 'Precision': 0.003821217377612828, 'Recall': 0.6445555124223602, 'Bleu Score': 0.008301144574680166}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  10%|█         | 40/400 [1:25:35<12:43:10, 127.19s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 41, 'Train Loss': 3.1457536100353325, 'Train Accuracy': 0.6469964378238342, 'Validation Loss': 3.092512633189682, 'Validation Accuracy': 0.0026560458724290427, 'Precision': 0.00390489140991616, 'Recall': 0.6463751940993789, 'Bleu Score': 0.009073243163257978}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  10%|█         | 41/400 [1:27:43<12:41:53, 127.34s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 42, 'Train Loss': 3.1293721869176263, 'Train Accuracy': 0.6484240069084629, 'Validation Loss': 3.0784442961708574, 'Validation Accuracy': 0.002930271200275362, 'Precision': 0.003982120839346833, 'Recall': 0.647555965320911, 'Bleu Score': 0.009249912581280143}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  10%|█         | 42/400 [1:29:53<12:45:03, 128.22s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 43, 'Train Loss': 3.1143681739575295, 'Train Accuracy': 0.6499649179620035, 'Validation Loss': 3.060955239721566, 'Validation Accuracy': 0.002923307814390024, 'Precision': 0.0040617300188177125, 'Recall': 0.6486558618012422, 'Bleu Score': 0.009378093567548955}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  11%|█         | 43/400 [1:32:01<12:42:00, 128.07s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 44, 'Train Loss': 3.0986300771078352, 'Train Accuracy': 0.6512723985319516, 'Validation Loss': 3.0465574742348727, 'Validation Accuracy': 0.0030868775988164817, 'Precision': 0.0041682497337428475, 'Recall': 0.6500186011904762, 'Bleu Score': 0.010521367207198437}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  11%|█         | 44/400 [1:34:08<12:37:58, 127.75s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 45, 'Train Loss': 3.0855911894397843, 'Train Accuracy': 0.6528902202072538, 'Validation Loss': 3.0270974601595855, 'Validation Accuracy': 0.0034585316024056275, 'Precision': 0.0042806314615109675, 'Recall': 0.6514379528985508, 'Bleu Score': 0.011971647661266401}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  11%|█▏        | 45/400 [1:36:16<12:37:09, 127.97s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 46, 'Train Loss': 3.070356717590469, 'Train Accuracy': 0.6542813579447323, 'Validation Loss': 3.0142981951886956, 'Validation Accuracy': 0.0035749888604204665, 'Precision': 0.004402935769226587, 'Recall': 0.6528411296583851, 'Bleu Score': 0.012611048727974816}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  12%|█▏        | 46/400 [1:38:24<12:34:11, 127.83s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 47, 'Train Loss': 3.0563049802134707, 'Train Accuracy': 0.6560637953367876, 'Validation Loss': 2.999487453748372, 'Validation Accuracy': 0.0036954992104479773, 'Precision': 0.00458247851473993, 'Recall': 0.6548225608178054, 'Bleu Score': 0.014128753009583616}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  12%|█▏        | 47/400 [1:40:31<12:31:49, 127.79s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 48, 'Train Loss': 3.042607859682642, 'Train Accuracy': 0.6575264464594128, 'Validation Loss': 2.9816076588039557, 'Validation Accuracy': 0.0038876992991738425, 'Precision': 0.0047461148353415885, 'Recall': 0.6565573240165632, 'Bleu Score': 0.014542371280798366}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  12%|█▏        | 48/400 [1:42:40<12:30:28, 127.92s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 49, 'Train Loss': 3.029605776894817, 'Train Accuracy': 0.6589621113989638, 'Validation Loss': 2.9684541082579243, 'Validation Accuracy': 0.004260403153776846, 'Precision': 0.004931747949259039, 'Recall': 0.6585508863871635, 'Bleu Score': 0.01564281022183544}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  12%|█▏        | 49/400 [1:44:48<12:29:06, 128.05s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 50, 'Train Loss': 3.016656799046374, 'Train Accuracy': 0.6606608916234887, 'Validation Loss': 2.9512599017009262, 'Validation Accuracy': 0.004693212057858796, 'Precision': 0.005157672078964408, 'Recall': 0.6608194228778468, 'Bleu Score': 0.016874069231538485}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  12%|█▎        | 50/400 [1:46:56<12:26:43, 128.01s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 51, 'Train Loss': 3.004391296133811, 'Train Accuracy': 0.6622328367875647, 'Validation Loss': 2.9390397505326704, 'Validation Accuracy': 0.00501712805619515, 'Precision': 0.005360859336024642, 'Recall': 0.6625744047619048, 'Bleu Score': 0.01728843351993625}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  13%|█▎        | 51/400 [1:49:04<12:25:15, 128.13s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 52, 'Train Loss': 2.9913606981216874, 'Train Accuracy': 0.6641164723661486, 'Validation Loss': 2.926860110326247, 'Validation Accuracy': 0.006128673946126302, 'Precision': 0.0055799219957269105, 'Recall': 0.6643819552277432, 'Bleu Score': 0.017730339580969697}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  13%|█▎        | 52/400 [1:51:12<12:21:43, 127.88s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 53, 'Train Loss': 2.9791346340548266, 'Train Accuracy': 0.6654563363557858, 'Validation Loss': 2.910352778828834, 'Validation Accuracy': 0.006462223100670107, 'Precision': 0.005782945731590093, 'Recall': 0.6660722373188406, 'Bleu Score': 0.018361090676974747}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  13%|█▎        | 53/400 [1:53:19<12:19:42, 127.90s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 54, 'Train Loss': 2.9659724744314646, 'Train Accuracy': 0.6670296308290156, 'Validation Loss': 2.8963588436773002, 'Validation Accuracy': 0.00706640604411851, 'Precision': 0.005987595507209548, 'Recall': 0.6677948693064182, 'Bleu Score': 0.019065312369395272}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  14%|█▎        | 54/400 [1:55:28<12:18:37, 128.09s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 55, 'Train Loss': 2.953854607449052, 'Train Accuracy': 0.668528713298791, 'Validation Loss': 2.8873546290988763, 'Validation Accuracy': 0.007804495213141472, 'Precision': 0.006180899827440288, 'Recall': 0.6692627458592133, 'Bleu Score': 0.01935054344582016}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  14%|█▍        | 55/400 [1:57:36<12:16:48, 128.14s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 56, 'Train Loss': 2.9419535126804646, 'Train Accuracy': 0.6701438363557858, 'Validation Loss': 2.874475839216847, 'Validation Accuracy': 0.008003045859344655, 'Precision': 0.006387868711496795, 'Recall': 0.6708317158385093, 'Bleu Score': 0.019727126986920897}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  14%|█▍        | 56/400 [1:59:45<12:15:15, 128.24s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 57, 'Train Loss': 2.9304941606126436, 'Train Accuracy': 0.6714229814335061, 'Validation Loss': 2.857107735862417, 'Validation Accuracy': 0.008382023431762942, 'Precision': 0.006631876594050243, 'Recall': 0.6726190476190477, 'Bleu Score': 0.020356478323053227}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  14%|█▍        | 57/400 [2:01:53<12:12:49, 128.19s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 58, 'Train Loss': 2.9189394526389423, 'Train Accuracy': 0.6732472474093264, 'Validation Loss': 2.8456295777943508, 'Validation Accuracy': 0.009581341184553676, 'Precision': 0.006910682278659343, 'Recall': 0.6743618982919255, 'Bleu Score': 0.021522653289816798}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  14%|█▍        | 58/400 [2:04:01<12:11:01, 128.25s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 59, 'Train Loss': 2.906893194874347, 'Train Accuracy': 0.674924438687392, 'Validation Loss': 2.8327960199561, 'Validation Accuracy': 0.010034586083285271, 'Precision': 0.007214949048550116, 'Recall': 0.6761654050207039, 'Bleu Score': 0.022606572446045022}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  15%|█▍        | 59/400 [2:06:10<12:09:08, 128.30s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 60, 'Train Loss': 2.8960348553749737, 'Train Accuracy': 0.6762710492227979, 'Validation Loss': 2.8209196004000576, 'Validation Accuracy': 0.01101325504883396, 'Precision': 0.007542443799654129, 'Recall': 0.6780416990165632, 'Bleu Score': 0.02368841564354841}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  15%|█▌        | 60/400 [2:08:16<12:04:37, 127.87s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 61, 'Train Loss': 2.8845242666934734, 'Train Accuracy': 0.6779738773747841, 'Validation Loss': 2.811522323237963, 'Validation Accuracy': 0.011500000073498613, 'Precision': 0.00789017465727367, 'Recall': 0.6798977743271222, 'Bleu Score': 0.024756746458083623}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  15%|█▌        | 61/400 [2:10:25<12:02:49, 127.93s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 62, 'Train Loss': 2.8732308277767666, 'Train Accuracy': 0.6800140328151986, 'Validation Loss': 2.794631959978214, 'Validation Accuracy': 0.011881687493276682, 'Precision': 0.008242326132960809, 'Recall': 0.6818508993271222, 'Bleu Score': 0.0259791884140764}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  16%|█▌        | 62/400 [2:12:33<12:01:39, 128.11s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 63, 'Train Loss': 2.862967769085373, 'Train Accuracy': 0.6815144645941278, 'Validation Loss': 2.7848171498164658, 'Validation Accuracy': 0.01265956757219554, 'Precision': 0.008584135499730394, 'Recall': 0.6834724378881988, 'Bleu Score': 0.02694318228508995}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  16%|█▌        | 63/400 [2:14:42<12:00:07, 128.21s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 64, 'Train Loss': 2.8522201562454685, 'Train Accuracy': 0.683495250431779, 'Validation Loss': 2.7790344377194556, 'Validation Accuracy': 0.013877810355515873, 'Precision': 0.008986077104180198, 'Recall': 0.6855873123706004, 'Bleu Score': 0.02831420522597142}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  16%|█▌        | 64/400 [2:16:52<12:01:15, 128.80s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 65, 'Train Loss': 2.841509000043184, 'Train Accuracy': 0.6853721394645941, 'Validation Loss': 2.763517404883361, 'Validation Accuracy': 0.014878039251651883, 'Precision': 0.009414764770040843, 'Recall': 0.6879084174430642, 'Bleu Score': 0.029906345618378512}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  16%|█▋        | 65/400 [2:19:00<11:58:18, 128.65s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 66, 'Train Loss': 2.8307357316847006, 'Train Accuracy': 0.6874824589810017, 'Validation Loss': 2.7487421291918794, 'Validation Accuracy': 0.015437030523315895, 'Precision': 0.009832264745370035, 'Recall': 0.6900677730331263, 'Bleu Score': 0.03156044185154128}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  16%|█▋        | 66/400 [2:21:07<11:53:48, 128.23s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 67, 'Train Loss': 2.8216763693654077, 'Train Accuracy': 0.6894268134715026, 'Validation Loss': 2.738819756291129, 'Validation Accuracy': 0.016029265434122, 'Precision': 0.01028090618071552, 'Recall': 0.692178603778468, 'Bleu Score': 0.03308892723655356}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  17%|█▋        | 67/400 [2:23:18<11:55:11, 128.86s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 68, 'Train Loss': 2.811554440147969, 'Train Accuracy': 0.691137737478411, 'Validation Loss': 2.728419542312622, 'Validation Accuracy': 0.01657595188875724, 'Precision': 0.01078049643549495, 'Recall': 0.6944026591614907, 'Bleu Score': 0.03500254821170664}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  17%|█▋        | 68/400 [2:25:25<11:50:48, 128.46s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 69, 'Train Loss': 2.8011777231377133, 'Train Accuracy': 0.6926934909326425, 'Validation Loss': 2.719241324042486, 'Validation Accuracy': 0.01735819859286971, 'Precision': 0.011294917206351524, 'Recall': 0.6968531638198758, 'Bleu Score': 0.0371540339880419}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  17%|█▋        | 69/400 [2:27:33<11:47:07, 128.18s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 70, 'Train Loss': 2.791728624652104, 'Train Accuracy': 0.6946796740069084, 'Validation Loss': 2.709352082457424, 'Validation Accuracy': 0.01764950723739536, 'Precision': 0.011743293276158898, 'Recall': 0.6988790760869565, 'Bleu Score': 0.03932732957970096}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  18%|█▊        | 70/400 [2:29:43<11:47:51, 128.70s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 71, 'Train Loss': 2.7828494596876494, 'Train Accuracy': 0.6964567141623489, 'Validation Loss': 2.695897734854832, 'Validation Accuracy': 0.019192300107939306, 'Precision': 0.012186298083590502, 'Recall': 0.7010182129917184, 'Bleu Score': 0.04092230372976208}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  18%|█▊        | 71/400 [2:31:52<11:46:23, 128.83s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 72, 'Train Loss': 2.77272924352746, 'Train Accuracy': 0.6982135146804835, 'Validation Loss': 2.685389919221894, 'Validation Accuracy': 0.020111840113261222, 'Precision': 0.012638625554020757, 'Recall': 0.703023906573499, 'Bleu Score': 0.042587776005458114}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  18%|█▊        | 72/400 [2:33:59<11:42:08, 128.44s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 73, 'Train Loss': 2.7639454753030073, 'Train Accuracy': 0.6999973013816926, 'Validation Loss': 2.6763764053336847, 'Validation Accuracy': 0.020943986613328944, 'Precision': 0.012985328654952078, 'Recall': 0.7045483954451346, 'Bleu Score': 0.04391886062588969}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  18%|█▊        | 73/400 [2:36:07<11:39:33, 128.36s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 74, 'Train Loss': 2.7549131774441316, 'Train Accuracy': 0.7016421092400691, 'Validation Loss': 2.6661927276406407, 'Validation Accuracy': 0.02193387522473296, 'Precision': 0.013423689528335433, 'Recall': 0.7064893892339544, 'Bleu Score': 0.04542507211029643}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  18%|█▊        | 74/400 [2:38:15<11:35:40, 128.04s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 75, 'Train Loss': 2.7461892623269097, 'Train Accuracy': 0.7034569300518134, 'Validation Loss': 2.657538918424244, 'Validation Accuracy': 0.023610225614084303, 'Precision': 0.013889345626569469, 'Recall': 0.7082807647515528, 'Bleu Score': 0.04697718133952924}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  19%|█▉        | 75/400 [2:40:22<11:32:19, 127.81s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 76, 'Train Loss': 2.737579328908446, 'Train Accuracy': 0.7047981433506045, 'Validation Loss': 2.6459834748063207, 'Validation Accuracy': 0.02580083540971664, 'Precision': 0.014393283552764792, 'Recall': 0.7101853649068323, 'Bleu Score': 0.0484219462680657}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  19%|█▉        | 76/400 [2:42:30<11:31:12, 128.00s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 77, 'Train Loss': 2.728609571634735, 'Train Accuracy': 0.7066156627806564, 'Validation Loss': 2.6385785060480607, 'Validation Accuracy': 0.026935683585161796, 'Precision': 0.014819055872987374, 'Recall': 0.711717941252588, 'Bleu Score': 0.04986011570125226}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  19%|█▉        | 77/400 [2:44:38<11:28:27, 127.89s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 78, 'Train Loss': 2.7203767273307506, 'Train Accuracy': 0.7080648208117444, 'Validation Loss': 2.6280380576110085, 'Validation Accuracy': 0.029883620141729513, 'Precision': 0.015310719917687485, 'Recall': 0.7134041796066253, 'Bleu Score': 0.05133032231080425}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  20%|█▉        | 78/400 [2:46:48<11:30:18, 128.63s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 79, 'Train Loss': 2.7122473194783563, 'Train Accuracy': 0.7092616580310881, 'Validation Loss': 2.6211242656077234, 'Validation Accuracy': 0.030694121636422645, 'Precision': 0.01590470151063763, 'Recall': 0.7152481237060041, 'Bleu Score': 0.05263468002108755}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  20%|█▉        | 79/400 [2:48:57<11:27:48, 128.56s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 80, 'Train Loss': 2.7032392385585533, 'Train Accuracy': 0.7111183074265975, 'Validation Loss': 2.610310186531918, 'Validation Accuracy': 0.03155464480494659, 'Precision': 0.01642170682984557, 'Recall': 0.716893924689441, 'Bleu Score': 0.054293248908222146}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  20%|██        | 80/400 [2:51:05<11:25:00, 128.44s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 81, 'Train Loss': 2.696179134411048, 'Train Accuracy': 0.7123893566493955, 'Validation Loss': 2.5990667830814016, 'Validation Accuracy': 0.032493905017803096, 'Precision': 0.016925458566139247, 'Recall': 0.7183577575051759, 'Bleu Score': 0.0552087784358762}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  20%|██        | 81/400 [2:53:13<11:21:55, 128.26s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 82, 'Train Loss': 2.6871320784750563, 'Train Accuracy': 0.7140962327288428, 'Validation Loss': 2.5911517108767486, 'Validation Accuracy': 0.03353804760092524, 'Precision': 0.017503731917492833, 'Recall': 0.7200925207039337, 'Bleu Score': 0.05667020503135994}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  20%|██        | 82/400 [2:55:21<11:19:52, 128.28s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 83, 'Train Loss': 2.6798951904088755, 'Train Accuracy': 0.7155696783246978, 'Validation Loss': 2.586591017640327, 'Validation Accuracy': 0.034223041432459717, 'Precision': 0.018028163256692906, 'Recall': 0.7214512163561076, 'Bleu Score': 0.057984633607110495}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  21%|██        | 83/400 [2:57:30<11:18:26, 128.41s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 84, 'Train Loss': 2.672115580317724, 'Train Accuracy': 0.7169351791882557, 'Validation Loss': 2.57550086068713, 'Validation Accuracy': 0.03611321193022339, 'Precision': 0.01865179585035646, 'Recall': 0.7231576733954451, 'Bleu Score': 0.05982673063825374}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  21%|██        | 84/400 [2:59:40<11:19:13, 128.97s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 85, 'Train Loss': 2.664938383010211, 'Train Accuracy': 0.7181724956822108, 'Validation Loss': 2.5681512409990486, 'Validation Accuracy': 0.03669284937466831, 'Precision': 0.019224947686922966, 'Recall': 0.7248641304347826, 'Bleu Score': 0.06093691772779091}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  21%|██▏       | 85/400 [3:01:50<11:18:54, 129.32s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 86, 'Train Loss': 2.6576644139395236, 'Train Accuracy': 0.7199036593264249, 'Validation Loss': 2.5603473846577414, 'Validation Accuracy': 0.038569102179342084, 'Precision': 0.019865794955655405, 'Recall': 0.7264856689958592, 'Bleu Score': 0.06242667197963442}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  22%|██▏       | 86/400 [3:03:58<11:14:34, 128.90s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 87, 'Train Loss': 2.6504146087894123, 'Train Accuracy': 0.7211247841105354, 'Validation Loss': 2.555686864478529, 'Validation Accuracy': 0.03846708952035029, 'Precision': 0.020407965781223246, 'Recall': 0.7279697204968945, 'Bleu Score': 0.06385771145375121}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  22%|██▏       | 87/400 [3:06:08<11:13:41, 129.14s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 88, 'Train Loss': 2.643900791419804, 'Train Accuracy': 0.7230354058721934, 'Validation Loss': 2.5429820837068164, 'Validation Accuracy': 0.039946255145598845, 'Precision': 0.021140287272168858, 'Recall': 0.7298904956004141, 'Bleu Score': 0.06572242974523076}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  22%|██▏       | 88/400 [3:08:16<11:10:07, 128.87s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 89, 'Train Loss': 2.637410013715207, 'Train Accuracy': 0.72421875, 'Validation Loss': 2.534945001779509, 'Validation Accuracy': 0.040279784416614645, 'Precision': 0.02160369070571833, 'Recall': 0.731063179347826, 'Bleu Score': 0.06766018838426469}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  22%|██▏       | 89/400 [3:10:25<11:07:57, 128.87s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 90, 'Train Loss': 2.630066392830064, 'Train Accuracy': 0.7253818544905009, 'Validation Loss': 2.531279002831987, 'Validation Accuracy': 0.04050556769095182, 'Precision': 0.02217518198138638, 'Recall': 0.7325270121635611, 'Bleu Score': 0.06896670137458465}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  22%|██▎       | 90/400 [3:12:35<11:06:52, 129.07s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 91, 'Train Loss': 2.6228294237542547, 'Train Accuracy': 0.7269780872193436, 'Validation Loss': 2.520277557786831, 'Validation Accuracy': 0.04253177062022039, 'Precision': 0.02313686363389625, 'Recall': 0.734674236542443, 'Bleu Score': 0.07093869241032497}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  23%|██▎       | 91/400 [3:14:43<11:03:50, 128.90s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 92, 'Train Loss': 2.617320659246234, 'Train Accuracy': 0.7279104598445596, 'Validation Loss': 2.516969746301982, 'Validation Accuracy': 0.04332362595760483, 'Precision': 0.023601329378867886, 'Recall': 0.7357983954451346, 'Bleu Score': 0.07159307788634846}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  23%|██▎       | 92/400 [3:16:52<11:02:33, 129.07s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 93, 'Train Loss': 2.6102926861186053, 'Train Accuracy': 0.7297994926597582, 'Validation Loss': 2.50568606686001, 'Validation Accuracy': 0.04431030845608489, 'Precision': 0.024216927823058093, 'Recall': 0.73730266563147, 'Bleu Score': 0.072871288799816}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  23%|██▎       | 93/400 [3:19:02<11:01:51, 129.35s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 94, 'Train Loss': 2.604382578015986, 'Train Accuracy': 0.7310354598445595, 'Validation Loss': 2.5045129750385757, 'Validation Accuracy': 0.04587284494251326, 'Precision': 0.024724312614947837, 'Recall': 0.7386128364389234, 'Bleu Score': 0.07435516133597386}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  24%|██▎       | 94/400 [3:21:10<10:57:10, 128.86s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 95, 'Train Loss': 2.5977951976475793, 'Train Accuracy': 0.732261981865285, 'Validation Loss': 2.4941703470285272, 'Validation Accuracy': 0.046343888750376344, 'Precision': 0.02531997796854049, 'Recall': 0.7401251940993789, 'Bleu Score': 0.07608440418913606}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  24%|██▍       | 95/400 [3:23:20<10:55:54, 129.03s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 96, 'Train Loss': 2.5917876613074244, 'Train Accuracy': 0.733622085492228, 'Validation Loss': 2.485251844421891, 'Validation Accuracy': 0.047287337925868256, 'Precision': 0.025842226966583483, 'Recall': 0.7414434523809523, 'Bleu Score': 0.07745454351639361}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  24%|██▍       | 96/400 [3:25:28<10:52:31, 128.79s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 97, 'Train Loss': 2.5854637112406738, 'Train Accuracy': 0.7346624028497409, 'Validation Loss': 2.480817425349527, 'Validation Accuracy': 0.04824547783289466, 'Precision': 0.026276177116885086, 'Recall': 0.7425271739130435, 'Bleu Score': 0.07862571714286827}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  24%|██▍       | 97/400 [3:27:38<10:52:34, 129.22s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 98, 'Train Loss': 2.579917696299474, 'Train Accuracy': 0.7360872733160622, 'Validation Loss': 2.4731001592864676, 'Validation Accuracy': 0.04969892933276131, 'Precision': 0.026857740261365715, 'Recall': 0.7439303506728778, 'Bleu Score': 0.0798578975256333}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  24%|██▍       | 98/400 [3:29:48<10:50:54, 129.32s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 99, 'Train Loss': 2.573999226751907, 'Train Accuracy': 0.7375607189119171, 'Validation Loss': 2.465354033245528, 'Validation Accuracy': 0.051313750298063406, 'Precision': 0.02741997841951232, 'Recall': 0.745313308747412, 'Bleu Score': 0.08114055808069301}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  25%|██▍       | 99/400 [3:31:58<10:50:32, 129.68s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 100, 'Train Loss': 2.568503081469246, 'Train Accuracy': 0.7387953367875648, 'Validation Loss': 2.4628417349058735, 'Validation Accuracy': 0.05211548916679181, 'Precision': 0.028069805977872255, 'Recall': 0.7467973602484472, 'Bleu Score': 0.08304726270696706}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  25%|██▌       | 100/400 [3:34:04<10:43:22, 128.68s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 101, 'Train Loss': 2.5630135145964545, 'Train Accuracy': 0.7399705850604491, 'Validation Loss': 2.4542574872655316, 'Validation Accuracy': 0.053337407440677734, 'Precision': 0.028537385967422505, 'Recall': 0.7479053442028986, 'Bleu Score': 0.08430090361839525}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  25%|██▌       | 101/400 [3:36:14<10:42:15, 128.88s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 102, 'Train Loss': 2.5579929501641523, 'Train Accuracy': 0.7411269430051813, 'Validation Loss': 2.4478435270057237, 'Validation Accuracy': 0.0549955310770168, 'Precision': 0.029133672173850343, 'Recall': 0.7492478649068323, 'Bleu Score': 0.08599026165114795}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  26%|██▌       | 102/400 [3:38:22<10:39:09, 128.69s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 103, 'Train Loss': 2.5523611740183436, 'Train Accuracy': 0.7425720531088082, 'Validation Loss': 2.4428558354535377, 'Validation Accuracy': 0.05637460072802408, 'Precision': 0.029665157303985574, 'Recall': 0.7503558488612836, 'Bleu Score': 0.08775250014152203}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  26%|██▌       | 103/400 [3:40:30<10:36:23, 128.56s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 104, 'Train Loss': 2.5464518429166048, 'Train Accuracy': 0.7432102763385147, 'Validation Loss': 2.4352470188101463, 'Validation Accuracy': 0.05749675876309259, 'Precision': 0.030214034467164155, 'Recall': 0.7515811011904762, 'Bleu Score': 0.0895541475316976}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  26%|██▌       | 104/400 [3:42:40<10:35:26, 128.81s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 105, 'Train Loss': 2.5416140449310536, 'Train Accuracy': 0.7446432426597582, 'Validation Loss': 2.4326502311328224, 'Validation Accuracy': 0.05818121792985806, 'Precision': 0.030739243716062303, 'Recall': 0.752737609989648, 'Bleu Score': 0.09088196757752441}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  26%|██▋       | 105/400 [3:44:48<10:32:30, 128.65s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 106, 'Train Loss': 2.5366934646559023, 'Train Accuracy': 0.7456552245250432, 'Validation Loss': 2.426288232823049, 'Validation Accuracy': 0.059298669432378236, 'Precision': 0.031487550256988815, 'Recall': 0.7542620988612836, 'Bleu Score': 0.09291686323944684}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  26%|██▋       | 106/400 [3:46:57<10:31:17, 128.83s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 107, 'Train Loss': 2.531762641767112, 'Train Accuracy': 0.7469910405872193, 'Validation Loss': 2.4194692984100215, 'Validation Accuracy': 0.060045891714007565, 'Precision': 0.03206721102834222, 'Recall': 0.7554833074534162, 'Bleu Score': 0.09463784729284379}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  27%|██▋       | 107/400 [3:49:07<10:30:19, 129.08s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 108, 'Train Loss': 2.526846149679047, 'Train Accuracy': 0.7477385578583765, 'Validation Loss': 2.415679886321391, 'Validation Accuracy': 0.06100517512910977, 'Precision': 0.03255742162683245, 'Recall': 0.756441673136646, 'Bleu Score': 0.09560702973965461}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  27%|██▋       | 108/400 [3:51:15<10:26:57, 128.83s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 109, 'Train Loss': 2.5215184156736616, 'Train Accuracy': 0.749105408031088, 'Validation Loss': 2.4121500312789412, 'Validation Accuracy': 0.06215068853501876, 'Precision': 0.03337414518452373, 'Recall': 0.7580753429089027, 'Bleu Score': 0.09772206945678558}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  27%|██▋       | 109/400 [3:53:25<10:26:51, 129.25s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 110, 'Train Loss': 2.5174816580108517, 'Train Accuracy': 0.7496572754749569, 'Validation Loss': 2.4046882445161994, 'Validation Accuracy': 0.06321603261664153, 'Precision': 0.0338971628693109, 'Recall': 0.7590862771739131, 'Bleu Score': 0.09911563873505069}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  28%|██▊       | 110/400 [3:55:35<10:24:53, 129.29s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 111, 'Train Loss': 2.512444290008334, 'Train Accuracy': 0.7509472150259068, 'Validation Loss': 2.402477050123136, 'Validation Accuracy': 0.06350105480592169, 'Precision': 0.03453541714393174, 'Recall': 0.7603964479813664, 'Bleu Score': 0.10068353123042602}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  28%|██▊       | 111/400 [3:57:44<10:22:18, 129.20s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 112, 'Train Loss': 2.508295836204982, 'Train Accuracy': 0.7516272668393782, 'Validation Loss': 2.3956381112090814, 'Validation Accuracy': 0.06502811987164443, 'Precision': 0.03512974971343212, 'Recall': 0.7613709886128365, 'Bleu Score': 0.10218946478086038}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  28%|██▊       | 112/400 [3:59:53<10:20:09, 129.20s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 113, 'Train Loss': 2.5028344511327165, 'Train Accuracy': 0.7529077612262521, 'Validation Loss': 2.388103845690893, 'Validation Accuracy': 0.06649635913848198, 'Precision': 0.035792566944543476, 'Recall': 0.7625962409420289, 'Bleu Score': 0.10418207911156246}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  28%|██▊       | 113/400 [4:02:03<10:19:18, 129.47s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 114, 'Train Loss': 2.4985118521511227, 'Train Accuracy': 0.7541180915371329, 'Validation Loss': 2.382555560139585, 'Validation Accuracy': 0.06687289995607702, 'Precision': 0.03642112484589261, 'Recall': 0.7636112189440993, 'Bleu Score': 0.10568379323457879}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  28%|██▊       | 114/400 [4:04:11<10:15:11, 129.06s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 115, 'Train Loss': 2.4942541282150628, 'Train Accuracy': 0.7549856973229706, 'Validation Loss': 2.3781326102816367, 'Validation Accuracy': 0.06808066193880212, 'Precision': 0.03718474895068313, 'Recall': 0.7649335209627329, 'Bleu Score': 0.10758423920041757}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  29%|██▉       | 115/400 [4:06:21<10:14:20, 129.34s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 116, 'Train Loss': 2.4895074994853847, 'Train Accuracy': 0.7556360643350605, 'Validation Loss': 2.3725978338028773, 'Validation Accuracy': 0.06954909311810271, 'Precision': 0.0376276461582196, 'Recall': 0.7656533061594203, 'Bleu Score': 0.10897503793803272}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  29%|██▉       | 116/400 [4:08:30<10:11:35, 129.21s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 117, 'Train Loss': 2.4859989581845743, 'Train Accuracy': 0.7567290047495682, 'Validation Loss': 2.3678749405648096, 'Validation Accuracy': 0.07012043299806724, 'Precision': 0.038253530433222604, 'Recall': 0.7669189958592133, 'Bleu Score': 0.1107069803361516}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  29%|██▉       | 117/400 [4:10:39<10:09:44, 129.27s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 118, 'Train Loss': 2.4811145766993254, 'Train Accuracy': 0.7577720207253886, 'Validation Loss': 2.364938968961889, 'Validation Accuracy': 0.07064456795938076, 'Precision': 0.038926178235880605, 'Recall': 0.7680391110248447, 'Bleu Score': 0.11272506585427997}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  30%|██▉       | 118/400 [4:12:50<10:08:50, 129.54s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 119, 'Train Loss': 2.47705898281619, 'Train Accuracy': 0.7585762089810018, 'Validation Loss': 2.362190242148628, 'Validation Accuracy': 0.07153511138941601, 'Precision': 0.039870686935158085, 'Recall': 0.7699073175465838, 'Bleu Score': 0.11503061253317672}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  30%|██▉       | 119/400 [4:14:58<10:05:20, 129.25s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 120, 'Train Loss': 2.4729888615357942, 'Train Accuracy': 0.7596691493955094, 'Validation Loss': 2.357705726603831, 'Validation Accuracy': 0.07301679713227363, 'Precision': 0.040376276736353675, 'Recall': 0.770800983436853, 'Bleu Score': 0.11629254925695841}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  30%|███       | 120/400 [4:17:09<10:05:40, 129.79s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 121, 'Train Loss': 2.4688040423129802, 'Train Accuracy': 0.7604207145941279, 'Validation Loss': 2.3509251391592105, 'Validation Accuracy': 0.07275706327803799, 'Precision': 0.04100620426603948, 'Recall': 0.7717674365942029, 'Bleu Score': 0.11802148463526846}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  30%|███       | 121/400 [4:19:19<10:03:06, 129.70s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 122, 'Train Loss': 2.4645280248552397, 'Train Accuracy': 0.7614434909326425, 'Validation Loss': 2.349595569382029, 'Validation Accuracy': 0.07512103753650261, 'Precision': 0.04166391486151633, 'Recall': 0.7727905020703933, 'Bleu Score': 0.11972702436570747}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  30%|███       | 122/400 [4:21:27<9:59:23, 129.36s/it] c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 123, 'Train Loss': 2.4606221046566303, 'Train Accuracy': 0.76222743955095, 'Validation Loss': 2.3422245053220387, 'Validation Accuracy': 0.07631829325594054, 'Precision': 0.04205388395323235, 'Recall': 0.773534549689441, 'Bleu Score': 0.12121965728723458}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  31%|███       | 123/400 [4:23:36<9:56:50, 129.28s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 124, 'Train Loss': 2.4569218209764574, 'Train Accuracy': 0.7630356757340242, 'Validation Loss': 2.3384653477629356, 'Validation Accuracy': 0.07645441566616552, 'Precision': 0.042479568719701065, 'Recall': 0.7742422036749482, 'Bleu Score': 0.12212145583036375}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  31%|███       | 124/400 [4:25:45<9:53:53, 129.11s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 125, 'Train Loss': 2.452543916458583, 'Train Accuracy': 0.7639181239205527, 'Validation Loss': 2.3333593690690915, 'Validation Accuracy': 0.07839022668783022, 'Precision': 0.0435584537516467, 'Recall': 0.7758556547619048, 'Bleu Score': 0.12465370251724155}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  31%|███▏      | 125/400 [4:27:54<9:51:33, 129.07s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 126, 'Train Loss': 2.4484273022380325, 'Train Accuracy': 0.7647142163212435, 'Validation Loss': 2.3279711801158496, 'Validation Accuracy': 0.07950670870663744, 'Precision': 0.04390577387435412, 'Recall': 0.776470302795031, 'Bleu Score': 0.12533200260869912}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  32%|███▏      | 126/400 [4:30:03<9:49:40, 129.12s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 127, 'Train Loss': 2.4449198275639867, 'Train Accuracy': 0.7655737262521589, 'Validation Loss': 2.3237476979405427, 'Validation Accuracy': 0.08066093481297616, 'Precision': 0.04445441818128753, 'Recall': 0.7774852807971014, 'Bleu Score': 0.12659104595867166}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  32%|███▏      | 127/400 [4:32:13<9:48:49, 129.41s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 128, 'Train Loss': 2.4412229214254664, 'Train Accuracy': 0.76640625, 'Validation Loss': 2.3199422536802685, 'Validation Accuracy': 0.08098535572445573, 'Precision': 0.04503643021565003, 'Recall': 0.7784962150621118, 'Bleu Score': 0.12852489205466114}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  32%|███▏      | 128/400 [4:34:22<9:45:56, 129.25s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 129, 'Train Loss': 2.4372988237860453, 'Train Accuracy': 0.7671672603626943, 'Validation Loss': 2.315380497412248, 'Validation Accuracy': 0.08150589616683881, 'Precision': 0.04548892028278364, 'Recall': 0.7792402626811594, 'Bleu Score': 0.129330581270789}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  32%|███▏      | 129/400 [4:36:31<9:43:36, 129.21s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 130, 'Train Loss': 2.433977549576628, 'Train Accuracy': 0.7677825453367876, 'Validation Loss': 2.3118345779328306, 'Validation Accuracy': 0.08294182303091167, 'Precision': 0.0460754449279709, 'Recall': 0.7800894474637681, 'Bleu Score': 0.13085264204604835}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  32%|███▎      | 130/400 [4:38:40<9:40:12, 128.93s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 131, 'Train Loss': 2.429708576004808, 'Train Accuracy': 0.7686811852331606, 'Validation Loss': 2.309842707697025, 'Validation Accuracy': 0.08296845914137058, 'Precision': 0.046412953772075605, 'Recall': 0.7808496700310559, 'Bleu Score': 0.13245313464187208}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  33%|███▎      | 131/400 [4:40:49<9:38:09, 128.96s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 132, 'Train Loss': 2.4265876058386175, 'Train Accuracy': 0.7694152094127806, 'Validation Loss': 2.3034268445219874, 'Validation Accuracy': 0.08423236459849813, 'Precision': 0.04726979611190649, 'Recall': 0.7820466162008282, 'Bleu Score': 0.13442392848700474}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  33%|███▎      | 132/400 [4:42:57<9:35:23, 128.82s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 133, 'Train Loss': 2.422409130064822, 'Train Accuracy': 0.7705094991364422, 'Validation Loss': 2.3010360238965877, 'Validation Accuracy': 0.08513709204587872, 'Precision': 0.047727850463152935, 'Recall': 0.7827380952380952, 'Bleu Score': 0.13536478537665203}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  33%|███▎      | 133/400 [4:45:06<9:33:05, 128.78s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 134, 'Train Loss': 2.4189175489199095, 'Train Accuracy': 0.7712259822970639, 'Validation Loss': 2.2960901575640214, 'Validation Accuracy': 0.08615405043088974, 'Precision': 0.04830142947929986, 'Recall': 0.7835751488095238, 'Bleu Score': 0.13633358833428533}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  34%|███▎      | 134/400 [4:47:16<9:33:16, 129.31s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 135, 'Train Loss': 2.4151227001656483, 'Train Accuracy': 0.7717791990500864, 'Validation Loss': 2.2948281745280115, 'Validation Accuracy': 0.08650501181762907, 'Precision': 0.04874773010471299, 'Recall': 0.7842261904761905, 'Bleu Score': 0.13744420351317}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  34%|███▍      | 135/400 [4:49:26<9:31:50, 129.47s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 136, 'Train Loss': 2.4115876785958013, 'Train Accuracy': 0.7726049762521588, 'Validation Loss': 2.2875870993314695, 'Validation Accuracy': 0.08708724671940572, 'Precision': 0.049303840740613995, 'Recall': 0.7851279438405797, 'Bleu Score': 0.13903642906982322}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  34%|███▍      | 136/400 [4:51:36<9:29:20, 129.40s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 137, 'Train Loss': 2.407911456586248, 'Train Accuracy': 0.7733916234887738, 'Validation Loss': 2.282825208892507, 'Validation Accuracy': 0.0880274839427477, 'Precision': 0.049827202101234015, 'Recall': 0.7858679477225673, 'Bleu Score': 0.14059309440416742}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  34%|███▍      | 137/400 [4:53:44<9:25:23, 128.99s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 138, 'Train Loss': 2.4043269353347587, 'Train Accuracy': 0.7739421416234887, 'Validation Loss': 2.278348223729567, 'Validation Accuracy': 0.08804388469316261, 'Precision': 0.05037919809523435, 'Recall': 0.7866564764492754, 'Bleu Score': 0.14218171976821933}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  34%|███▍      | 138/400 [4:55:52<9:22:40, 128.86s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 139, 'Train Loss': 2.4009693462545703, 'Train Accuracy': 0.7744063039723661, 'Validation Loss': 2.275735169402824, 'Validation Accuracy': 0.08859630843674911, 'Precision': 0.050922063741440086, 'Recall': 0.7875137487060041, 'Bleu Score': 0.14381363594520014}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  35%|███▍      | 139/400 [4:58:00<9:19:52, 128.71s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 140, 'Train Loss': 2.3975614823030504, 'Train Accuracy': 0.7755518674438687, 'Validation Loss': 2.272478131223316, 'Validation Accuracy': 0.08881939668655152, 'Precision': 0.05121884701355172, 'Recall': 0.7880556094720497, 'Bleu Score': 0.1442744773582036}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  35%|███▌      | 140/400 [5:00:10<9:19:10, 129.04s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 141, 'Train Loss': 2.394308874949566, 'Train Accuracy': 0.7760659542314335, 'Validation Loss': 2.2688877922444304, 'Validation Accuracy': 0.08988954746475408, 'Precision': 0.05190007874649122, 'Recall': 0.7889937564699793, 'Bleu Score': 0.14627369811262658}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  35%|███▌      | 141/400 [5:02:21<9:18:57, 129.49s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 142, 'Train Loss': 2.3906591337030103, 'Train Accuracy': 0.7767999784110535, 'Validation Loss': 2.2631290067325938, 'Validation Accuracy': 0.09037915938702717, 'Precision': 0.05228905612717047, 'Recall': 0.7897256728778468, 'Bleu Score': 0.1474437918482994}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  36%|███▌      | 142/400 [5:04:30<9:17:01, 129.54s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 143, 'Train Loss': 2.387571222215726, 'Train Accuracy': 0.7774139140759931, 'Validation Loss': 2.260563590802437, 'Validation Accuracy': 0.0911957596458312, 'Precision': 0.0526822948995466, 'Recall': 0.7901987901138716, 'Bleu Score': 0.1481798540318882}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  36%|███▌      | 143/400 [5:06:41<9:15:30, 129.69s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 144, 'Train Loss': 2.3834698998796346, 'Train Accuracy': 0.7782194516407599, 'Validation Loss': 2.2581772789482244, 'Validation Accuracy': 0.09218449303523295, 'Precision': 0.053262471604384, 'Recall': 0.7911611995341615, 'Bleu Score': 0.15023993339654196}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  36%|███▌      | 144/400 [5:08:50<9:13:20, 129.69s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 145, 'Train Loss': 2.3805055809284443, 'Train Accuracy': 0.7787861614853195, 'Validation Loss': 2.2528015793847644, 'Validation Accuracy': 0.09297337411725905, 'Precision': 0.05375168242090012, 'Recall': 0.7919416407867494, 'Bleu Score': 0.151730850848191}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  36%|███▋      | 145/400 [5:10:59<9:10:39, 129.57s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 146, 'Train Loss': 2.376855527169138, 'Train Accuracy': 0.7794135902417962, 'Validation Loss': 2.2534388983545224, 'Validation Accuracy': 0.09467891621487406, 'Precision': 0.054492216874910314, 'Recall': 0.7929849249482401, 'Bleu Score': 0.15408220951701587}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  36%|███▋      | 146/400 [5:13:17<9:18:46, 131.99s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 147, 'Train Loss': 2.3735796199977726, 'Train Accuracy': 0.7800518134715025, 'Validation Loss': 2.2487673301342106, 'Validation Accuracy': 0.09637787930138846, 'Precision': 0.05500676573056168, 'Recall': 0.7937289725672878, 'Bleu Score': 0.1548969618336306}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  37%|███▋      | 147/400 [5:15:26<9:13:05, 131.17s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 148, 'Train Loss': 2.370156562789369, 'Train Accuracy': 0.7808870358376512, 'Validation Loss': 2.241710681560611, 'Validation Accuracy': 0.09640628182004185, 'Precision': 0.055348640012072, 'Recall': 0.7942748770703933, 'Bleu Score': 0.15578890814949492}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  37%|███▋      | 148/400 [5:17:38<9:12:04, 131.45s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 149, 'Train Loss': 2.366688794029352, 'Train Accuracy': 0.7812999244386873, 'Validation Loss': 2.238725941043255, 'Validation Accuracy': 0.09745837614453673, 'Precision': 0.05586772841475589, 'Recall': 0.7949663561076604, 'Bleu Score': 0.15670629697402663}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  37%|███▋      | 149/400 [5:19:48<9:07:57, 130.99s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 150, 'Train Loss': 2.3631470647964687, 'Train Accuracy': 0.7820528389464594, 'Validation Loss': 2.236670020198034, 'Validation Accuracy': 0.09798805525411151, 'Precision': 0.05615779176315083, 'Recall': 0.7954273421325052, 'Bleu Score': 0.15754583365639824}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  38%|███▊      | 150/400 [5:21:58<9:04:09, 130.60s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 151, 'Train Loss': 2.3604502577478716, 'Train Accuracy': 0.7825925626079447, 'Validation Loss': 2.2300417383840263, 'Validation Accuracy': 0.09855845832899353, 'Precision': 0.05655413177442703, 'Recall': 0.7960500776397516, 'Bleu Score': 0.15818872448285423}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  38%|███▊      | 151/400 [5:24:09<9:02:12, 130.65s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 152, 'Train Loss': 2.3563712486246016, 'Train Accuracy': 0.7836288320379965, 'Validation Loss': 2.2309510131512793, 'Validation Accuracy': 0.0988740468731593, 'Precision': 0.05714460792321921, 'Recall': 0.7969680059523809, 'Bleu Score': 0.16010989375290863}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  38%|███▊      | 152/400 [5:26:19<8:58:54, 130.38s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 153, 'Train Loss': 2.3536543052499463, 'Train Accuracy': 0.7837799546632125, 'Validation Loss': 2.2291836275542076, 'Validation Accuracy': 0.09958828347298128, 'Precision': 0.05720545848448669, 'Recall': 0.7971337991718427, 'Bleu Score': 0.1603272124753502}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  38%|███▊      | 153/400 [5:28:29<8:56:14, 130.26s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 154, 'Train Loss': 2.3499605420215355, 'Train Accuracy': 0.7845288212435233, 'Validation Loss': 2.2194562071611075, 'Validation Accuracy': 0.10086070480933593, 'Precision': 0.05785388951943814, 'Recall': 0.7980679024327122, 'Bleu Score': 0.16173075376607368}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  38%|███▊      | 154/400 [5:30:40<8:54:58, 130.48s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 155, 'Train Loss': 2.347406217735775, 'Train Accuracy': 0.7852048251295337, 'Validation Loss': 2.2175330209337973, 'Validation Accuracy': 0.10122692362698472, 'Precision': 0.05823606930250402, 'Recall': 0.7986582880434783, 'Bleu Score': 0.16261688608886388}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  39%|███▉      | 155/400 [5:32:52<8:54:46, 130.97s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 156, 'Train Loss': 2.3433860360917467, 'Train Accuracy': 0.7857647884283246, 'Validation Loss': 2.2128167896231346, 'Validation Accuracy': 0.10162089262859043, 'Precision': 0.058726283157106825, 'Recall': 0.7993982919254659, 'Bleu Score': 0.1639721559107535}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  39%|███▉      | 156/400 [5:35:02<8:51:15, 130.64s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 157, 'Train Loss': 2.3400021435806106, 'Train Accuracy': 0.7865055591537133, 'Validation Loss': 2.2082043304916255, 'Validation Accuracy': 0.10197021483993626, 'Precision': 0.05922626951117707, 'Recall': 0.8000250711697723, 'Bleu Score': 0.1651072771750786}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  39%|███▉      | 157/400 [5:37:11<8:47:26, 130.23s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 158, 'Train Loss': 2.336706715888081, 'Train Accuracy': 0.7870223445595855, 'Validation Loss': 2.2062333930622446, 'Validation Accuracy': 0.10266012190450528, 'Precision': 0.059827799861176686, 'Recall': 0.8008661684782609, 'Bleu Score': 0.16695802767508275}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  40%|███▉      | 158/400 [5:39:20<8:44:22, 130.01s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 159, 'Train Loss': 2.333575472976621, 'Train Accuracy': 0.787518890328152, 'Validation Loss': 2.200352767282281, 'Validation Accuracy': 0.10281243412138971, 'Precision': 0.06013819825179044, 'Recall': 0.8013271545031055, 'Bleu Score': 0.16755675933510028}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  40%|███▉      | 159/400 [5:41:32<8:44:12, 130.51s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 160, 'Train Loss': 2.33037877362736, 'Train Accuracy': 0.7881517163212435, 'Validation Loss': 2.1983550688451974, 'Validation Accuracy': 0.1024038807965942, 'Precision': 0.06073645619394036, 'Recall': 0.8021237707039337, 'Bleu Score': 0.16881562394299343}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  40%|████      | 160/400 [5:43:42<8:41:38, 130.41s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 161, 'Train Loss': 2.3273142268315206, 'Train Accuracy': 0.7888142271157168, 'Validation Loss': 2.1960393929284465, 'Validation Accuracy': 0.10302545647429691, 'Precision': 0.06086317511901804, 'Recall': 0.8024674883540373, 'Bleu Score': 0.16940676287764878}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  40%|████      | 161/400 [5:45:52<8:38:57, 130.28s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 162, 'Train Loss': 2.324194308143953, 'Train Accuracy': 0.7894038752158895, 'Validation Loss': 2.190257421702393, 'Validation Accuracy': 0.1032303649476563, 'Precision': 0.06131711910067333, 'Recall': 0.8032115359730849, 'Bleu Score': 0.17121383258988743}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  40%|████      | 162/400 [5:48:04<8:38:37, 130.75s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 163, 'Train Loss': 2.3205036555535226, 'Train Accuracy': 0.7900259067357513, 'Validation Loss': 2.1867145895957947, 'Validation Accuracy': 0.10377213421764306, 'Precision': 0.061988488275799405, 'Recall': 0.8039879334886129, 'Bleu Score': 0.17243971666737856}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  41%|████      | 163/400 [5:50:14<8:35:20, 130.47s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 164, 'Train Loss': 2.317158609793331, 'Train Accuracy': 0.7904482405008636, 'Validation Loss': 2.1861576945328514, 'Validation Accuracy': 0.10401560621149851, 'Precision': 0.06237166517055946, 'Recall': 0.8044731819358178, 'Bleu Score': 0.1734947505953062}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  41%|████      | 164/400 [5:52:24<8:32:25, 130.28s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 165, 'Train Loss': 2.314228493864365, 'Train Accuracy': 0.7912659218480138, 'Validation Loss': 2.1803782922177275, 'Validation Accuracy': 0.10567902812743118, 'Precision': 0.06287615462296485, 'Recall': 0.805083786231884, 'Bleu Score': 0.1747540774537022}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  41%|████▏     | 165/400 [5:54:35<8:31:39, 130.63s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 166, 'Train Loss': 2.311161935988052, 'Train Accuracy': 0.7916734132124352, 'Validation Loss': 2.177744854087672, 'Validation Accuracy': 0.10625458537393212, 'Precision': 0.06310056140010914, 'Recall': 0.8055164660973085, 'Bleu Score': 0.17546265406067965}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  42%|████▏     | 166/400 [5:56:46<8:29:34, 130.66s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 167, 'Train Loss': 2.307296320713686, 'Train Accuracy': 0.7920701101036269, 'Validation Loss': 2.1742076073303696, 'Validation Accuracy': 0.10627192647680853, 'Precision': 0.06356189347519976, 'Recall': 0.806058326863354, 'Bleu Score': 0.17706496670056815}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  42%|████▏     | 167/400 [5:58:57<8:27:39, 130.73s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 168, 'Train Loss': 2.3048447902360674, 'Train Accuracy': 0.7928662025043178, 'Validation Loss': 2.171154923675474, 'Validation Accuracy': 0.1081367125211843, 'Precision': 0.06416502758335968, 'Recall': 0.8070126488095238, 'Bleu Score': 0.1793871575524317}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  42%|████▏     | 168/400 [6:01:07<8:25:26, 130.72s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 169, 'Train Loss': 2.301139664584102, 'Train Accuracy': 0.7931563039723661, 'Validation Loss': 2.1718009611791818, 'Validation Accuracy': 0.10761985741164504, 'Precision': 0.06420937120806768, 'Recall': 0.8070813923395446, 'Bleu Score': 0.1791472839536165}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  42%|████▏     | 169/400 [6:03:18<8:23:28, 130.77s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 170, 'Train Loss': 2.2981457231123805, 'Train Accuracy': 0.7936649935233161, 'Validation Loss': 2.162951242578916, 'Validation Accuracy': 0.1087097205164534, 'Precision': 0.06471397384979703, 'Recall': 0.80761920936853, 'Bleu Score': 0.18023045587394287}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  42%|████▎     | 170/400 [6:05:30<8:22:10, 131.00s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 171, 'Train Loss': 2.294987013326824, 'Train Accuracy': 0.7944435449050087, 'Validation Loss': 2.1634050504235196, 'Validation Accuracy': 0.10990421573071645, 'Precision': 0.06515094696886893, 'Recall': 0.8081893762939959, 'Bleu Score': 0.1813864385091407}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  43%|████▎     | 171/400 [6:07:40<8:18:26, 130.60s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 172, 'Train Loss': 2.2921811966276957, 'Train Accuracy': 0.7948361938687392, 'Validation Loss': 2.15709240475962, 'Validation Accuracy': 0.11069631347281284, 'Precision': 0.06549689158725842, 'Recall': 0.8086988871635611, 'Bleu Score': 0.18205164377793795}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  43%|████▎     | 172/400 [6:09:51<8:17:05, 130.82s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 173, 'Train Loss': 2.2887093760690638, 'Train Accuracy': 0.7953678216753023, 'Validation Loss': 2.153078468377925, 'Validation Accuracy': 0.1104991865581587, 'Precision': 0.06589795056540752, 'Recall': 0.8092528791407867, 'Bleu Score': 0.18329090490904548}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  43%|████▎     | 173/400 [6:12:01<8:14:32, 130.71s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 174, 'Train Loss': 2.285518770553789, 'Train Accuracy': 0.796211139896373, 'Validation Loss': 2.148574339949395, 'Validation Accuracy': 0.11267710188135499, 'Precision': 0.06645313370067472, 'Recall': 0.8098432647515528, 'Bleu Score': 0.18468886705741208}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  44%|████▎     | 174/400 [6:14:12<8:12:09, 130.66s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 175, 'Train Loss': 2.2823952602747397, 'Train Accuracy': 0.7965619602763385, 'Validation Loss': 2.1486471049056566, 'Validation Accuracy': 0.11310090231251518, 'Precision': 0.06685949578878321, 'Recall': 0.8104740877329193, 'Bleu Score': 0.18633492098916687}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  44%|████▍     | 175/400 [6:16:21<8:08:38, 130.31s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 176, 'Train Loss': 2.2795399028951953, 'Train Accuracy': 0.79724201208981, 'Validation Loss': 2.143323722457098, 'Validation Accuracy': 0.11430346052962434, 'Precision': 0.06753133838885744, 'Recall': 0.8114122347308489, 'Bleu Score': 0.18790588975190786}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  44%|████▍     | 176/400 [6:18:34<8:09:17, 131.06s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 177, 'Train Loss': 2.276654237212397, 'Train Accuracy': 0.7974187715889465, 'Validation Loss': 2.1420387798104406, 'Validation Accuracy': 0.11459621914295841, 'Precision': 0.06774857826500684, 'Recall': 0.8116993400621118, 'Bleu Score': 0.1886421181117159}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  44%|████▍     | 177/400 [6:20:45<8:06:45, 130.97s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 178, 'Train Loss': 2.273999855992544, 'Train Accuracy': 0.7982526446459413, 'Validation Loss': 2.1384419493438784, 'Validation Accuracy': 0.11529174910882403, 'Precision': 0.0682070107353719, 'Recall': 0.8124231689958592, 'Bleu Score': 0.190844647471074}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  44%|████▍     | 178/400 [6:22:56<8:04:38, 130.98s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 179, 'Train Loss': 2.270859526501176, 'Train Accuracy': 0.7987599848877375, 'Validation Loss': 2.1358556639064443, 'Validation Accuracy': 0.11534792990220027, 'Precision': 0.06854827680937221, 'Recall': 0.8128477613871635, 'Bleu Score': 0.191653330516272}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  45%|████▍     | 179/400 [6:25:07<8:02:23, 130.97s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 180, 'Train Loss': 2.267376022773553, 'Train Accuracy': 0.7993779684801382, 'Validation Loss': 2.131427121556495, 'Validation Accuracy': 0.11700454962494444, 'Precision': 0.06912123559179498, 'Recall': 0.8135513716356108, 'Bleu Score': 0.1933435219059096}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  45%|████▌     | 180/400 [6:27:18<8:00:25, 131.03s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 181, 'Train Loss': 2.26404774880541, 'Train Accuracy': 0.7997341860967185, 'Validation Loss': 2.126044664008558, 'Validation Accuracy': 0.11680860832861986, 'Precision': 0.06923920892211478, 'Recall': 0.813769733436853, 'Bleu Score': 0.19400951713792428}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  45%|████▌     | 181/400 [6:29:29<7:58:02, 130.97s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 182, 'Train Loss': 2.261254939585101, 'Train Accuracy': 0.8003062931778929, 'Validation Loss': 2.123312972793894, 'Validation Accuracy': 0.1177601370730933, 'Precision': 0.06979772939816371, 'Recall': 0.8144167313664596, 'Bleu Score': 0.19523597164259018}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  46%|████▌     | 182/400 [6:31:40<7:55:34, 130.89s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 183, 'Train Loss': 2.2580250157506425, 'Train Accuracy': 0.8011145293609672, 'Validation Loss': 2.1196266821593293, 'Validation Accuracy': 0.11851650112164104, 'Precision': 0.07016349528414505, 'Recall': 0.8149949857660456, 'Bleu Score': 0.1966116956324621}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  46%|████▌     | 183/400 [6:33:53<7:56:38, 131.79s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 184, 'Train Loss': 2.2554543421742665, 'Train Accuracy': 0.8013681994818653, 'Validation Loss': 2.1163779324736476, 'Validation Accuracy': 0.11926234320048837, 'Precision': 0.07045744592717082, 'Recall': 0.8153791407867494, 'Bleu Score': 0.19756983857747304}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  46%|████▌     | 184/400 [6:36:06<7:54:42, 131.87s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 185, 'Train Loss': 2.2522739731804444, 'Train Accuracy': 0.8018067249568221, 'Validation Loss': 2.116685705736649, 'Validation Accuracy': 0.11952752183230766, 'Precision': 0.07108209044636757, 'Recall': 0.8160301824534162, 'Bleu Score': 0.19896331499824438}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  46%|████▋     | 185/400 [6:38:15<7:50:09, 131.21s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 186, 'Train Loss': 2.249142673628106, 'Train Accuracy': 0.802305969343696, 'Validation Loss': 2.1091996076678443, 'Validation Accuracy': 0.12047962685869539, 'Precision': 0.071507419266578, 'Recall': 0.816596305641822, 'Bleu Score': 0.20028760969594028}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  46%|████▋     | 186/400 [6:40:26<7:47:40, 131.12s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 187, 'Train Loss': 2.246288026893995, 'Train Accuracy': 0.8029158570811744, 'Validation Loss': 2.106094953442408, 'Validation Accuracy': 0.12202910491153048, 'Precision': 0.07200905298003947, 'Recall': 0.8170977290372671, 'Bleu Score': 0.20138965061277725}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  47%|████▋     | 187/400 [6:42:38<7:46:03, 131.28s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 188, 'Train Loss': 2.2430989829545522, 'Train Accuracy': 0.8031047603626943, 'Validation Loss': 2.106130772878316, 'Validation Accuracy': 0.12213741578451655, 'Precision': 0.07238681569266102, 'Recall': 0.8176678959627329, 'Bleu Score': 0.20274988027043866}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  47%|████▋     | 188/400 [6:44:48<7:43:07, 131.07s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 189, 'Train Loss': 2.2403961187897465, 'Train Accuracy': 0.8036971070811745, 'Validation Loss': 2.103214051112656, 'Validation Accuracy': 0.12224011867698902, 'Precision': 0.07280612250692554, 'Recall': 0.818258281573499, 'Bleu Score': 0.20409213270508736}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  47%|████▋     | 189/400 [6:47:01<7:42:33, 131.53s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 190, 'Train Loss': 2.237495040860624, 'Train Accuracy': 0.8041585708117444, 'Validation Loss': 2.097232093495771, 'Validation Accuracy': 0.12279626717622806, 'Precision': 0.07321434171508862, 'Recall': 0.8187516174948241, 'Bleu Score': 0.20494690726591186}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  48%|████▊     | 190/400 [6:49:13<7:41:04, 131.74s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 191, 'Train Loss': 2.2338632499974076, 'Train Accuracy': 0.8046524179620035, 'Validation Loss': 2.0947442330604744, 'Validation Accuracy': 0.12347079262187664, 'Precision': 0.07360113651695147, 'Recall': 0.8192489971532091, 'Bleu Score': 0.205809126400127}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  48%|████▊     | 191/400 [6:51:25<7:39:17, 131.85s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 192, 'Train Loss': 2.231751216379977, 'Train Accuracy': 0.8052150798791019, 'Validation Loss': 2.091544666073539, 'Validation Accuracy': 0.12408175387598402, 'Precision': 0.07417661601256635, 'Recall': 0.8198151203416149, 'Bleu Score': 0.20741752194486449}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  48%|████▊     | 192/400 [6:53:37<7:36:30, 131.69s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 193, 'Train Loss': 2.228701385509902, 'Train Accuracy': 0.8054512089810018, 'Validation Loss': 2.0887129828949607, 'Validation Accuracy': 0.12419157416609582, 'Precision': 0.07467568103203098, 'Recall': 0.8204621182712215, 'Bleu Score': 0.2087345553235786}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  48%|████▊     | 193/400 [6:55:47<7:32:34, 131.18s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 194, 'Train Loss': 2.2256808132756483, 'Train Accuracy': 0.8060921308290155, 'Validation Loss': 2.0867725093502645, 'Validation Accuracy': 0.12482862637500038, 'Precision': 0.07515052384643148, 'Recall': 0.8208422295548654, 'Bleu Score': 0.2092670213813726}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  48%|████▊     | 194/400 [6:57:58<7:30:26, 131.20s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 195, 'Train Loss': 2.2228664918828405, 'Train Accuracy': 0.8068976683937824, 'Validation Loss': 2.083632535678296, 'Validation Accuracy': 0.12482808113463909, 'Precision': 0.0756226811232726, 'Recall': 0.8216388457556936, 'Bleu Score': 0.21062208121366902}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  49%|████▉     | 195/400 [7:00:10<7:29:39, 131.61s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 196, 'Train Loss': 2.219710931922849, 'Train Accuracy': 0.8070582361830743, 'Validation Loss': 2.0788106243472453, 'Validation Accuracy': 0.12561818799067448, 'Precision': 0.07592223460113263, 'Recall': 0.8220230007763976, 'Bleu Score': 0.21180504752935328}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  49%|████▉     | 196/400 [7:02:24<7:29:15, 132.13s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 197, 'Train Loss': 2.216654204778908, 'Train Accuracy': 0.8074913644214162, 'Validation Loss': 2.076003805664945, 'Validation Accuracy': 0.126118760764464, 'Precision': 0.07624311605078055, 'Recall': 0.8223990683229814, 'Bleu Score': 0.2122897114968085}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  49%|████▉     | 197/400 [7:04:35<7:26:38, 132.01s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 198, 'Train Loss': 2.2140103792617336, 'Train Accuracy': 0.8080459304835924, 'Validation Loss': 2.0729443406270556, 'Validation Accuracy': 0.1262908153262391, 'Precision': 0.07676519954740865, 'Recall': 0.8229207104037267, 'Bleu Score': 0.21355651661031294}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  50%|████▉     | 198/400 [7:06:47<7:24:06, 131.91s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 199, 'Train Loss': 2.2111329800186894, 'Train Accuracy': 0.8085397776338514, 'Validation Loss': 2.070942320606925, 'Validation Accuracy': 0.12773858845062894, 'Precision': 0.07735485811485095, 'Recall': 0.8234747023809523, 'Bleu Score': 0.21430639156249082}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  50%|████▉     | 199/400 [7:08:59<7:21:51, 131.90s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 200, 'Train Loss': 2.2082834466880197, 'Train Accuracy': 0.8090417206390328, 'Validation Loss': 2.0654458245955225, 'Validation Accuracy': 0.12802177736074552, 'Precision': 0.07785709151093545, 'Recall': 0.8239154697204969, 'Bleu Score': 0.21545460007180395}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  50%|█████     | 200/400 [7:11:10<7:18:55, 131.68s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 201, 'Train Loss': 2.2057014983661927, 'Train Accuracy': 0.8093884930915372, 'Validation Loss': 2.063086968315534, 'Validation Accuracy': 0.1290345376539166, 'Precision': 0.07838457291876383, 'Recall': 0.8245382052277432, 'Bleu Score': 0.2171788760880833}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  50%|█████     | 201/400 [7:13:33<7:27:39, 134.97s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 202, 'Train Loss': 2.2028639570125557, 'Train Accuracy': 0.8099956822107082, 'Validation Loss': 2.0591292361582605, 'Validation Accuracy': 0.12954824571220902, 'Precision': 0.07875900273720546, 'Recall': 0.8251366783126294, 'Bleu Score': 0.21836497228302196}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  50%|█████     | 202/400 [7:15:46<7:23:07, 134.28s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 203, 'Train Loss': 2.199787208882485, 'Train Accuracy': 0.8106042206390328, 'Validation Loss': 2.057699262110655, 'Validation Accuracy': 0.1290870404726777, 'Precision': 0.07904489768807504, 'Recall': 0.8256340579710145, 'Bleu Score': 0.21901398864166866}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  51%|█████     | 203/400 [7:17:59<7:20:25, 134.14s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 204, 'Train Loss': 2.197333064033182, 'Train Accuracy': 0.810829555267703, 'Validation Loss': 2.053918229646919, 'Validation Accuracy': 0.12994396779832612, 'Precision': 0.07958796538120902, 'Recall': 0.8262082686335404, 'Bleu Score': 0.22069248225005683}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  51%|█████     | 204/400 [7:20:11<7:15:34, 133.34s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 205, 'Train Loss': 2.194052959344664, 'Train Accuracy': 0.8113180051813471, 'Validation Loss': 2.0529472064380805, 'Validation Accuracy': 0.1303532453642753, 'Precision': 0.08002420901849724, 'Recall': 0.8266854296066253, 'Bleu Score': 0.22161705114938854}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  51%|█████▏    | 205/400 [7:22:22<7:11:23, 132.74s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 206, 'Train Loss': 2.191616667239047, 'Train Accuracy': 0.8117147020725388, 'Validation Loss': 2.051102695878872, 'Validation Accuracy': 0.13071622280772757, 'Precision': 0.0803930528993108, 'Recall': 0.8270210597826086, 'Bleu Score': 0.22197898154717405}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  52%|█████▏    | 206/400 [7:24:34<7:07:52, 132.33s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 207, 'Train Loss': 2.188473292477223, 'Train Accuracy': 0.8123704663212435, 'Validation Loss': 2.0469051372906395, 'Validation Accuracy': 0.13087462381746987, 'Precision': 0.08050810608642184, 'Recall': 0.8273849961180124, 'Bleu Score': 0.2226194412181586}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  52%|█████▏    | 207/400 [7:26:44<7:04:04, 131.84s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 208, 'Train Loss': 2.1855288284588914, 'Train Accuracy': 0.8127131908462867, 'Validation Loss': 2.0419566173198795, 'Validation Accuracy': 0.13177930942184435, 'Precision': 0.08092120761365454, 'Recall': 0.8278864195134575, 'Bleu Score': 0.22376399556562596}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  52%|█████▏    | 208/400 [7:28:56<7:01:28, 131.71s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 209, 'Train Loss': 2.183127590635205, 'Train Accuracy': 0.8130451208981002, 'Validation Loss': 2.0420430356805976, 'Validation Accuracy': 0.13155200650633828, 'Precision': 0.08129813294302798, 'Recall': 0.828416149068323, 'Bleu Score': 0.22501358149393366}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  52%|█████▏    | 209/400 [7:31:08<6:59:44, 131.86s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 210, 'Train Loss': 2.1803171736759377, 'Train Accuracy': 0.8136590565630397, 'Validation Loss': 2.036120593055221, 'Validation Accuracy': 0.13142646738565691, 'Precision': 0.08149439036281346, 'Recall': 0.828808391563147, 'Bleu Score': 0.22569677102972524}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  52%|█████▎    | 210/400 [7:33:22<6:59:32, 132.48s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 211, 'Train Loss': 2.1775542701805493, 'Train Accuracy': 0.8143579987046632, 'Validation Loss': 2.0344146194536825, 'Validation Accuracy': 0.1327452198264986, 'Precision': 0.08202586844474762, 'Recall': 0.8293138586956522, 'Bleu Score': 0.22647995834712845}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  53%|█████▎    | 211/400 [7:35:33<6:56:07, 132.10s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 212, 'Train Loss': 2.17498470851071, 'Train Accuracy': 0.8147223121761658, 'Validation Loss': 2.0324374304330055, 'Validation Accuracy': 0.13177302823237766, 'Precision': 0.08212968464894656, 'Recall': 0.8297020574534162, 'Bleu Score': 0.2275641958798185}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  53%|█████▎    | 212/400 [7:37:46<6:54:32, 132.30s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 213, 'Train Loss': 2.1718640538210368, 'Train Accuracy': 0.8146454015544041, 'Validation Loss': 2.0285861201522764, 'Validation Accuracy': 0.132479295829921, 'Precision': 0.082450194666216, 'Recall': 0.8300619500517599, 'Bleu Score': 0.22796172038074827}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  53%|█████▎    | 213/400 [7:39:58<6:52:12, 132.26s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 214, 'Train Loss': 2.169235204958784, 'Train Accuracy': 0.8152566386010363, 'Validation Loss': 2.0279047636946372, 'Validation Accuracy': 0.13343008015869479, 'Precision': 0.08302080338532372, 'Recall': 0.8306159420289855, 'Bleu Score': 0.22950648786618255}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  54%|█████▎    | 214/400 [7:42:11<6:50:29, 132.42s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 215, 'Train Loss': 2.166744035910506, 'Train Accuracy': 0.8156169041450777, 'Validation Loss': 2.022328294998358, 'Validation Accuracy': 0.1328774945718528, 'Precision': 0.08331962951299454, 'Recall': 0.8311133216873706, 'Bleu Score': 0.23090185032392965}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  54%|█████▍    | 215/400 [7:44:22<6:47:39, 132.21s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 216, 'Train Loss': 2.163805991081902, 'Train Accuracy': 0.8162524287564766, 'Validation Loss': 2.0187654647945372, 'Validation Accuracy': 0.1338943932985433, 'Precision': 0.08371229519601277, 'Recall': 0.8314044707556936, 'Bleu Score': 0.23128481604156395}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  54%|█████▍    | 216/400 [7:46:34<6:44:46, 131.99s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 217, 'Train Loss': 2.161052879707589, 'Train Accuracy': 0.8166693652849741, 'Validation Loss': 2.01533763566293, 'Validation Accuracy': 0.1345456042850195, 'Precision': 0.08423198218582946, 'Recall': 0.8319786814182195, 'Bleu Score': 0.2327374879187993}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  54%|█████▍    | 217/400 [7:48:39<6:35:49, 129.78s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 218, 'Train Loss': 2.1581830635913826, 'Train Accuracy': 0.8172401230569948, 'Validation Loss': 2.012751457119776, 'Validation Accuracy': 0.13586304020312553, 'Precision': 0.08482217140593946, 'Recall': 0.8325367171325052, 'Bleu Score': 0.23393631023180037}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  55%|█████▍    | 218/400 [7:50:33<6:19:48, 125.21s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 219, 'Train Loss': 2.1557213239248285, 'Train Accuracy': 0.8176975388601037, 'Validation Loss': 2.010012167051804, 'Validation Accuracy': 0.1369137230292063, 'Precision': 0.08522340038269481, 'Recall': 0.8329087409420289, 'Bleu Score': 0.23478268138835795}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  55%|█████▍    | 219/400 [7:52:28<6:08:07, 122.03s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 220, 'Train Loss': 2.1531475790627095, 'Train Accuracy': 0.8178216753022453, 'Validation Loss': 2.007019265377817, 'Validation Accuracy': 0.1376741956661128, 'Precision': 0.08536980887956655, 'Recall': 0.8332767210144928, 'Bleu Score': 0.23538727513962085}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  55%|█████▌    | 220/400 [7:54:23<5:59:39, 119.89s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 221, 'Train Loss': 2.150215138552597, 'Train Accuracy': 0.8183290155440415, 'Validation Loss': 2.006513187461648, 'Validation Accuracy': 0.1370574856304141, 'Precision': 0.08576913202775323, 'Recall': 0.8338307129917184, 'Bleu Score': 0.23644971640995105}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  55%|█████▌    | 221/400 [7:56:17<5:52:49, 118.27s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 222, 'Train Loss': 2.147433853116483, 'Train Accuracy': 0.818778335492228, 'Validation Loss': 2.00167505233741, 'Validation Accuracy': 0.13888207816497822, 'Precision': 0.08623287453880234, 'Recall': 0.8342189117494824, 'Bleu Score': 0.2382122142975695}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  56%|█████▌    | 222/400 [7:58:12<5:47:58, 117.29s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 223, 'Train Loss': 2.1450916123653645, 'Train Accuracy': 0.8190252590673575, 'Validation Loss': 1.9994698329405352, 'Validation Accuracy': 0.13854818670289296, 'Precision': 0.08632134097982322, 'Recall': 0.8343442675983437, 'Bleu Score': 0.23816527882406985}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  56%|█████▌    | 223/400 [8:00:06<5:43:27, 116.42s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 224, 'Train Loss': 2.1422185230979602, 'Train Accuracy': 0.8198712759067357, 'Validation Loss': 1.9968443899607855, 'Validation Accuracy': 0.13906838762680204, 'Precision': 0.08671893167233213, 'Recall': 0.8348214285714286, 'Bleu Score': 0.23929688597839202}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  56%|█████▌    | 224/400 [8:02:19<5:55:15, 121.11s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 225, 'Train Loss': 2.139357899434, 'Train Accuracy': 0.8201505829015544, 'Validation Loss': 1.9976774473820835, 'Validation Accuracy': 0.13855236195455117, 'Precision': 0.08689928620520047, 'Recall': 0.8351247088509317, 'Bleu Score': 0.2400254961558121}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  56%|█████▋    | 225/400 [8:04:40<6:10:49, 127.14s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 226, 'Train Loss': 2.1367417280845222, 'Train Accuracy': 0.8205310880829015, 'Validation Loss': 1.9926201277527928, 'Validation Accuracy': 0.1397432808379657, 'Precision': 0.08759763381401403, 'Recall': 0.8356544384057971, 'Bleu Score': 0.24151344098148603}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  56%|█████▋    | 226/400 [8:06:57<6:17:43, 130.25s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 227, 'Train Loss': 2.1341963917510944, 'Train Accuracy': 0.8213096394645941, 'Validation Loss': 1.990585148088203, 'Validation Accuracy': 0.14042392508861914, 'Precision': 0.08769982775434582, 'Recall': 0.8358768439440993, 'Bleu Score': 0.24178918692787713}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  57%|█████▋    | 227/400 [8:09:13<6:20:31, 131.97s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 228, 'Train Loss': 2.131543001417297, 'Train Accuracy': 0.8214054404145078, 'Validation Loss': 1.9858663313644977, 'Validation Accuracy': 0.1406854298017386, 'Precision': 0.08798203257333237, 'Recall': 0.836236736542443, 'Bleu Score': 0.24289648963287533}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  57%|█████▋    | 228/400 [8:11:29<6:21:43, 133.16s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 229, 'Train Loss': 2.1296013755034346, 'Train Accuracy': 0.821738719775475, 'Validation Loss': 1.9838569193832145, 'Validation Accuracy': 0.14158838103574525, 'Precision': 0.0884837140237383, 'Recall': 0.8366491977225673, 'Bleu Score': 0.24384902207204637}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  57%|█████▋    | 229/400 [8:13:47<6:23:30, 134.56s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 230, 'Train Loss': 2.12631760809303, 'Train Accuracy': 0.822416072970639, 'Validation Loss': 1.9843638293014085, 'Validation Accuracy': 0.14132294094102035, 'Precision': 0.08876567175464249, 'Recall': 0.8371546648550725, 'Bleu Score': 0.2452748369068407}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  57%|█████▊    | 230/400 [8:16:04<6:23:16, 135.27s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 231, 'Train Loss': 2.123732931706128, 'Train Accuracy': 0.8224713946459413, 'Validation Loss': 1.9779287024963002, 'Validation Accuracy': 0.14235641618464173, 'Precision': 0.08912536666080344, 'Recall': 0.8374822075569358, 'Bleu Score': 0.2458104838203445}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  58%|█████▊    | 231/400 [8:18:19<6:20:34, 135.11s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 232, 'Train Loss': 2.120935341518228, 'Train Accuracy': 0.8229085708117444, 'Validation Loss': 1.9732512792279897, 'Validation Accuracy': 0.14251481902900007, 'Precision': 0.0895533590470055, 'Recall': 0.8380564182194618, 'Bleu Score': 0.24721781805312046}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  58%|█████▊    | 232/400 [8:20:30<6:14:45, 133.84s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 233, 'Train Loss': 2.1183839083047205, 'Train Accuracy': 0.8232715349740932, 'Validation Loss': 1.9714684801653397, 'Validation Accuracy': 0.14249801313265134, 'Precision': 0.08970540029617281, 'Recall': 0.8381170742753623, 'Bleu Score': 0.2473790859613726}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  58%|█████▊    | 233/400 [8:22:41<6:10:19, 133.05s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 234, 'Train Loss': 2.1158287212334943, 'Train Accuracy': 0.8239326964594128, 'Validation Loss': 1.9697102840281715, 'Validation Accuracy': 0.1428809234183949, 'Precision': 0.09025890885534012, 'Recall': 0.838772159679089, 'Bleu Score': 0.2491306851511179}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  58%|█████▊    | 234/400 [8:24:52<6:06:37, 132.51s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 235, 'Train Loss': 2.1135526915281515, 'Train Accuracy': 0.8243051057858376, 'Validation Loss': 1.9665723684405492, 'Validation Accuracy': 0.14353828150340833, 'Precision': 0.09064848128872824, 'Recall': 0.8391037461180124, 'Bleu Score': 0.25003464505477935}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  59%|█████▉    | 235/400 [8:27:03<6:03:01, 132.01s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 236, 'Train Loss': 2.1109975218278927, 'Train Accuracy': 0.8245560772884283, 'Validation Loss': 1.9668629435468312, 'Validation Accuracy': 0.1446627293320786, 'Precision': 0.09078055926282874, 'Recall': 0.8393140204451346, 'Bleu Score': 0.2507012917096486}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  59%|█████▉    | 236/400 [8:29:15<6:00:54, 132.04s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 237, 'Train Loss': 2.108315297253224, 'Train Accuracy': 0.825037780656304, 'Validation Loss': 1.9629901514565649, 'Validation Accuracy': 0.14483028474747778, 'Precision': 0.09129780055688812, 'Recall': 0.839742656573499, 'Bleu Score': 0.2515938472689278}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  59%|█████▉    | 237/400 [8:31:27<5:58:46, 132.06s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 238, 'Train Loss': 2.105720028939827, 'Train Accuracy': 0.8255154360967185, 'Validation Loss': 1.9595243950520664, 'Validation Accuracy': 0.14530368418296707, 'Precision': 0.09166477097862777, 'Recall': 0.8400701992753623, 'Bleu Score': 0.25269580804082215}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  60%|█████▉    | 238/400 [8:33:39<5:56:22, 131.99s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 239, 'Train Loss': 2.103498495086122, 'Train Accuracy': 0.8260942897236615, 'Validation Loss': 1.9566320254783, 'Validation Accuracy': 0.14496856068216837, 'Precision': 0.09199095678163137, 'Recall': 0.840337085921325, 'Bleu Score': 0.2537705236258044}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  60%|█████▉    | 239/400 [8:35:50<5:53:52, 131.88s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 240, 'Train Loss': 2.1011415708460204, 'Train Accuracy': 0.8261819948186528, 'Validation Loss': 1.954687755708852, 'Validation Accuracy': 0.1456741313629397, 'Precision': 0.09224842010864165, 'Recall': 0.8407657220496895, 'Bleu Score': 0.25457176067145487}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  60%|██████    | 240/400 [8:38:02<5:51:14, 131.71s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 241, 'Train Loss': 2.0977710882273826, 'Train Accuracy': 0.8267271157167531, 'Validation Loss': 1.9499047728609447, 'Validation Accuracy': 0.14607650961919677, 'Precision': 0.09286755481822073, 'Recall': 0.8412388392857143, 'Bleu Score': 0.256090689892973}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  60%|██████    | 241/400 [8:40:13<5:48:34, 131.54s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 242, 'Train Loss': 2.0954996117735436, 'Train Accuracy': 0.8268714917962003, 'Validation Loss': 1.9488408348777078, 'Validation Accuracy': 0.14635330588609216, 'Precision': 0.09327588802537376, 'Recall': 0.8416351255175983, 'Bleu Score': 0.2570770796974614}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  60%|██████    | 242/400 [8:42:26<5:47:26, 131.94s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 243, 'Train Loss': 2.0931124462442505, 'Train Accuracy': 0.8275407491364422, 'Validation Loss': 1.945701325235288, 'Validation Accuracy': 0.14636748010599193, 'Precision': 0.09379645365854358, 'Recall': 0.8420718491200828, 'Bleu Score': 0.2582460099967069}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  61%|██████    | 243/400 [8:44:36<5:44:14, 131.56s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 244, 'Train Loss': 2.0906836382262615, 'Train Accuracy': 0.8276149611398964, 'Validation Loss': 1.9436754081860061, 'Validation Accuracy': 0.1473022280963783, 'Precision': 0.09412812055456815, 'Recall': 0.8423872606107661, 'Bleu Score': 0.2591121784698807}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  61%|██████    | 244/400 [8:46:48<5:41:53, 131.50s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 245, 'Train Loss': 2.088261512432309, 'Train Accuracy': 0.8282140544041451, 'Validation Loss': 1.9408201333905055, 'Validation Accuracy': 0.14778919188335934, 'Precision': 0.09476229005241511, 'Recall': 0.8429736024844721, 'Bleu Score': 0.2608367846567123}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  61%|██████▏   | 245/400 [8:49:01<5:40:50, 131.94s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 246, 'Train Loss': 2.0860357796618954, 'Train Accuracy': 0.8286053540587219, 'Validation Loss': 1.9386700854813756, 'Validation Accuracy': 0.14811309208136703, 'Precision': 0.09503328326029399, 'Recall': 0.8431960080227743, 'Bleu Score': 0.2613573296438868}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  62%|██████▏   | 246/400 [8:51:12<5:38:20, 131.82s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 247, 'Train Loss': 2.0834554957421445, 'Train Accuracy': 0.8291869063039724, 'Validation Loss': 1.9364872614214244, 'Validation Accuracy': 0.14751737448899419, 'Precision': 0.09521604002028765, 'Recall': 0.8434345885093167, 'Bleu Score': 0.26211893618733656}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  62%|██████▏   | 247/400 [8:53:24<5:35:39, 131.63s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 248, 'Train Loss': 2.081017857510082, 'Train Accuracy': 0.8294958981001727, 'Validation Loss': 1.9313613373385974, 'Validation Accuracy': 0.14843602533656633, 'Precision': 0.09562029229743357, 'Recall': 0.8436974314182195, 'Bleu Score': 0.2627825234231581}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  62%|██████▏   | 248/400 [8:55:36<5:33:52, 131.79s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 249, 'Train Loss': 2.078905966729749, 'Train Accuracy': 0.8295728087219344, 'Validation Loss': 1.9303642550775828, 'Validation Accuracy': 0.14959421148111873, 'Precision': 0.09620239668109114, 'Recall': 0.8443161231884058, 'Bleu Score': 0.2646844184347749}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  62%|██████▏   | 249/400 [8:57:47<5:31:33, 131.75s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 250, 'Train Loss': 2.076341038580099, 'Train Accuracy': 0.8303392163212435, 'Validation Loss': 1.9277491663113113, 'Validation Accuracy': 0.1501114061035961, 'Precision': 0.09674912617720584, 'Recall': 0.84472454063147, 'Bleu Score': 0.26583433979100246}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  62%|██████▎   | 250/400 [9:00:00<5:29:56, 131.97s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 251, 'Train Loss': 2.0737590933043655, 'Train Accuracy': 0.8307682966321244, 'Validation Loss': 1.9265270223302289, 'Validation Accuracy': 0.15007884601528107, 'Precision': 0.09700526425146383, 'Recall': 0.8449388586956522, 'Bleu Score': 0.2664783635445608}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  63%|██████▎   | 251/400 [9:02:12<5:27:31, 131.89s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 252, 'Train Loss': 2.0713467258774774, 'Train Accuracy': 0.831038158462867, 'Validation Loss': 1.922766958632745, 'Validation Accuracy': 0.15048829571383338, 'Precision': 0.097447657011866, 'Recall': 0.8452583139233955, 'Bleu Score': 0.2670321642194183}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  63%|██████▎   | 252/400 [9:04:24<5:25:57, 132.15s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 253, 'Train Loss': 2.069382619462619, 'Train Accuracy': 0.8314294581174438, 'Validation Loss': 1.9196777333897992, 'Validation Accuracy': 0.15203180979269124, 'Precision': 0.09806886213036423, 'Recall': 0.8457192999482401, 'Bleu Score': 0.26868129329445933}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  63%|██████▎   | 253/400 [9:06:36<5:23:39, 132.11s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 254, 'Train Loss': 2.0665806741016346, 'Train Accuracy': 0.8316885254749569, 'Validation Loss': 1.9163680083988126, 'Validation Accuracy': 0.15212021486833519, 'Precision': 0.09823811488922642, 'Recall': 0.8461479360766045, 'Bleu Score': 0.2692772481988686}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  64%|██████▎   | 254/400 [9:08:47<5:20:22, 131.66s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 255, 'Train Loss': 2.0640879245423482, 'Train Accuracy': 0.8322700777202072, 'Validation Loss': 1.9157002797304106, 'Validation Accuracy': 0.1528918319511091, 'Precision': 0.0987758569614081, 'Recall': 0.8465442223084886, 'Bleu Score': 0.2703010206212838}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  64%|██████▍   | 255/400 [9:10:58<5:17:42, 131.46s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 256, 'Train Loss': 2.0620144307613373, 'Train Accuracy': 0.8324306455094992, 'Validation Loss': 1.913090246275437, 'Validation Accuracy': 0.154299965599076, 'Precision': 0.09928348638114534, 'Recall': 0.8470658643892339, 'Bleu Score': 0.27193897562301295}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  64%|██████▍   | 256/400 [9:13:10<5:16:11, 131.75s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 257, 'Train Loss': 2.0592993609813037, 'Train Accuracy': 0.8331066493955095, 'Validation Loss': 1.9111696195996497, 'Validation Accuracy': 0.15388292562034697, 'Precision': 0.09977533089284538, 'Recall': 0.8474823693064182, 'Bleu Score': 0.27291988729749606}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  64%|██████▍   | 257/400 [9:15:21<5:13:20, 131.47s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 258, 'Train Loss': 2.0572239191821926, 'Train Accuracy': 0.8333171416234888, 'Validation Loss': 1.907911494004825, 'Validation Accuracy': 0.15557286529552988, 'Precision': 0.10028162967057282, 'Recall': 0.847846305641822, 'Bleu Score': 0.27365635911571584}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  64%|██████▍   | 258/400 [9:17:33<5:11:06, 131.45s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 259, 'Train Loss': 2.054664953637518, 'Train Accuracy': 0.8334723121761658, 'Validation Loss': 1.90570929621862, 'Validation Accuracy': 0.15538634721343764, 'Precision': 0.10034509089657513, 'Recall': 0.8480363612836439, 'Bleu Score': 0.27435604299961286}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  65%|██████▍   | 259/400 [9:19:46<5:10:33, 132.15s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 260, 'Train Loss': 2.0527181137991213, 'Train Accuracy': 0.8341523639896373, 'Validation Loss': 1.903498645656365, 'Validation Accuracy': 0.15509723541465595, 'Precision': 0.10065768566483216, 'Recall': 0.8483922101449275, 'Bleu Score': 0.27528652524571184}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  65%|██████▌   | 260/400 [9:21:58<5:08:13, 132.10s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 261, 'Train Loss': 2.0501538697856567, 'Train Accuracy': 0.834219829447323, 'Validation Loss': 1.9039405665614388, 'Validation Accuracy': 0.15513399602401692, 'Precision': 0.10085461042120189, 'Recall': 0.8486954904244306, 'Bleu Score': 0.27633891790276516}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  65%|██████▌   | 261/400 [9:24:11<5:06:09, 132.16s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 262, 'Train Loss': 2.048246126807197, 'Train Accuracy': 0.834704231433506, 'Validation Loss': 1.8979134771449506, 'Validation Accuracy': 0.15532099852680037, 'Precision': 0.10149850858393845, 'Recall': 0.8491888263457557, 'Bleu Score': 0.2777068222693189}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  66%|██████▌   | 262/400 [9:26:23<5:03:49, 132.10s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 263, 'Train Loss': 2.045868175793748, 'Train Accuracy': 0.8351589486183074, 'Validation Loss': 1.8961773822622852, 'Validation Accuracy': 0.1548418684784017, 'Precision': 0.10172240715976996, 'Recall': 0.8494597567287785, 'Bleu Score': 0.2783851374971253}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  66%|██████▌   | 263/400 [9:28:34<5:01:24, 132.00s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 264, 'Train Loss': 2.0436699518841275, 'Train Accuracy': 0.8356420012953368, 'Validation Loss': 1.8934708988863576, 'Validation Accuracy': 0.15578025465165712, 'Precision': 0.10211469167242473, 'Recall': 0.849900524068323, 'Bleu Score': 0.2799702529722046}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  66%|██████▌   | 264/400 [9:30:47<4:59:50, 132.28s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 265, 'Train Loss': 2.0408793597260892, 'Train Accuracy': 0.8358862262521589, 'Validation Loss': 1.8906166573201328, 'Validation Accuracy': 0.15626831405339595, 'Precision': 0.10263849746597767, 'Recall': 0.850296810300207, 'Bleu Score': 0.2813091413796648}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  66%|██████▋   | 265/400 [9:32:58<4:56:41, 131.86s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 266, 'Train Loss': 2.038606098014347, 'Train Accuracy': 0.8363126079447323, 'Validation Loss': 1.8908881944073133, 'Validation Accuracy': 0.15674620056481967, 'Precision': 0.10318670778818059, 'Recall': 0.8506162655279503, 'Bleu Score': 0.2817241103828828}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  66%|██████▋   | 266/400 [9:35:12<4:56:02, 132.56s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 267, 'Train Loss': 2.036682103384924, 'Train Accuracy': 0.8363598337651122, 'Validation Loss': 1.8854286399754612, 'Validation Accuracy': 0.1570054069754923, 'Precision': 0.10337578597761853, 'Recall': 0.8510206392339544, 'Bleu Score': 0.2829627368633693}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  67%|██████▋   | 267/400 [9:37:24<4:53:07, 132.24s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 268, 'Train Loss': 2.0342445808220964, 'Train Accuracy': 0.8367254965457686, 'Validation Loss': 1.8863304634232165, 'Validation Accuracy': 0.15714155245004924, 'Precision': 0.10394942849365059, 'Recall': 0.8513400944616977, 'Bleu Score': 0.28363073512691206}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  67%|██████▋   | 268/400 [9:39:35<4:50:14, 131.93s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 269, 'Train Loss': 2.032313857947924, 'Train Accuracy': 0.8371248920552677, 'Validation Loss': 1.882997902956876, 'Validation Accuracy': 0.15732058173605923, 'Precision': 0.10423894134389042, 'Recall': 0.8516797683747412, 'Bleu Score': 0.28457615778286616}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  67%|██████▋   | 269/400 [9:41:47<4:47:53, 131.86s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 270, 'Train Loss': 2.029716537143644, 'Train Accuracy': 0.8374743631260795, 'Validation Loss': 1.8829167834983385, 'Validation Accuracy': 0.15796333796434783, 'Precision': 0.10440622520727848, 'Recall': 0.8518212991718427, 'Bleu Score': 0.2852758950244929}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  68%|██████▊   | 270/400 [9:43:58<4:45:07, 131.60s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 271, 'Train Loss': 2.028249395815707, 'Train Accuracy': 0.8379371761658031, 'Validation Loss': 1.8789505007838414, 'Validation Accuracy': 0.15843333087525432, 'Precision': 0.10501775576991668, 'Recall': 0.8522944164078675, 'Bleu Score': 0.2867577494747796}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  68%|██████▊   | 271/400 [9:46:09<4:42:32, 131.41s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 272, 'Train Loss': 2.02551921922199, 'Train Accuracy': 0.8382947430915372, 'Validation Loss': 1.8754891048778186, 'Validation Accuracy': 0.15838531580620394, 'Precision': 0.10538558151172456, 'Recall': 0.85254512810559, 'Bleu Score': 0.2875887359303874}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  68%|██████▊   | 272/400 [9:48:21<4:41:05, 131.76s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 273, 'Train Loss': 2.0230347076996913, 'Train Accuracy': 0.8385807966321244, 'Validation Loss': 1.8733511850360995, 'Validation Accuracy': 0.15855639163529364, 'Precision': 0.10576789445351502, 'Recall': 0.852933326863354, 'Bleu Score': 0.2884720169676005}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  68%|██████▊   | 273/400 [9:50:34<4:39:46, 132.18s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 274, 'Train Loss': 2.021248283636504, 'Train Accuracy': 0.8390746437823834, 'Validation Loss': 1.8724724354822773, 'Validation Accuracy': 0.1592286346795423, 'Precision': 0.10617650986552354, 'Recall': 0.8532325634057971, 'Bleu Score': 0.28945848965393445}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  68%|██████▊   | 274/400 [9:52:46<4:36:57, 131.89s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 275, 'Train Loss': 2.0189317179977566, 'Train Accuracy': 0.8392999784110535, 'Validation Loss': 1.870084910107053, 'Validation Accuracy': 0.15965268305646915, 'Precision': 0.10666913026907239, 'Recall': 0.8536652432712215, 'Bleu Score': 0.2906368440785336}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  69%|██████▉   | 275/400 [9:54:58<4:34:57, 131.98s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 276, 'Train Loss': 2.0168979027982576, 'Train Accuracy': 0.8395374568221071, 'Validation Loss': 1.865329390222376, 'Validation Accuracy': 0.16007168606206973, 'Precision': 0.10698065773405913, 'Recall': 0.8540857919254659, 'Bleu Score': 0.29164765139208054}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  69%|██████▉   | 276/400 [9:57:09<4:32:28, 131.84s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 277, 'Train Loss': 2.0143438592470813, 'Train Accuracy': 0.8399692357512953, 'Validation Loss': 1.8665594734436224, 'Validation Accuracy': 0.16091874038241286, 'Precision': 0.10705263850394253, 'Recall': 0.8542071040372671, 'Bleu Score': 0.29197115986551303}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  69%|██████▉   | 277/400 [9:59:22<4:30:41, 132.05s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 278, 'Train Loss': 2.0122591843262563, 'Train Accuracy': 0.8401972689982729, 'Validation Loss': 1.8631469464499104, 'Validation Accuracy': 0.16092200183000957, 'Precision': 0.10755474389353166, 'Recall': 0.8546802212732919, 'Bleu Score': 0.2933325359396447}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  70%|██████▉   | 278/400 [10:01:33<4:27:56, 131.78s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 279, 'Train Loss': 2.010486789829823, 'Train Accuracy': 0.8403821243523316, 'Validation Loss': 1.860868178123285, 'Validation Accuracy': 0.16160029812767174, 'Precision': 0.10802142899528154, 'Recall': 0.8550441576086957, 'Bleu Score': 0.29423249239790333}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  70%|██████▉   | 279/400 [10:03:46<4:26:32, 132.17s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 280, 'Train Loss': 2.0084967825623505, 'Train Accuracy': 0.8408098553540587, 'Validation Loss': 1.8588333757948283, 'Validation Accuracy': 0.1619039513543088, 'Precision': 0.10804641450739251, 'Recall': 0.8551856884057971, 'Bleu Score': 0.2947994058818484}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  70%|███████   | 280/400 [10:05:58<4:24:07, 132.06s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 281, 'Train Loss': 2.0061166508751023, 'Train Accuracy': 0.8414022020725389, 'Validation Loss': 1.8544104451482946, 'Validation Accuracy': 0.16250386839098077, 'Precision': 0.10855333319277523, 'Recall': 0.8554606625258799, 'Bleu Score': 0.29581143288005973}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  70%|███████   | 281/400 [10:08:09<4:21:15, 131.73s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 282, 'Train Loss': 2.004149775643375, 'Train Accuracy': 0.8415776122625216, 'Validation Loss': 1.8518786065834614, 'Validation Accuracy': 0.16368052337554115, 'Precision': 0.1091894015437657, 'Recall': 0.8558245988612836, 'Bleu Score': 0.29675264924757083}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  70%|███████   | 282/400 [10:10:20<4:18:48, 131.60s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 283, 'Train Loss': 2.002095168466726, 'Train Accuracy': 0.8421254317789292, 'Validation Loss': 1.8518869524652308, 'Validation Accuracy': 0.1637509839490731, 'Precision': 0.10955021467988553, 'Recall': 0.8562330163043478, 'Bleu Score': 0.29849046748601277}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  71%|███████   | 283/400 [10:12:32<4:16:39, 131.62s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 284, 'Train Loss': 2.000045162867446, 'Train Accuracy': 0.8420876511226252, 'Validation Loss': 1.8519807009657552, 'Validation Accuracy': 0.1649138157826396, 'Precision': 0.11004376887358569, 'Recall': 0.8565848214285714, 'Bleu Score': 0.2993742538631968}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  71%|███████   | 284/400 [10:14:44<4:14:32, 131.66s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 285, 'Train Loss': 1.99804122424916, 'Train Accuracy': 0.842399341537133, 'Validation Loss': 1.8450872299592358, 'Validation Accuracy': 0.16544488215743683, 'Precision': 0.11052127003567647, 'Recall': 0.8569528015010351, 'Bleu Score': 0.30020965492400514}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  71%|███████▏  | 285/400 [10:16:55<4:12:21, 131.66s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 286, 'Train Loss': 1.996000362199973, 'Train Accuracy': 0.8429255721070812, 'Validation Loss': 1.8446972513001811, 'Validation Accuracy': 0.16598849223431317, 'Precision': 0.11066500414903575, 'Recall': 0.8572479943064182, 'Bleu Score': 0.3010885419110092}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  72%|███████▏  | 286/400 [10:19:12<4:13:17, 133.31s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 287, 'Train Loss': 1.993608992238071, 'Train Accuracy': 0.8431684477547495, 'Validation Loss': 1.8432390470642688, 'Validation Accuracy': 0.16658026570316423, 'Precision': 0.11113861232106932, 'Recall': 0.8575795807453416, 'Bleu Score': 0.3018566063476575}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  72%|███████▏  | 287/400 [10:21:24<4:09:59, 132.74s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 288, 'Train Loss': 1.9921346487919929, 'Train Accuracy': 0.8433222689982729, 'Validation Loss': 1.8395926292277565, 'Validation Accuracy': 0.1669349282280488, 'Precision': 0.11167736447605738, 'Recall': 0.8579839544513458, 'Bleu Score': 0.30255604035973155}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  72%|███████▏  | 288/400 [10:23:36<4:07:27, 132.56s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 289, 'Train Loss': 1.9894543114782037, 'Train Accuracy': 0.8439672387737478, 'Validation Loss': 1.8368018631600151, 'Validation Accuracy': 0.16702557673298923, 'Precision': 0.11180478748466767, 'Recall': 0.8581376164596274, 'Bleu Score': 0.30354445510668304}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  72%|███████▏  | 289/400 [10:25:47<4:04:35, 132.21s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 290, 'Train Loss': 1.9878593677479919, 'Train Accuracy': 0.8439969235751296, 'Validation Loss': 1.8378709298520048, 'Validation Accuracy': 0.16635802353277804, 'Precision': 0.11213893102670405, 'Recall': 0.8585136840062112, 'Bleu Score': 0.3045927335657829}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  72%|███████▎  | 290/400 [10:28:00<4:02:35, 132.33s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 291, 'Train Loss': 1.9857423790416664, 'Train Accuracy': 0.8444475928324697, 'Validation Loss': 1.8339290697712542, 'Validation Accuracy': 0.16695313445676863, 'Precision': 0.11248864215403559, 'Recall': 0.8588614453933747, 'Bleu Score': 0.30610205428752185}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  73%|███████▎  | 291/400 [10:30:12<4:00:18, 132.28s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 292, 'Train Loss': 1.9836526751847556, 'Train Accuracy': 0.844724201208981, 'Validation Loss': 1.831692999552104, 'Validation Accuracy': 0.16819386003705755, 'Precision': 0.11315298373877966, 'Recall': 0.8591525944616977, 'Bleu Score': 0.30685607524103903}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  73%|███████▎  | 292/400 [10:32:23<3:57:23, 131.89s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 293, 'Train Loss': 1.9813724526548913, 'Train Accuracy': 0.8447889680483592, 'Validation Loss': 1.8293600198158548, 'Validation Accuracy': 0.16797726978131203, 'Precision': 0.1130670577465422, 'Recall': 0.859273906573499, 'Bleu Score': 0.307368572049903}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  73%|███████▎  | 293/400 [10:34:36<3:55:54, 132.29s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 294, 'Train Loss': 1.9799188612574372, 'Train Accuracy': 0.8453178972366149, 'Validation Loss': 1.8277975956270518, 'Validation Accuracy': 0.1681897419199327, 'Precision': 0.11347597793173142, 'Recall': 0.8595569681677019, 'Bleu Score': 0.3076754658655301}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  74%|███████▎  | 294/400 [10:36:48<3:53:25, 132.12s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 295, 'Train Loss': 1.9777082234456393, 'Train Accuracy': 0.8455121977547496, 'Validation Loss': 1.8252991061072705, 'Validation Accuracy': 0.1680948371196809, 'Precision': 0.11363917221062052, 'Recall': 0.8597915049171843, 'Bleu Score': 0.308359766827835}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  74%|███████▍  | 295/400 [10:38:59<3:50:35, 131.77s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 296, 'Train Loss': 1.9758856441434576, 'Train Accuracy': 0.8459034974093265, 'Validation Loss': 1.8260152527123443, 'Validation Accuracy': 0.1690065201637728, 'Precision': 0.11409987733079656, 'Recall': 0.8601352225672878, 'Bleu Score': 0.30963497909130916}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  74%|███████▍  | 296/400 [10:41:10<3:48:05, 131.59s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 297, 'Train Loss': 1.973754876391005, 'Train Accuracy': 0.8461261334196891, 'Validation Loss': 1.8209463717523686, 'Validation Accuracy': 0.168599689520654, 'Precision': 0.11435137009692097, 'Recall': 0.8604101966873706, 'Bleu Score': 0.31027215054860513}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  74%|███████▍  | 297/400 [10:43:22<3:46:10, 131.76s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 298, 'Train Loss': 1.9713169000425392, 'Train Accuracy': 0.8466793501727116, 'Validation Loss': 1.820614598014138, 'Validation Accuracy': 0.16890731036275689, 'Precision': 0.11462468187712989, 'Recall': 0.8607539143374742, 'Bleu Score': 0.311321956319516}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  74%|███████▍  | 298/400 [10:45:34<3:43:45, 131.62s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 299, 'Train Loss': 1.969558967246535, 'Train Accuracy': 0.8469896912780657, 'Validation Loss': 1.8164323804792293, 'Validation Accuracy': 0.16869836169130203, 'Precision': 0.11510533939121509, 'Recall': 0.8610450634057971, 'Bleu Score': 0.3121872944017584}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  75%|███████▍  | 299/400 [10:47:47<3:42:31, 132.19s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 300, 'Train Loss': 1.9681273496282694, 'Train Accuracy': 0.8469465133851468, 'Validation Loss': 1.8161685757400576, 'Validation Accuracy': 0.16955911863606507, 'Precision': 0.11515763412839015, 'Recall': 0.8612149003623188, 'Bleu Score': 0.3125185222820272}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  75%|███████▌  | 300/400 [10:50:00<3:40:46, 132.47s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 301, 'Train Loss': 1.9662807251208394, 'Train Accuracy': 0.8472959844559586, 'Validation Loss': 1.8142846566586455, 'Validation Accuracy': 0.17016673267177632, 'Precision': 0.11550257858711971, 'Recall': 0.8614534808488613, 'Bleu Score': 0.3134702751191805}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  75%|███████▌  | 301/400 [10:52:11<3:37:49, 132.01s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 302, 'Train Loss': 1.9641952050324962, 'Train Accuracy': 0.8475725928324698, 'Validation Loss': 1.8136518173966527, 'Validation Accuracy': 0.17007534692196757, 'Precision': 0.11553444532298568, 'Recall': 0.861627361542443, 'Bleu Score': 0.31340079561084916}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  76%|███████▌  | 302/400 [10:54:23<3:35:38, 132.03s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 303, 'Train Loss': 1.9623271620405314, 'Train Accuracy': 0.8477048251295337, 'Validation Loss': 1.8089814070335104, 'Validation Accuracy': 0.1711356981636473, 'Precision': 0.1161613941846178, 'Recall': 0.8619508605072463, 'Bleu Score': 0.3146571449370864}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  76%|███████▌  | 303/400 [10:56:34<3:32:40, 131.56s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 304, 'Train Loss': 1.9606257319779685, 'Train Accuracy': 0.8481892271157168, 'Validation Loss': 1.8087222413583235, 'Validation Accuracy': 0.17169249464020173, 'Precision': 0.11642850991785102, 'Recall': 0.8622581845238095, 'Bleu Score': 0.3153764661565669}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  76%|███████▌  | 304/400 [10:58:45<3:30:12, 131.38s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 305, 'Train Loss': 1.958572394940076, 'Train Accuracy': 0.8483754317789292, 'Validation Loss': 1.8076390653602348, 'Validation Accuracy': 0.17178183867447905, 'Precision': 0.11672029176754382, 'Recall': 0.8623754528985508, 'Bleu Score': 0.3155657461462377}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  76%|███████▋  | 305/400 [11:00:56<3:28:08, 131.45s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 306, 'Train Loss': 1.9566275539154505, 'Train Accuracy': 0.8487370466321243, 'Validation Loss': 1.8037653338810629, 'Validation Accuracy': 0.17252555728283328, 'Precision': 0.11711425008869036, 'Recall': 0.8627029956004141, 'Bleu Score': 0.3171344300673198}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  76%|███████▋  | 306/400 [11:03:08<3:26:13, 131.63s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 307, 'Train Loss': 1.9550596217094864, 'Train Accuracy': 0.8487491904145078, 'Validation Loss': 1.8027289960502593, 'Validation Accuracy': 0.17275328543582166, 'Precision': 0.11716719775243559, 'Recall': 0.8628121765010351, 'Bleu Score': 0.31708514747195277}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  77%|███████▋  | 307/400 [11:05:21<3:24:38, 132.03s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 308, 'Train Loss': 1.953040153035143, 'Train Accuracy': 0.8493388385146805, 'Validation Loss': 1.8014515919133651, 'Validation Accuracy': 0.17342955400422477, 'Precision': 0.11791069807374277, 'Recall': 0.8633540372670807, 'Bleu Score': 0.3189847081705525}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  77%|███████▋  | 308/400 [11:07:33<3:22:26, 132.03s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 309, 'Train Loss': 1.9512988238374174, 'Train Accuracy': 0.8495601252158894, 'Validation Loss': 1.7994130697132142, 'Validation Accuracy': 0.17340955505061162, 'Precision': 0.11806565217391077, 'Recall': 0.863479393115942, 'Bleu Score': 0.3190726907564988}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  77%|███████▋  | 309/400 [11:09:45<3:20:11, 131.99s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 310, 'Train Loss': 1.9493118308855024, 'Train Accuracy': 0.8498704663212435, 'Validation Loss': 1.796331734942996, 'Validation Accuracy': 0.17405019150127649, 'Precision': 0.11841908381011655, 'Recall': 0.8638109795548654, 'Bleu Score': 0.32003964739304214}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  78%|███████▊  | 310/400 [11:11:57<3:17:59, 132.00s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 311, 'Train Loss': 1.947415576290689, 'Train Accuracy': 0.8501268350604491, 'Validation Loss': 1.796441880632038, 'Validation Accuracy': 0.17317677812290277, 'Precision': 0.11844805981902237, 'Recall': 0.8640980848861284, 'Bleu Score': 0.3214703276747599}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  78%|███████▊  | 311/400 [11:14:09<3:15:40, 131.92s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 312, 'Train Loss': 1.9457967524205781, 'Train Accuracy': 0.8501497733160622, 'Validation Loss': 1.791841692422047, 'Validation Accuracy': 0.17393714496636414, 'Precision': 0.11880072592480309, 'Recall': 0.8641506534679089, 'Bleu Score': 0.32102626809355783}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  78%|███████▊  | 312/400 [11:16:22<3:13:58, 132.25s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 313, 'Train Loss': 1.944241372343585, 'Train Accuracy': 0.8505950453367875, 'Validation Loss': 1.7904404746599434, 'Validation Accuracy': 0.1740748622951705, 'Precision': 0.11936104303693033, 'Recall': 0.8644984148550725, 'Bleu Score': 0.32199309398723647}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  78%|███████▊  | 313/400 [11:18:35<3:11:58, 132.40s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 314, 'Train Loss': 1.9425554147906066, 'Train Accuracy': 0.85119548791019, 'Validation Loss': 1.7887628462688983, 'Validation Accuracy': 0.1740884970459839, 'Precision': 0.11944654358746053, 'Recall': 0.8647612577639752, 'Bleu Score': 0.323240140731036}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  78%|███████▊  | 314/400 [11:20:48<3:10:10, 132.69s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 315, 'Train Loss': 1.94045102332837, 'Train Accuracy': 0.8511900906735751, 'Validation Loss': 1.787145564871386, 'Validation Accuracy': 0.17451918192203733, 'Precision': 0.11968999185255269, 'Recall': 0.8647895639233955, 'Bleu Score': 0.32289378456025536}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  79%|███████▉  | 315/400 [11:23:00<3:07:39, 132.46s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 316, 'Train Loss': 1.9384397437888614, 'Train Accuracy': 0.8514046308290155, 'Validation Loss': 1.7855807212758656, 'Validation Accuracy': 0.1744784564152147, 'Precision': 0.11974807989648957, 'Recall': 0.8649917507763976, 'Bleu Score': 0.32343415339635906}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  79%|███████▉  | 316/400 [11:25:12<3:05:06, 132.22s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 317, 'Train Loss': 1.9367578633911702, 'Train Accuracy': 0.8514855893782384, 'Validation Loss': 1.7846165040800395, 'Validation Accuracy': 0.17581280795437199, 'Precision': 0.12004274627474396, 'Recall': 0.8652828998447205, 'Bleu Score': 0.3247546276384958}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  79%|███████▉  | 317/400 [11:27:23<3:02:34, 131.98s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 318, 'Train Loss': 1.935617961442273, 'Train Accuracy': 0.8519659434369603, 'Validation Loss': 1.7844229049919065, 'Validation Accuracy': 0.17579089479934096, 'Precision': 0.12036770072333408, 'Recall': 0.8654931741718427, 'Bleu Score': 0.32512697218186787}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  80%|███████▉  | 318/400 [11:29:35<3:00:09, 131.82s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 319, 'Train Loss': 1.933720060968926, 'Train Accuracy': 0.8519821351468049, 'Validation Loss': 1.7825881907762575, 'Validation Accuracy': 0.17591876101513243, 'Precision': 0.12031429340896627, 'Recall': 0.8656994047619048, 'Bleu Score': 0.3257696075995205}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  80%|███████▉  | 319/400 [11:31:47<2:57:57, 131.82s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 320, 'Train Loss': 1.9317347659261188, 'Train Accuracy': 0.8525218588082901, 'Validation Loss': 1.7789283884950906, 'Validation Accuracy': 0.17642008044472413, 'Precision': 0.12093171983242468, 'Recall': 0.8659460727225673, 'Bleu Score': 0.3267108639666525}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  80%|████████  | 320/400 [11:33:58<2:55:35, 131.69s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 321, 'Train Loss': 1.9296309195500052, 'Train Accuracy': 0.8526783786701209, 'Validation Loss': 1.776676093497552, 'Validation Accuracy': 0.17665852927628292, 'Precision': 0.12089186925637589, 'Recall': 0.8660997347308489, 'Bleu Score': 0.32695129726240085}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  80%|████████  | 321/400 [11:36:11<2:54:08, 132.26s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 322, 'Train Loss': 1.9281077100921071, 'Train Accuracy': 0.8527040155440414, 'Validation Loss': 1.7746698440106448, 'Validation Accuracy': 0.17825238669211474, 'Precision': 0.12130518821624593, 'Recall': 0.8663544901656315, 'Bleu Score': 0.3278828372687315}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  80%|████████  | 322/400 [11:38:23<2:51:47, 132.15s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 323, 'Train Loss': 1.926366566706099, 'Train Accuracy': 0.8529860211571675, 'Validation Loss': 1.774282293132514, 'Validation Accuracy': 0.17819289639116231, 'Precision': 0.12177451848206879, 'Recall': 0.8666254205486542, 'Bleu Score': 0.3287167103576868}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  81%|████████  | 323/400 [11:40:34<2:49:00, 131.70s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 324, 'Train Loss': 1.9245162393836026, 'Train Accuracy': 0.8533705742659758, 'Validation Loss': 1.7724256158367662, 'Validation Accuracy': 0.17782875251565058, 'Precision': 0.12169654607939326, 'Recall': 0.8668154761904762, 'Bleu Score': 0.32925048668418455}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  81%|████████  | 324/400 [11:42:46<2:46:54, 131.78s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 325, 'Train Loss': 1.9232115080343426, 'Train Accuracy': 0.8536647236614853, 'Validation Loss': 1.7695592587644404, 'Validation Accuracy': 0.1789589944185905, 'Precision': 0.12247411959076986, 'Recall': 0.8671389751552795, 'Bleu Score': 0.330123152414554}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  81%|████████▏ | 325/400 [11:44:57<2:44:28, 131.58s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 326, 'Train Loss': 1.9213936011929538, 'Train Accuracy': 0.8535001079447323, 'Validation Loss': 1.7678607234284898, 'Validation Accuracy': 0.17878930433086873, 'Precision': 0.12247917240707286, 'Recall': 0.8673654244306418, 'Bleu Score': 0.33111318361690706}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  82%|████████▏ | 326/400 [11:47:09<2:42:25, 131.69s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 327, 'Train Loss': 1.9199297773903905, 'Train Accuracy': 0.8539845099309153, 'Validation Loss': 1.7672293888143271, 'Validation Accuracy': 0.17995076698295023, 'Precision': 0.12312547084362842, 'Recall': 0.8677293607660456, 'Bleu Score': 0.3320651318053294}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  82%|████████▏ | 327/400 [11:49:20<2:40:05, 131.58s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 328, 'Train Loss': 1.9184394276273844, 'Train Accuracy': 0.8542003993955095, 'Validation Loss': 1.7648715130553758, 'Validation Accuracy': 0.18011222029185073, 'Precision': 0.1231728468098282, 'Recall': 0.8679113289337475, 'Bleu Score': 0.3324225434894666}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  82%|████████▏ | 328/400 [11:51:34<2:38:35, 132.16s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 329, 'Train Loss': 1.9166804344614565, 'Train Accuracy': 0.8546888493091537, 'Validation Loss': 1.7629498649727215, 'Validation Accuracy': 0.18027007975381404, 'Precision': 0.12357868240954185, 'Recall': 0.8681296907349897, 'Bleu Score': 0.33341409522088195}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  82%|████████▏ | 329/400 [11:53:46<2:36:18, 132.09s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 330, 'Train Loss': 1.9145982222662445, 'Train Accuracy': 0.8547792530224525, 'Validation Loss': 1.76355071008698, 'Validation Accuracy': 0.18004690114773503, 'Precision': 0.12362772810179018, 'Recall': 0.8683763586956522, 'Bleu Score': 0.33380234787105384}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  82%|████████▎ | 330/400 [11:55:58<2:34:16, 132.24s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 331, 'Train Loss': 1.9131033702120597, 'Train Accuracy': 0.8551503130397237, 'Validation Loss': 1.7605209611664134, 'Validation Accuracy': 0.17969032679790461, 'Precision': 0.12385578738310178, 'Recall': 0.868457233436853, 'Bleu Score': 0.33419261238423453}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  83%|████████▎ | 331/400 [11:58:09<2:31:36, 131.83s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 332, 'Train Loss': 1.9116613654141927, 'Train Accuracy': 0.8554053324697755, 'Validation Loss': 1.7569920181735488, 'Validation Accuracy': 0.18001446929492165, 'Precision': 0.12428941443472781, 'Recall': 0.8686917701863354, 'Bleu Score': 0.3350412891876325}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  83%|████████▎ | 332/400 [12:00:21<2:29:22, 131.80s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 333, 'Train Loss': 1.9099208145345772, 'Train Accuracy': 0.8555281196027634, 'Validation Loss': 1.7560902346264233, 'Validation Accuracy': 0.18033513267660456, 'Precision': 0.12452889038890944, 'Recall': 0.8689101319875776, 'Bleu Score': 0.3353309953850646}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  83%|████████▎ | 333/400 [12:02:33<2:27:09, 131.78s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 334, 'Train Loss': 1.908463930062826, 'Train Accuracy': 0.8557143242659758, 'Validation Loss': 1.754254378070516, 'Validation Accuracy': 0.1805161481054004, 'Precision': 0.1248234201975324, 'Recall': 0.8691851061076604, 'Bleu Score': 0.33643971503431896}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  84%|████████▎ | 334/400 [12:04:45<2:25:16, 132.07s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 335, 'Train Loss': 1.9066107712727225, 'Train Accuracy': 0.8559491040587219, 'Validation Loss': 1.753048755905845, 'Validation Accuracy': 0.1815891585613426, 'Precision': 0.1249921181150122, 'Recall': 0.8693064182194618, 'Bleu Score': 0.3369050951119515}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  84%|████████▍ | 335/400 [12:06:57<2:23:03, 132.06s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 336, 'Train Loss': 1.905365333125736, 'Train Accuracy': 0.8566048683074265, 'Validation Loss': 1.7505940107767246, 'Validation Accuracy': 0.1816820520607019, 'Precision': 0.12529074041207472, 'Recall': 0.8696177859730849, 'Bleu Score': 0.3375624810863725}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  84%|████████▍ | 336/400 [12:09:09<2:20:32, 131.76s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 337, 'Train Loss': 1.9036663431489007, 'Train Accuracy': 0.8564186636442142, 'Validation Loss': 1.749020138555322, 'Validation Accuracy': 0.182877217235401, 'Precision': 0.12585378965191196, 'Recall': 0.8698159290890269, 'Bleu Score': 0.33869917267327376}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  84%|████████▍ | 337/400 [12:11:20<2:18:20, 131.75s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 338, 'Train Loss': 1.9018717261638431, 'Train Accuracy': 0.856847743955095, 'Validation Loss': 1.7476522011205184, 'Validation Accuracy': 0.1835338188852059, 'Precision': 0.12604733096455353, 'Recall': 0.8699655473602484, 'Bleu Score': 0.3390762637431962}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  84%|████████▍ | 338/400 [12:13:31<2:15:51, 131.48s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 339, 'Train Loss': 1.9012664098765968, 'Train Accuracy': 0.8566655872193437, 'Validation Loss': 1.7491786418374904, 'Validation Accuracy': 0.18249021038355115, 'Precision': 0.12595038960488333, 'Recall': 0.8701960403726708, 'Bleu Score': 0.34025272385136934}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  85%|████████▍ | 339/400 [12:15:44<2:13:58, 131.79s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 340, 'Train Loss': 1.8994519408401205, 'Train Accuracy': 0.8571634822970639, 'Validation Loss': 1.7444622336832944, 'Validation Accuracy': 0.18342693197008095, 'Precision': 0.12627248230605465, 'Recall': 0.8704548395445134, 'Bleu Score': 0.3406788437291006}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  85%|████████▌ | 340/400 [12:17:56<2:11:58, 131.98s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 341, 'Train Loss': 1.8981253541800198, 'Train Accuracy': 0.8573213514680483, 'Validation Loss': 1.7418054857037284, 'Validation Accuracy': 0.18475450592131126, 'Precision': 0.126784868054642, 'Recall': 0.8707459886128365, 'Bleu Score': 0.3416747721310296}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  85%|████████▌ | 341/400 [12:20:09<2:09:58, 132.18s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 342, 'Train Loss': 1.8957027652974945, 'Train Accuracy': 0.8575170012953368, 'Validation Loss': 1.7413290258774088, 'Validation Accuracy': 0.18449129815423798, 'Precision': 0.12660171677727122, 'Recall': 0.8707217261904762, 'Bleu Score': 0.3419247755545179}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  86%|████████▌ | 342/400 [12:22:20<2:07:35, 131.99s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 343, 'Train Loss': 1.8937793228343047, 'Train Accuracy': 0.8579879101899828, 'Validation Loss': 1.7414484888561501, 'Validation Accuracy': 0.18520092562322274, 'Precision': 0.12698399222974496, 'Recall': 0.8709400879917184, 'Bleu Score': 0.34239150192156276}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  86%|████████▌ | 343/400 [12:24:32<2:05:23, 132.00s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 344, 'Train Loss': 1.8928359259557987, 'Train Accuracy': 0.8581592724525043, 'Validation Loss': 1.7378441528840498, 'Validation Accuracy': 0.18566423480347047, 'Precision': 0.12717991590397104, 'Recall': 0.871190799689441, 'Bleu Score': 0.3432853725046609}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  86%|████████▌ | 344/400 [12:26:44<2:03:05, 131.88s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 345, 'Train Loss': 1.8914175539056242, 'Train Accuracy': 0.858151176597582, 'Validation Loss': 1.7367408137676144, 'Validation Accuracy': 0.1859565984152025, 'Precision': 0.12758092038805185, 'Recall': 0.8714981237060041, 'Bleu Score': 0.34406841942366234}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  86%|████████▋ | 345/400 [12:28:55<2:00:47, 131.77s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 346, 'Train Loss': 1.8897600305673168, 'Train Accuracy': 0.8584129425734024, 'Validation Loss': 1.7358494674371294, 'Validation Accuracy': 0.18685819982599142, 'Precision': 0.12769918825037793, 'Recall': 0.8715304736024845, 'Bleu Score': 0.3442070525835946}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  86%|████████▋ | 346/400 [12:31:09<1:59:00, 132.24s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 347, 'Train Loss': 1.8883306983426131, 'Train Accuracy': 0.8588622625215889, 'Validation Loss': 1.7358101453662904, 'Validation Accuracy': 0.18617735402415272, 'Precision': 0.12814784319942055, 'Recall': 0.8718580163043478, 'Bleu Score': 0.3453144651219095}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  87%|████████▋ | 347/400 [12:33:20<1:56:34, 131.98s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 348, 'Train Loss': 1.887277816869936, 'Train Accuracy': 0.8589621113989637, 'Validation Loss': 1.7327223737870365, 'Validation Accuracy': 0.18637019816440947, 'Precision': 0.1283172025964067, 'Recall': 0.8720318969979296, 'Bleu Score': 0.34624593906008777}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  87%|████████▋ | 348/400 [12:35:34<1:54:46, 132.42s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 349, 'Train Loss': 1.8851123014207702, 'Train Accuracy': 0.8588460708117444, 'Validation Loss': 1.7320683460590267, 'Validation Accuracy': 0.1864136973346199, 'Precision': 0.12841804075032512, 'Recall': 0.8721127717391305, 'Bleu Score': 0.3461724391243527}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  87%|████████▋ | 349/400 [12:37:45<1:52:17, 132.11s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 350, 'Train Loss': 1.8843237672886137, 'Train Accuracy': 0.8594532599309154, 'Validation Loss': 1.7286003310818316, 'Validation Accuracy': 0.18659888300490154, 'Precision': 0.12891192093861825, 'Recall': 0.8723473084886129, 'Bleu Score': 0.3467868927854871}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  88%|████████▊ | 350/400 [12:39:57<1:50:00, 132.01s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 351, 'Train Loss': 1.882541101446468, 'Train Accuracy': 0.8595193760794473, 'Validation Loss': 1.7279975603927265, 'Validation Accuracy': 0.18791543657499893, 'Precision': 0.12933129346711203, 'Recall': 0.872561626552795, 'Bleu Score': 0.34753592866575517}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  88%|████████▊ | 351/400 [12:42:08<1:47:42, 131.89s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 352, 'Train Loss': 1.8805962863548027, 'Train Accuracy': 0.8595895401554404, 'Validation Loss': 1.7260928242659765, 'Validation Accuracy': 0.18737440269159703, 'Precision': 0.12940060117191646, 'Recall': 0.872751682194617, 'Bleu Score': 0.34818569028256985}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  88%|████████▊ | 352/400 [12:44:19<1:45:14, 131.54s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 353, 'Train Loss': 1.8795143358450568, 'Train Accuracy': 0.859906627806563, 'Validation Loss': 1.7247418303135014, 'Validation Accuracy': 0.18829006876304538, 'Precision': 0.12970331758509612, 'Recall': 0.8729336503623188, 'Bleu Score': 0.34842436186412806}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  88%|████████▊ | 353/400 [12:46:30<1:42:59, 131.47s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 354, 'Train Loss': 1.8776772737667706, 'Train Accuracy': 0.8600105246113989, 'Validation Loss': 1.7225277995275072, 'Validation Accuracy': 0.18833137893884833, 'Precision': 0.1301248537453063, 'Recall': 0.8730873123706004, 'Bleu Score': 0.3488637083525688}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  88%|████████▊ | 354/400 [12:48:42<1:40:54, 131.62s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 355, 'Train Loss': 1.8760992427721868, 'Train Accuracy': 0.8604571459412781, 'Validation Loss': 1.72173880570191, 'Validation Accuracy': 0.18849978653359212, 'Precision': 0.13034455072853768, 'Recall': 0.8733137616459627, 'Bleu Score': 0.3498361648493081}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  89%|████████▉ | 355/400 [12:50:55<1:38:57, 131.94s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 356, 'Train Loss': 1.875060464631128, 'Train Accuracy': 0.8606433506044905, 'Validation Loss': 1.7191680460429388, 'Validation Accuracy': 0.188524822386062, 'Precision': 0.13063273653286075, 'Recall': 0.873435073757764, 'Bleu Score': 0.3496664191931156}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  89%|████████▉ | 356/400 [12:53:07<1:36:42, 131.88s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 357, 'Train Loss': 1.8733714509405484, 'Train Accuracy': 0.8608848769430052, 'Validation Loss': 1.7214471123927881, 'Validation Accuracy': 0.1882579373329809, 'Precision': 0.1305705275963648, 'Recall': 0.8735725608178054, 'Bleu Score': 0.35030298009941635}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  89%|████████▉ | 357/400 [12:55:18<1:34:24, 131.73s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 358, 'Train Loss': 1.8724690870026857, 'Train Accuracy': 0.8608740824697755, 'Validation Loss': 1.7171352476127877, 'Validation Accuracy': 0.18881242812694382, 'Precision': 0.1310240375603316, 'Recall': 0.8737464415113871, 'Bleu Score': 0.35063618635534993}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  90%|████████▉ | 358/400 [12:57:29<1:32:05, 131.57s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 359, 'Train Loss': 1.8707314492589202, 'Train Accuracy': 0.8609240069084628, 'Validation Loss': 1.7149015460625168, 'Validation Accuracy': 0.1890380876281446, 'Precision': 0.13119752705984683, 'Recall': 0.8738354037267081, 'Bleu Score': 0.35080319198025667}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  90%|████████▉ | 359/400 [12:59:42<1:30:06, 131.88s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 360, 'Train Loss': 1.869172494961412, 'Train Accuracy': 0.8614272992227979, 'Validation Loss': 1.7180688186617923, 'Validation Accuracy': 0.1888768272507316, 'Precision': 0.1314125932451323, 'Recall': 0.8740739842132506, 'Bleu Score': 0.3515874996083944}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  90%|█████████ | 360/400 [13:01:54<1:27:52, 131.81s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 361, 'Train Loss': 1.8679800691360926, 'Train Accuracy': 0.8614232512953368, 'Validation Loss': 1.7132248252876534, 'Validation Accuracy': 0.1887528782643206, 'Precision': 0.1314046235753075, 'Recall': 0.8741750776397516, 'Bleu Score': 0.35180244362201707}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  90%|█████████ | 361/400 [13:04:05<1:25:35, 131.68s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 362, 'Train Loss': 1.8663634950120147, 'Train Accuracy': 0.8615271481001727, 'Validation Loss': 1.710226435799244, 'Validation Accuracy': 0.18970074938902462, 'Precision': 0.13195125912197472, 'Recall': 0.8744540954968945, 'Bleu Score': 0.3525739389349422}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  90%|█████████ | 362/400 [13:06:18<1:23:40, 132.13s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 363, 'Train Loss': 1.8644753194810277, 'Train Accuracy': 0.8621505289291883, 'Validation Loss': 1.709881067276001, 'Validation Accuracy': 0.18911976000727534, 'Precision': 0.13194640553175155, 'Recall': 0.874506664078675, 'Bleu Score': 0.35261997685759755}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  91%|█████████ | 363/400 [13:08:30<1:21:20, 131.92s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 364, 'Train Loss': 1.8636084343023722, 'Train Accuracy': 0.86218021373057, 'Validation Loss': 1.7090589891780505, 'Validation Accuracy': 0.19049065554907454, 'Precision': 0.13262979891081356, 'Recall': 0.8748867753623188, 'Bleu Score': 0.3536097996805767}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  91%|█████████ | 364/400 [13:10:41<1:19:00, 131.69s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 365, 'Train Loss': 1.8621074010654048, 'Train Accuracy': 0.8622490284974094, 'Validation Loss': 1.7070588013849968, 'Validation Accuracy': 0.1897977225133551, 'Precision': 0.132531210415007, 'Recall': 0.8749312564699793, 'Bleu Score': 0.3535335826068206}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  91%|█████████▏| 365/400 [13:12:52<1:16:48, 131.68s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 366, 'Train Loss': 1.8607756335761665, 'Train Accuracy': 0.8623664183937824, 'Validation Loss': 1.7040392098840602, 'Validation Accuracy': 0.19066780366257075, 'Precision': 0.13286721348880887, 'Recall': 0.8750930059523809, 'Bleu Score': 0.3544345061549386}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  92%|█████████▏| 366/400 [13:15:04<1:14:32, 131.54s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 367, 'Train Loss': 1.859424898308285, 'Train Accuracy': 0.8624932534542314, 'Validation Loss': 1.7035694710971896, 'Validation Accuracy': 0.19038332588947596, 'Precision': 0.1331075684522716, 'Recall': 0.8752304930124224, 'Bleu Score': 0.35465486023515325}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  92%|█████████▏| 367/400 [13:17:16<1:12:26, 131.72s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 368, 'Train Loss': 1.857796195873898, 'Train Accuracy': 0.8628697107081175, 'Validation Loss': 1.7037155177475007, 'Validation Accuracy': 0.19073551631520233, 'Precision': 0.133225176945375, 'Recall': 0.8754326798654244, 'Bleu Score': 0.3552126089973875}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  92%|█████████▏| 368/400 [13:19:28<1:10:22, 131.95s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 369, 'Train Loss': 1.8565597496309334, 'Train Accuracy': 0.8632569624352332, 'Validation Loss': 1.7024908087962916, 'Validation Accuracy': 0.19086972391476253, 'Precision': 0.13345423238078358, 'Recall': 0.875582298136646, 'Bleu Score': 0.3559586300110856}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  92%|█████████▏| 369/400 [13:21:41<1:08:15, 132.12s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 370, 'Train Loss': 1.8552409583363085, 'Train Accuracy': 0.8633433182210708, 'Validation Loss': 1.7024743593921345, 'Validation Accuracy': 0.19070356608645941, 'Precision': 0.13372905933211157, 'Recall': 0.8757602225672878, 'Bleu Score': 0.3566098790498141}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  92%|█████████▎| 370/400 [13:23:53<1:06:02, 132.08s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 371, 'Train Loss': 1.854035884635883, 'Train Accuracy': 0.8634499136442142, 'Validation Loss': 1.6971789408813824, 'Validation Accuracy': 0.19096359746800157, 'Precision': 0.13378110747985972, 'Recall': 0.8758936658902692, 'Bleu Score': 0.3575258713380536}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  93%|█████████▎| 371/400 [13:26:04<1:03:47, 131.99s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 372, 'Train Loss': 1.8521710048887612, 'Train Accuracy': 0.8635160297927461, 'Validation Loss': 1.6954611066944343, 'Validation Accuracy': 0.1922812002874472, 'Precision': 0.13412043999730425, 'Recall': 0.8760392404244306, 'Bleu Score': 0.3578254604518858}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  93%|█████████▎| 372/400 [13:28:17<1:01:37, 132.05s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 373, 'Train Loss': 1.8508683375561434, 'Train Accuracy': 0.8638749460276338, 'Validation Loss': 1.6946115180973178, 'Validation Accuracy': 0.19123286275541293, 'Precision': 0.134389697220483, 'Recall': 0.876180771221532, 'Bleu Score': 0.3581096953043096}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  93%|█████████▎| 373/400 [13:30:29<59:27, 132.14s/it]  c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 374, 'Train Loss': 1.8494435743073732, 'Train Accuracy': 0.8638803432642487, 'Validation Loss': 1.6945029945412944, 'Validation Accuracy': 0.19173230286925, 'Precision': 0.1343544527551782, 'Recall': 0.8762171648550725, 'Bleu Score': 0.3581372055486444}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  94%|█████████▎| 374/400 [13:32:40<57:03, 131.67s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 375, 'Train Loss': 1.8480349476166194, 'Train Accuracy': 0.8639869386873921, 'Validation Loss': 1.6915578935757156, 'Validation Accuracy': 0.1918522453947307, 'Precision': 0.13425422036409976, 'Recall': 0.8763829580745341, 'Bleu Score': 0.35869860195691705}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  94%|█████████▍| 375/400 [13:34:52<54:54, 131.77s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 376, 'Train Loss': 1.8468556025410225, 'Train Accuracy': 0.8643836355785838, 'Validation Loss': 1.6906658167188817, 'Validation Accuracy': 0.19358130158433956, 'Precision': 0.13512973979036844, 'Recall': 0.8768115942028986, 'Bleu Score': 0.36019386834935657}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  94%|█████████▍| 376/400 [13:37:05<52:52, 132.19s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 377, 'Train Loss': 1.844991388324216, 'Train Accuracy': 0.8646831822107082, 'Validation Loss': 1.6895441713411945, 'Validation Accuracy': 0.19327626216831828, 'Precision': 0.1350399892130857, 'Recall': 0.8769167313664596, 'Bleu Score': 0.36044105684167804}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  94%|█████████▍| 377/400 [13:39:16<50:36, 132.01s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 378, 'Train Loss': 1.8444764290560676, 'Train Accuracy': 0.8646400043177893, 'Validation Loss': 1.6877078911489691, 'Validation Accuracy': 0.19359661101569436, 'Precision': 0.13535907360663585, 'Recall': 0.8770663496376812, 'Bleu Score': 0.3610836854881827}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  94%|█████████▍| 378/400 [13:41:28<48:23, 132.00s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 379, 'Train Loss': 1.8431084399723876, 'Train Accuracy': 0.8650677353195164, 'Validation Loss': 1.6861066409378997, 'Validation Accuracy': 0.19397587336409045, 'Precision': 0.13568540813138633, 'Recall': 0.8772806677018633, 'Bleu Score': 0.3615467271598968}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  95%|█████████▍| 379/400 [13:43:40<46:08, 131.82s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 380, 'Train Loss': 1.8421500572183513, 'Train Accuracy': 0.864998920552677, 'Validation Loss': 1.6877652261375395, 'Validation Accuracy': 0.1937308706459524, 'Precision': 0.13570017346665608, 'Recall': 0.8773170613354038, 'Bleu Score': 0.3620001610883772}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  95%|█████████▌| 380/400 [13:45:50<43:49, 131.49s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 381, 'Train Loss': 1.8406496082550914, 'Train Accuracy': 0.8651891731433506, 'Validation Loss': 1.6835753826563022, 'Validation Accuracy': 0.19402496794076585, 'Precision': 0.13610825714430475, 'Recall': 0.8776243853519669, 'Bleu Score': 0.36310832747643995}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  95%|█████████▌| 381/400 [13:48:02<41:39, 131.58s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 382, 'Train Loss': 1.8385146261908072, 'Train Accuracy': 0.8652512413644214, 'Validation Loss': 1.6842896145237378, 'Validation Accuracy': 0.19325269709496515, 'Precision': 0.136251654379695, 'Recall': 0.8776607789855072, 'Bleu Score': 0.362982580631027}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  96%|█████████▌| 382/400 [13:50:14<39:30, 131.70s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 383, 'Train Loss': 1.8375479057842856, 'Train Accuracy': 0.8653996653713298, 'Validation Loss': 1.6809137185250431, 'Validation Accuracy': 0.19404112533668766, 'Precision': 0.13657817580313375, 'Recall': 0.8778629658385093, 'Bleu Score': 0.36378792722773096}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  96%|█████████▌| 383/400 [13:52:27<37:22, 131.94s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 384, 'Train Loss': 1.8363142244888273, 'Train Accuracy': 0.8655116580310881, 'Validation Loss': 1.681625147250073, 'Validation Accuracy': 0.19338931420091526, 'Precision': 0.1364644905496394, 'Recall': 0.8778629658385093, 'Bleu Score': 0.36385858801527216}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  96%|█████████▌| 384/400 [13:54:39<35:10, 131.91s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 385, 'Train Loss': 1.8345113782757554, 'Train Accuracy': 0.8660149503454232, 'Validation Loss': 1.6787119357546498, 'Validation Accuracy': 0.19299107631325363, 'Precision': 0.1368120583148403, 'Recall': 0.8781298524844721, 'Bleu Score': 0.3646050824757648}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  96%|█████████▋| 385/400 [13:56:49<32:52, 131.49s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 386, 'Train Loss': 1.8336324262849533, 'Train Accuracy': 0.8660351899827289, 'Validation Loss': 1.6770801719062585, 'Validation Accuracy': 0.1933828346864408, 'Precision': 0.1367946598731769, 'Recall': 0.8782632958074534, 'Bleu Score': 0.3652278067003823}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  96%|█████████▋| 386/400 [13:59:00<30:40, 131.43s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 387, 'Train Loss': 1.8319919001496299, 'Train Accuracy': 0.8663037025043178, 'Validation Loss': 1.6750055041687548, 'Validation Accuracy': 0.1936058080068128, 'Precision': 0.1369311805402108, 'Recall': 0.8784048266045549, 'Bleu Score': 0.3655190586141945}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  97%|█████████▋| 387/400 [14:01:13<28:31, 131.65s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 388, 'Train Loss': 1.8310018173568157, 'Train Accuracy': 0.8662942573402418, 'Validation Loss': 1.677507076627952, 'Validation Accuracy': 0.19403967590321475, 'Precision': 0.13720061111544204, 'Recall': 0.8785140075051759, 'Bleu Score': 0.3661566892041281}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  97%|█████████▋| 388/400 [14:03:24<26:19, 131.66s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 389, 'Train Loss': 1.8301755408061802, 'Train Accuracy': 0.8667462759067357, 'Validation Loss': 1.6723254586546874, 'Validation Accuracy': 0.19367794467691332, 'Precision': 0.13748302556201422, 'Recall': 0.8787525879917184, 'Bleu Score': 0.36698954786856747}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  97%|█████████▋| 389/400 [14:05:37<24:13, 132.09s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 390, 'Train Loss': 1.8284444362748393, 'Train Accuracy': 0.8666140436096719, 'Validation Loss': 1.6714172673619483, 'Validation Accuracy': 0.19420329787680324, 'Precision': 0.1376155187169272, 'Recall': 0.8787525879917184, 'Bleu Score': 0.3667704667303254}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  98%|█████████▊| 390/400 [14:07:50<22:02, 132.23s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 391, 'Train Loss': 1.8268562872271512, 'Train Accuracy': 0.8670377266839379, 'Validation Loss': 1.6709801736942007, 'Validation Accuracy': 0.19477995981831728, 'Precision': 0.13789212828777644, 'Recall': 0.8789022062629399, 'Bleu Score': 0.3671347546659892}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  98%|█████████▊| 391/400 [14:10:01<19:47, 131.97s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 392, 'Train Loss': 1.826564234017667, 'Train Accuracy': 0.8669257340241796, 'Validation Loss': 1.6685190218046677, 'Validation Accuracy': 0.19472613522587837, 'Precision': 0.13810047285883997, 'Recall': 0.8791812241200828, 'Bleu Score': 0.36826374977074205}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  98%|█████████▊| 392/400 [14:12:14<17:37, 132.21s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 393, 'Train Loss': 1.8247069697518374, 'Train Accuracy': 0.8672671092400691, 'Validation Loss': 1.6689085324933706, 'Validation Accuracy': 0.19477088232075512, 'Precision': 0.13822806671285912, 'Recall': 0.8793065799689441, 'Bleu Score': 0.3682301234581372}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  98%|█████████▊| 393/400 [14:14:26<15:24, 132.04s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 394, 'Train Loss': 1.8234086095134199, 'Train Accuracy': 0.8671537672711571, 'Validation Loss': 1.6654400941261576, 'Validation Accuracy': 0.1950535472705458, 'Precision': 0.1381986273912331, 'Recall': 0.8792661425983437, 'Bleu Score': 0.36820015812124934}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  98%|█████████▊| 394/400 [14:16:38<13:11, 132.00s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 395, 'Train Loss': 1.8223079147424488, 'Train Accuracy': 0.8673885470639033, 'Validation Loss': 1.6654791312276824, 'Validation Accuracy': 0.19428007947055342, 'Precision': 0.13835714551384115, 'Recall': 0.8795694228778468, 'Bleu Score': 0.369140943789337}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  99%|█████████▉| 395/400 [14:18:50<11:00, 132.16s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 396, 'Train Loss': 1.821135638497811, 'Train Accuracy': 0.867380451208981, 'Validation Loss': 1.66454921059372, 'Validation Accuracy': 0.19549778454940558, 'Precision': 0.13872149760198432, 'Recall': 0.8797028662008282, 'Bleu Score': 0.3696907523954655}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  99%|█████████▉| 396/400 [14:21:03<08:49, 132.34s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 397, 'Train Loss': 1.8192749111527238, 'Train Accuracy': 0.8679997841105354, 'Validation Loss': 1.6630062340212262, 'Validation Accuracy': 0.19567185769611434, 'Precision': 0.1389474125436124, 'Recall': 0.8798727031573499, 'Bleu Score': 0.3704487213955497}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s):  99%|█████████▉| 397/400 [14:23:14<06:36, 132.04s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 398, 'Train Loss': 1.8185445679485468, 'Train Accuracy': 0.8678000863557859, 'Validation Loss': 1.6611944567566075, 'Validation Accuracy': 0.19581301018887523, 'Precision': 0.13906380740748295, 'Recall': 0.8799333592132506, 'Bleu Score': 0.3705890657446347}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s): 100%|█████████▉| 398/400 [14:25:26<04:23, 131.88s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 399, 'Train Loss': 1.8168238891257766, 'Train Accuracy': 0.8679309693436961, 'Validation Loss': 1.6610725677210438, 'Validation Accuracy': 0.19582676367315996, 'Precision': 0.13913443258435435, 'Recall': 0.8800304089026915, 'Bleu Score': 0.370999445788102}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s): 100%|█████████▉| 399/400 [14:27:38<02:12, 132.07s/it]c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\Sid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Epoch': 400, 'Train Loss': 1.815944814550284, 'Train Accuracy': 0.8679039831606218, 'Validation Loss': 1.6605953601273624, 'Validation Accuracy': 0.19521091671670854, 'Precision': 0.13934452232252484, 'Recall': 0.8801962021221532, 'Bleu Score': 0.371600905317761}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch(s): 100%|██████████| 400/400 [14:29:50<00:00, 130.48s/it]\n"
          ]
        }
      ],
      "source": [
        "for epoch in tqdm.trange(epochs,desc=\"Epoch(s)\"):\n",
        "    valloss,valacc, valprecision, valrecall, valbleu_score=validate(model, valDataloader, criterion, device, tokenizer)\n",
        "    train_loss,acc=train(model,optimizer,criterion,trainData)\n",
        "   \n",
        "    dataDict={\n",
        "        \"Epoch\": epoch+1,\n",
        "        \"Train Loss\": train_loss,\n",
        "        \"Train Accuracy\":acc,\n",
        "        \"Validation Loss\": valloss,\n",
        "        \"Validation Accuracy\":valacc,\n",
        "        \"Precision\": valprecision, \n",
        "        \"Recall\":valrecall, \n",
        "        \"Bleu Score\":valbleu_score,\n",
        "    }\n",
        "    print(dataDict)\n",
        "    wandb.log(dataDict)\n",
        "    model.save_pretrained(\"tunedModels/trainedSmallBlenderBotLoRA - Epoch {}\".format(epoch))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ec8_P9GgbMmy"
      },
      "outputs": [],
      "source": [
        "def zip_directory(directory_path, zip_name):\n",
        "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for folder_name, subfolders, filenames in os.walk(directory_path):\n",
        "            for filename in filenames:\n",
        "                file_path = os.path.join(folder_name, filename)\n",
        "                zipf.write(file_path, os.path.relpath(file_path, directory_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKoMYpMbi3rp"
      },
      "outputs": [],
      "source": [
        "save_directory = \"tunedModels/trainedSmallBlenderBotLoRA_Epoch_{}\".format(epoch)\n",
        "zip_name = f'/content/drive/MyDrive/Bbot/{save_directory}.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60x71RmsiwJH"
      },
      "outputs": [],
      "source": [
        "zip_directory(save_directory, zip_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTs15eqFi-D6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "094e2cb072c448fc955193aac5ed9cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fd907728ec547179d309868fa4785ca",
            "max": 62871,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a74bff5d8efa4a0e995096af655cdcf0",
            "value": 62871
          }
        },
        "0a22f0b0f49c486199b1fe21dbddc5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cd192bc71e348feae99d82a91e2272a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e57a414cb954a36a2f95e2211f30ac0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f5978e0628d4a5a8a4e5bb7cddb99f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbc655168f654b65874177e2cb2a90f9",
            "placeholder": "​",
            "style": "IPY_MODEL_9ce35ba7be0c4e249af62e8fc06cb6b2",
            "value": "vocab.json: 100%"
          }
        },
        "132fa1a7778d4e2b9724762e02d5caa5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16dc106cbdcd4fc2b488d40aa5dd9cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18ac5b9cf89144078be559c1cc69afc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca6291a586c34c2ebc5025f657cca2cb",
              "IPY_MODEL_af9cabc910d94b92ba34f00dda644e4f",
              "IPY_MODEL_656a6399de6e4a368b400b04a18c67cf"
            ],
            "layout": "IPY_MODEL_0cd192bc71e348feae99d82a91e2272a"
          }
        },
        "18c00b17204a43b5933a585ca6fe1709": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef10752385864568ad161de490e66d00",
            "placeholder": "​",
            "style": "IPY_MODEL_19fdb98f58364729b08d0afa173a8288",
            "value": "generation_config.json: 100%"
          }
        },
        "19fdb98f58364729b08d0afa173a8288": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b5910f6d99c4506a5ad39a7967e580e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f49c43e786845eea22a3e64601527f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fd907728ec547179d309868fa4785ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b445da530ee4c968cff1f4f23809449": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c54bc07c60647498fd66a1802bf9fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cbc823aa51845a3bf49424bbd7390e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cf10a6e9c684fd3b4c2b096a52421da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fe0498f8dd3437eafcfd5ebac0c9a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36134711e6fa4fb9b7889b54b98b64d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "364c8e5116834ebfb3d207328a03ed0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37de3204be71461781e159c8073a527d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39ad91c9e9054e368bc834285e73a034": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83d607d76ec1482dbdc0f928862c1d29",
            "placeholder": "​",
            "style": "IPY_MODEL_b32cacceea6e45f4a168ecc7c831b9b5",
            "value": " 1.57k/1.57k [00:00&lt;00:00, 111kB/s]"
          }
        },
        "3cbd3e2c2f1a4fd1ac82f594fbb2d1c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fe5ca7c802443a5ba6a1e99be84c45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46e024d7dee646cb9ac7ff24a4f305e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46f96d19d53b449191ca5c48e11ac9e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5454d148b0fa4c15850945391defd1f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54803b403ad8429893f7984a00d0a295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cf10a6e9c684fd3b4c2b096a52421da",
            "max": 772,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bea86f43b4054122a332638a79c71f54",
            "value": 772
          }
        },
        "561ff545431c439383c99d725da73261": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a22f0b0f49c486199b1fe21dbddc5c8",
            "placeholder": "​",
            "style": "IPY_MODEL_a288dfd190b44c9e8f7d638afdda963a",
            "value": "tokenizer.json: 100%"
          }
        },
        "5ac2ed6f76214a448c96b8243bac455b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd2b7dd4846a4e01b3dd00ac955dce77",
              "IPY_MODEL_54803b403ad8429893f7984a00d0a295",
              "IPY_MODEL_b03fd632eaaf4547a68792c93806d5c3"
            ],
            "layout": "IPY_MODEL_a3ce4a361f4d474baaa89f6f97a236e7"
          }
        },
        "5af09f96b6104d2092347f496ea17513": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dc4e43d0f7d4ce483c20a0062479728": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c30683a258449ad91c83045b5540917",
            "placeholder": "​",
            "style": "IPY_MODEL_2c54bc07c60647498fd66a1802bf9fa2",
            "value": " 347/347 [00:00&lt;00:00, 21.8kB/s]"
          }
        },
        "600b8f7e52004a52b456a23bc33bf470": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63a34540eb79438795e01b6d0cb09409": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64f31b01a4e54421a7762fb989a02682": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94e4a21a8505418a9bae0787793e3bc6",
            "max": 729755983,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16dc106cbdcd4fc2b488d40aa5dd9cb9",
            "value": 729755983
          }
        },
        "656a6399de6e4a368b400b04a18c67cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_741a1dadfef348a2978498b6de519f61",
            "placeholder": "​",
            "style": "IPY_MODEL_5af09f96b6104d2092347f496ea17513",
            "value": " 16.0/16.0 [00:00&lt;00:00, 665B/s]"
          }
        },
        "6be4c5e7bfec46f0aeb674c5b9971eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cbc823aa51845a3bf49424bbd7390e3",
            "placeholder": "​",
            "style": "IPY_MODEL_3fe5ca7c802443a5ba6a1e99be84c45a",
            "value": " 127k/127k [00:00&lt;00:00, 8.65MB/s]"
          }
        },
        "6dc438adeecc464fb23d9f7d35fa19b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f0a9baf6cbf454980d380a058cbe7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36134711e6fa4fb9b7889b54b98b64d9",
            "placeholder": "​",
            "style": "IPY_MODEL_952aab2645944dd6a8407c981d6639ba",
            "value": " 1.15k/1.15k [00:00&lt;00:00, 73.2kB/s]"
          }
        },
        "6f37d7dd04a94c0584c5a75627a1ce26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b5910f6d99c4506a5ad39a7967e580e",
            "placeholder": "​",
            "style": "IPY_MODEL_b5da88da852142c29d4febec72f8dbb0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "741a1dadfef348a2978498b6de519f61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76183fb7970348e49ca633affe45b876": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77bb15531efb4fab9e1b066d307d0e60": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "780d9f175c094ff1838a21609a0f6a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18c00b17204a43b5933a585ca6fe1709",
              "IPY_MODEL_f61e39d0001342ab814b7846404254b7",
              "IPY_MODEL_5dc4e43d0f7d4ce483c20a0062479728"
            ],
            "layout": "IPY_MODEL_63a34540eb79438795e01b6d0cb09409"
          }
        },
        "7c30683a258449ad91c83045b5540917": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d61b299408d41b4af6f849ecb544861": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cbd3e2c2f1a4fd1ac82f594fbb2d1c9",
            "max": 126891,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b445da530ee4c968cff1f4f23809449",
            "value": 126891
          }
        },
        "7f062ac5a24945429c901ba6c1a9c8fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "809024fe2d1843758b692ddb1b345508": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_561ff545431c439383c99d725da73261",
              "IPY_MODEL_8ac9aae4acab4270a4289b180acf2251",
              "IPY_MODEL_a0129d439d4d4ff1bec1ecbc936d7a28"
            ],
            "layout": "IPY_MODEL_f105d7e9329047dabbbaba12c436d108"
          }
        },
        "80f6b725374848e896c78c380df8a761": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81d3fc1c95bc4ede9908588674c88a0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83d607d76ec1482dbdc0f928862c1d29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83e7cc23b26c430388dc27988efec952": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9785f258a9c44c1991bb2d9f31e6ceb",
              "IPY_MODEL_094e2cb072c448fc955193aac5ed9cc9",
              "IPY_MODEL_94928d381d5647e3a67a38384f58d2d5"
            ],
            "layout": "IPY_MODEL_0e57a414cb954a36a2f95e2211f30ac0"
          }
        },
        "841b4dad5da741e68fbc8df590d0e4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ac9aae4acab4270a4289b180acf2251": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b9e4a60a93841e68945f6a7149ea921",
            "max": 309565,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b152d142cbd04e7dbf63643b4262019e",
            "value": 309565
          }
        },
        "8c8bca6276db4fb3a48c23abde0ee305": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90016f41ded64f2ea47024ccf8e07330": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f37d7dd04a94c0584c5a75627a1ce26",
              "IPY_MODEL_a7cec87970c7414baee4016de38e4b50",
              "IPY_MODEL_6f0a9baf6cbf454980d380a058cbe7da"
            ],
            "layout": "IPY_MODEL_364c8e5116834ebfb3d207328a03ed0b"
          }
        },
        "927514161df242d1998f112cf5ae0f22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93c670676fa54cb986855267bd1e99bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_132fa1a7778d4e2b9724762e02d5caa5",
            "placeholder": "​",
            "style": "IPY_MODEL_6dc438adeecc464fb23d9f7d35fa19b0",
            "value": " 730M/730M [00:02&lt;00:00, 267MB/s]"
          }
        },
        "94928d381d5647e3a67a38384f58d2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81d3fc1c95bc4ede9908588674c88a0a",
            "placeholder": "​",
            "style": "IPY_MODEL_76183fb7970348e49ca633affe45b876",
            "value": " 62.9k/62.9k [00:00&lt;00:00, 4.38MB/s]"
          }
        },
        "94e4a21a8505418a9bae0787793e3bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "952aab2645944dd6a8407c981d6639ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95ecaea34477439aa3d513357a9e1fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccf7c751578948d3b1acef6a80c910cb",
            "placeholder": "​",
            "style": "IPY_MODEL_d45cd1355ef34f0b849efbd1063f75e9",
            "value": "config.json: 100%"
          }
        },
        "968a7ee1eed349b58a07f65c7171ec25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95ecaea34477439aa3d513357a9e1fed",
              "IPY_MODEL_cdee43a350284239b95e0846dd65f5d3",
              "IPY_MODEL_39ad91c9e9054e368bc834285e73a034"
            ],
            "layout": "IPY_MODEL_46f96d19d53b449191ca5c48e11ac9e5"
          }
        },
        "9b9e4a60a93841e68945f6a7149ea921": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9caab121ba834f73acfb64b41766d8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc426d061c754be8b07232e0ecfb250e",
              "IPY_MODEL_64f31b01a4e54421a7762fb989a02682",
              "IPY_MODEL_93c670676fa54cb986855267bd1e99bb"
            ],
            "layout": "IPY_MODEL_46e024d7dee646cb9ac7ff24a4f305e9"
          }
        },
        "9ce35ba7be0c4e249af62e8fc06cb6b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0129d439d4d4ff1bec1ecbc936d7a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da8389e6eda1454e877694c340e51054",
            "placeholder": "​",
            "style": "IPY_MODEL_8c8bca6276db4fb3a48c23abde0ee305",
            "value": " 310k/310k [00:00&lt;00:00, 11.9MB/s]"
          }
        },
        "a08ed7f6aee641a7a13f32490a9d7d42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f5978e0628d4a5a8a4e5bb7cddb99f4",
              "IPY_MODEL_7d61b299408d41b4af6f849ecb544861",
              "IPY_MODEL_6be4c5e7bfec46f0aeb674c5b9971eed"
            ],
            "layout": "IPY_MODEL_e8fe5a3f063844fba0dfbc28ed12375c"
          }
        },
        "a288dfd190b44c9e8f7d638afdda963a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3ce4a361f4d474baaa89f6f97a236e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a74bff5d8efa4a0e995096af655cdcf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7cec87970c7414baee4016de38e4b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca4a09b42ef749a697a0596527b6a560",
            "max": 1153,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_841b4dad5da741e68fbc8df590d0e4c7",
            "value": 1153
          }
        },
        "abf239eb95c74afeaa6de1ad6f20860a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af9cabc910d94b92ba34f00dda644e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f062ac5a24945429c901ba6c1a9c8fa",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80f6b725374848e896c78c380df8a761",
            "value": 16
          }
        },
        "b03fd632eaaf4547a68792c93806d5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edac2586274545c198256949ab98db91",
            "placeholder": "​",
            "style": "IPY_MODEL_600b8f7e52004a52b456a23bc33bf470",
            "value": " 772/772 [00:00&lt;00:00, 32.5kB/s]"
          }
        },
        "b128a09e09834c80ac9a06caeb51405a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b152d142cbd04e7dbf63643b4262019e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b32cacceea6e45f4a168ecc7c831b9b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5da88da852142c29d4febec72f8dbb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8b1948f0c5b4dfdbb2217ca1e934d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbc655168f654b65874177e2cb2a90f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bea86f43b4054122a332638a79c71f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9785f258a9c44c1991bb2d9f31e6ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77bb15531efb4fab9e1b066d307d0e60",
            "placeholder": "​",
            "style": "IPY_MODEL_cc9cc33751194c7fb331363770d718dc",
            "value": "merges.txt: 100%"
          }
        },
        "ca4a09b42ef749a697a0596527b6a560": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca6291a586c34c2ebc5025f657cca2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_927514161df242d1998f112cf5ae0f22",
            "placeholder": "​",
            "style": "IPY_MODEL_abf239eb95c74afeaa6de1ad6f20860a",
            "value": "added_tokens.json: 100%"
          }
        },
        "cc9cc33751194c7fb331363770d718dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccf7c751578948d3b1acef6a80c910cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdee43a350284239b95e0846dd65f5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37de3204be71461781e159c8073a527d",
            "max": 1572,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d528510b18174f4cb8ec25df6823bae5",
            "value": 1572
          }
        },
        "d45cd1355ef34f0b849efbd1063f75e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d528510b18174f4cb8ec25df6823bae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da8389e6eda1454e877694c340e51054": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc426d061c754be8b07232e0ecfb250e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b128a09e09834c80ac9a06caeb51405a",
            "placeholder": "​",
            "style": "IPY_MODEL_2fe0498f8dd3437eafcfd5ebac0c9a12",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "dd2b7dd4846a4e01b3dd00ac955dce77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b1948f0c5b4dfdbb2217ca1e934d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_1f49c43e786845eea22a3e64601527f7",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e8fe5a3f063844fba0dfbc28ed12375c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edac2586274545c198256949ab98db91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef10752385864568ad161de490e66d00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f105d7e9329047dabbbaba12c436d108": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f276485b7fd14a43b03f32d68aa3f6d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f61e39d0001342ab814b7846404254b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5454d148b0fa4c15850945391defd1f8",
            "max": 347,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f276485b7fd14a43b03f32d68aa3f6d5",
            "value": 347
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
