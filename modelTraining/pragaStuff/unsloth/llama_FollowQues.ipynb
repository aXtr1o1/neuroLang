{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOnyLX76U+Hqklg0ItWrnD/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8ef278f452534426a583b4b0bb2eb6d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_274cf25a391a4f42a4c01ceb13ab910d","IPY_MODEL_66d74d8ca2724d288b1858d7181f799c","IPY_MODEL_81a90be24e834f14a8fa173c171b8387"],"layout":"IPY_MODEL_5cd9de13d11a4d37944099640f7a1da4"}},"274cf25a391a4f42a4c01ceb13ab910d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9321e3de9fad47b48740eebde69da182","placeholder":"â€‹","style":"IPY_MODEL_e11f3d3615974650af8cfd120e27af46","value":"Generatingâ€‡trainâ€‡split:â€‡"}},"66d74d8ca2724d288b1858d7181f799c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc7530e598d245649d5137263f5422f8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bc23297338d4a39872d1c148589503e","value":1}},"81a90be24e834f14a8fa173c171b8387":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_576d40b703e84b7185b1ed558bae7479","placeholder":"â€‹","style":"IPY_MODEL_49404aa710e445c1aa8a2b6559b86d03","value":"â€‡2077/0â€‡[00:00&lt;00:00,â€‡16613.02â€‡examples/s]"}},"5cd9de13d11a4d37944099640f7a1da4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9321e3de9fad47b48740eebde69da182":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e11f3d3615974650af8cfd120e27af46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc7530e598d245649d5137263f5422f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8bc23297338d4a39872d1c148589503e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"576d40b703e84b7185b1ed558bae7479":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49404aa710e445c1aa8a2b6559b86d03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa07f886615d44c28645d56a982e3ae6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c162a1d7541f4b03afae2e21564d604a","IPY_MODEL_5292fc8716d245beb1e4a3e6f28dedee","IPY_MODEL_939f6523ea9a41bd847eba64b910ec88"],"layout":"IPY_MODEL_f1a1f4f262a14e3e9b638feae3d7eb43"}},"c162a1d7541f4b03afae2e21564d604a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b24b388bdc741c4af422f2b52bfd450","placeholder":"â€‹","style":"IPY_MODEL_9f281eff2d2741088ecf9e16ac7ed485","value":"Map:â€‡100%"}},"5292fc8716d245beb1e4a3e6f28dedee":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_230de35e27be4b96a144b542246e24ff","max":2077,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6469b618c2342bc9e81fdd2709a21d2","value":2077}},"939f6523ea9a41bd847eba64b910ec88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a1ecf09e1994c41be5a2c80bf54f8f2","placeholder":"â€‹","style":"IPY_MODEL_27b7fe04016e44ecaed0db34cd42c33c","value":"â€‡2077/2077â€‡[00:00&lt;00:00,â€‡20450.08â€‡examples/s]"}},"f1a1f4f262a14e3e9b638feae3d7eb43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b24b388bdc741c4af422f2b52bfd450":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f281eff2d2741088ecf9e16ac7ed485":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"230de35e27be4b96a144b542246e24ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6469b618c2342bc9e81fdd2709a21d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a1ecf09e1994c41be5a2c80bf54f8f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27b7fe04016e44ecaed0db34cd42c33c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a6609d30459445f8db9adbd6d8f74c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4287151f219f4d4ca99651295ce798c5","IPY_MODEL_2187119f46c04453838bf1c98ac5838e","IPY_MODEL_d8cbee3da7824e59abff0d0fe1c7ac39"],"layout":"IPY_MODEL_bf142f8679d1417da2e4fac2873eb1fe"}},"4287151f219f4d4ca99651295ce798c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30394033cab74ff8bf907b3c36a6c5e0","placeholder":"â€‹","style":"IPY_MODEL_9eb3d876bf3442ea872fb0342befa749","value":"Mapâ€‡(num_proc=2):â€‡100%"}},"2187119f46c04453838bf1c98ac5838e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ecbe38d418114767a2d6bcbd89298f98","max":2077,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8d6437ac04a4ad9a0a16b62bcb197b0","value":2077}},"d8cbee3da7824e59abff0d0fe1c7ac39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c00685c0a5694c799d24c990194affd7","placeholder":"â€‹","style":"IPY_MODEL_45d3354193a042f783158ce6668d971e","value":"â€‡2077/2077â€‡[00:02&lt;00:00,â€‡1166.01â€‡examples/s]"}},"bf142f8679d1417da2e4fac2873eb1fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30394033cab74ff8bf907b3c36a6c5e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eb3d876bf3442ea872fb0342befa749":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecbe38d418114767a2d6bcbd89298f98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8d6437ac04a4ad9a0a16b62bcb197b0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c00685c0a5694c799d24c990194affd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45d3354193a042f783158ce6668d971e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Ep1Jbefz4abw","executionInfo":{"status":"ok","timestamp":1722693602839,"user_tz":-330,"elapsed":23537,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}}},"outputs":[],"source":["%%capture\n","# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes"]},{"cell_type":"code","source":["import torch\n","torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fxVXCk4-4_yh","executionInfo":{"status":"ok","timestamp":1722693607355,"user_tz":-330,"elapsed":4520,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"e525ca84-3fde-4668-8ad8-420606e172e5"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","max_seq_length = 2048\n","dtype = None\n","load_in_4bit = True\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/Meta-Llama-3.1-8B\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T68FWURc4ebX","executionInfo":{"status":"ok","timestamp":1722693653669,"user_tz":-330,"elapsed":46318,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"c22411ef-9d5d-4230-eb4e-13d125b5ed32"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.26.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}]},{"cell_type":"code","source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0,\n","    bias = \"none\",\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\",\n","    random_state = 3407,\n","    use_rslora = False,\n","    loftq_config = None,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ATBES0Te4y5o","executionInfo":{"status":"ok","timestamp":1722693657961,"user_tz":-330,"elapsed":4319,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"cdff903e-09d3-4704-a857-f2db505c904d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2024.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","data=pd.read_csv('AngularQuestions.csv')\n"],"metadata":{"id":"RmVDIfkJmfn1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3KTVXLWcopnl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alpaca_prompt = \"\"\"Below is a question,answer and followup question for that answer.\n","\n","\n","### Question:\n","{}\n","\n","### Answer:\n","{}\n","\n","### FollowUp Question:\n","{}\"\"\"\n","\n","EOS_TOKEN = tokenizer.eos_token\n","def formatting_prompts_func(examples):\n","    # instructions = examples[\"instruction\"]\n","    inputs       = examples[\"prompt\"]\n","    outputs      = examples[\"response\"]\n","    level        = examples[\"follow_up_question\"]\n","    texts = []\n","    for  input, output,level in zip(inputs, outputs,level):\n","\n","        text = alpaca_prompt.format( input, output,level) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","pass\n","\n","from datasets import load_dataset\n","dataset = load_dataset(\"csv\", data_files=\"/content/dataset.csv\", split=\"train\")\n","dataset = dataset.map(formatting_prompts_func, batched = True,)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["8ef278f452534426a583b4b0bb2eb6d7","274cf25a391a4f42a4c01ceb13ab910d","66d74d8ca2724d288b1858d7181f799c","81a90be24e834f14a8fa173c171b8387","5cd9de13d11a4d37944099640f7a1da4","9321e3de9fad47b48740eebde69da182","e11f3d3615974650af8cfd120e27af46","fc7530e598d245649d5137263f5422f8","8bc23297338d4a39872d1c148589503e","576d40b703e84b7185b1ed558bae7479","49404aa710e445c1aa8a2b6559b86d03","aa07f886615d44c28645d56a982e3ae6","c162a1d7541f4b03afae2e21564d604a","5292fc8716d245beb1e4a3e6f28dedee","939f6523ea9a41bd847eba64b910ec88","f1a1f4f262a14e3e9b638feae3d7eb43","7b24b388bdc741c4af422f2b52bfd450","9f281eff2d2741088ecf9e16ac7ed485","230de35e27be4b96a144b542246e24ff","b6469b618c2342bc9e81fdd2709a21d2","5a1ecf09e1994c41be5a2c80bf54f8f2","27b7fe04016e44ecaed0db34cd42c33c"]},"id":"TaOmNMpm5-IO","executionInfo":{"status":"ok","timestamp":1722695347752,"user_tz":-330,"elapsed":1405,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"014c71de-23ac-484d-f0fc-eccfb4e6c5f0"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ef278f452534426a583b4b0bb2eb6d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2077 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa07f886615d44c28645d56a982e3ae6"}},"metadata":{}}]},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sVhbE3-rpP8i","executionInfo":{"status":"ok","timestamp":1722695356762,"user_tz":-330,"elapsed":497,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"4504d1e3-68b7-4fa7-c042-629c5741945d"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['prompt', 'response', 'follow_up_question', 'text'],\n","    num_rows: 2077\n","})"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"What is the purpose of the 'static' keyword in Java?\", # question\n","        \"\",\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","tokenizer.batch_decode(outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yLebVJFeem-s","executionInfo":{"status":"ok","timestamp":1722693725035,"user_tz":-330,"elapsed":12615,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"6d1b1a24-7e08-452c-ea06-1d04f53576ac"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n\\n### Question:\\nWhat is the purpose of the'static' keyword in Java?\\n\\n### Answer:\\nThe'static' keyword in Java is used to declare variables and methods that belong to a class, rather than to a specific instance of that class. This means that the variable or method can be accessed without creating an object of the class, and is shared among all instances of the class.<|end_of_text|>\"]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        # num_train_epochs = 1, # Set this for 1 full training run.\n","        max_steps = 60,\n","        learning_rate = 2e-4,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","    ),\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121,"referenced_widgets":["4a6609d30459445f8db9adbd6d8f74c8","4287151f219f4d4ca99651295ce798c5","2187119f46c04453838bf1c98ac5838e","d8cbee3da7824e59abff0d0fe1c7ac39","bf142f8679d1417da2e4fac2873eb1fe","30394033cab74ff8bf907b3c36a6c5e0","9eb3d876bf3442ea872fb0342befa749","ecbe38d418114767a2d6bcbd89298f98","e8d6437ac04a4ad9a0a16b62bcb197b0","c00685c0a5694c799d24c990194affd7","45d3354193a042f783158ce6668d971e"]},"id":"zEdbJ72n6Obe","executionInfo":{"status":"ok","timestamp":1722695368829,"user_tz":-330,"elapsed":2633,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"ea84cf8c-db8c-41db-9064-ac1ac5b3c2ff"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/2077 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a6609d30459445f8db9adbd6d8f74c8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n","  warnings.warn(\n","max_steps is given, it will override any value given in num_train_epochs\n"]}]},{"cell_type":"code","source":["trainer_state=trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"aF32MdSW6bLC","executionInfo":{"status":"ok","timestamp":1722695650840,"user_tz":-330,"elapsed":280427,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"564b08bc-996e-4113-dbd1-a576e364446a"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 2,077 | Num Epochs = 1\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 60\n"," \"-____-\"     Number of trainable parameters = 41,943,040\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [60/60 04:32, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.446400</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.681700</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.613400</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>2.627300</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>2.340000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>2.438300</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>2.242900</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>2.490200</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>2.598500</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>2.613300</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>2.484500</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>2.531300</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>2.709800</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>2.506800</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>2.665000</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>2.302800</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>2.665400</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>2.593000</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>2.295300</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>2.430400</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>2.633100</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>2.331000</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>2.326900</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>2.421300</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>2.649200</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>2.393600</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>2.521800</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>2.558900</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>2.372100</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>2.409300</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>2.450600</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>2.461200</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>2.670200</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>2.568200</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>2.582300</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>2.486200</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>2.215200</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>2.269800</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>2.524100</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>2.339800</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>2.395400</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>2.631200</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>2.485700</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>2.582800</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>2.721300</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>2.606600</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>2.565400</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>2.629000</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>2.527400</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>2.582200</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>2.568000</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>2.398600</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>2.407600</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>2.279700</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>2.459700</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>2.368900</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>3.036100</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>2.491700</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>2.526900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>2.619900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":["gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4uNzvrF6odV","executionInfo":{"status":"ok","timestamp":1722692895703,"user_tz":-330,"elapsed":424,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"84a10d9f-f46f-45f5-e010-79f0e0668bf4"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = Tesla T4. Max memory = 14.748 GB.\n","11.949 GB of memory reserved.\n"]}]},{"cell_type":"code","source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_state.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_state.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JhdXreWG8sAu","executionInfo":{"status":"ok","timestamp":1722692898635,"user_tz":-330,"elapsed":407,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"f4cfcfc3-bb4d-4ac7-9699-37c38dd32e34"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["350.9565 seconds used for training.\n","5.85 minutes used for training.\n","Peak reserved memory = 11.949 GB.\n","Peak reserved memory for training = 0.0 GB.\n","Peak reserved memory % of max memory = 81.021 %.\n","Peak reserved memory for training % of max memory = 0.0 %.\n"]}]},{"cell_type":"code","source":["\n","FastLanguageModel.for_inference(model)\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"\",\n","        \"\",\n","        \"\"\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n","tokenizer.batch_decode(outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"7Ffu8IXj8vj7","executionInfo":{"status":"error","timestamp":1722697854142,"user_tz":-330,"elapsed":544,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"d1e127c7-a332-4bf6-f3b7-87ce5328b8aa"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'FastLanguageModel' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-cdf43d1cceb4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# alpaca_prompt = Copied from above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mFastLanguageModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Enable native 2x faster inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m inputs = tokenizer(\n\u001b[1;32m      4\u001b[0m [\n\u001b[1;32m      5\u001b[0m     alpaca_prompt.format(\n","\u001b[0;31mNameError\u001b[0m: name 'FastLanguageModel' is not defined"]}]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upcOlWe7A1vc","outputId":"62fac5e4-416b-47b3-f8f6-f9d885d2787c","executionInfo":{"status":"ok","timestamp":1722695877146,"user_tz":-330,"elapsed":2653,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('lora_model/tokenizer_config.json',\n"," 'lora_model/special_tokens_map.json',\n"," 'lora_model/tokenizer.json')"]},"metadata":{},"execution_count":22}],"source":["model.save_pretrained(\"lora_model\")\n","tokenizer.save_pretrained(\"lora_model\")"]},{"cell_type":"code","source":["model,tokenizer=FastLanguageModel.from_pretrained(\"lora_model\",load_in_4bit=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VUIFB33Rh4pM","executionInfo":{"status":"ok","timestamp":1722693474603,"user_tz":-330,"elapsed":31017,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"4a09aae8-668c-4862-a75c-e92440c69f5d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.43.3.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.26.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}]},{"cell_type":"code","source":["model.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qARxYzRdiJKc","executionInfo":{"status":"ok","timestamp":1722693494558,"user_tz":-330,"elapsed":5,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"75dde99c-291b-4a76-8da3-291efa67405f"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LlamaConfig {\n","  \"_name_or_path\": \"unsloth/meta-llama-3.1-8b-bnb-4bit\",\n","  \"architectures\": [\n","    \"LlamaForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 128000,\n","  \"eos_token_id\": 128001,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 4096,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 14336,\n","  \"max_position_embeddings\": 131072,\n","  \"mlp_bias\": false,\n","  \"model_type\": \"llama\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 8,\n","  \"pad_token_id\": 128004,\n","  \"pretraining_tp\": 1,\n","  \"quantization_config\": {\n","    \"bnb_4bit_compute_dtype\": \"float16\",\n","    \"bnb_4bit_quant_type\": \"nf4\",\n","    \"bnb_4bit_use_double_quant\": true,\n","    \"llm_int8_enable_fp32_cpu_offload\": false,\n","    \"llm_int8_has_fp16_weight\": false,\n","    \"llm_int8_skip_modules\": null,\n","    \"llm_int8_threshold\": 6.0,\n","    \"load_in_4bit\": true,\n","    \"load_in_8bit\": false,\n","    \"quant_method\": \"bitsandbytes\"\n","  },\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"factor\": 8.0,\n","    \"high_freq_factor\": 4.0,\n","    \"low_freq_factor\": 1.0,\n","    \"original_max_position_embeddings\": 8192,\n","    \"rope_type\": \"llama3\"\n","  },\n","  \"rope_theta\": 500000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.43.3\",\n","  \"unsloth_version\": \"2024.8\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128256\n","}"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["if False:\n","    from peft import AutoPeftModelForCausalLM\n","    from transformers import AutoTokenizer\n","    model = AutoPeftModelForCausalLM.from_pretrained(\n","        \"lora_model\",\n","        load_in_4bit = load_in_4bit,\n","    )\n","    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"],"metadata":{"id":"u7YLY1Ra9RDF","executionInfo":{"status":"ok","timestamp":1722683879443,"user_tz":-330,"elapsed":475,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["import shutil\n","\n","folder_to_zip = '/content/lora_model'\n","\n","output_zip_file = '/content/lora_model.zip'\n","\n","shutil.make_archive(base_name=output_zip_file.replace('.zip', ''), format='zip', root_dir=folder_to_zip)\n","\n","print(f\"Folder '{folder_to_zip}' has been zipped as '{output_zip_file}'\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bP5qECfT97AY","executionInfo":{"status":"ok","timestamp":1722695925190,"user_tz":-330,"elapsed":7983,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"38c0d02f-4407-4f2f-f1e4-05b30b69fcac"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Folder '/content/lora_model' has been zipped as '/content/lora_model.zip'\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download('/content/lora_model.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"T4Qj9h6WAGta","executionInfo":{"status":"ok","timestamp":1722695925190,"user_tz":-330,"elapsed":19,"user":{"displayName":"Pragadeswaran M.S","userId":"10530094868005003057"}},"outputId":"ff462ce4-9239-417b-b5cf-539c9550d937"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_beb2db93-fc8c-4314-8e14-900122a82411\", \"lora_model.zip\", 75638933)"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"eG8i5-pkAJej"},"execution_count":null,"outputs":[]}]}