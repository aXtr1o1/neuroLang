{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-16.1.0-cp312-cp312-macosx_10_15_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (4.66.4)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.5-cp312-cp312-macosx_10_9_x86_64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.23.4)\n",
      "Requirement already satisfied: packaging in /Users/apple/Library/Python/3.12/lib/python/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp312-cp312-macosx_10_9_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp312-cp312-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/apple/Library/Python/3.12/lib/python/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/apple/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp312-cp312-macosx_10_9_x86_64.whl (395 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.0/396.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-16.1.0-cp312-cp312-macosx_10_15_x86_64.whl (28.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.4/28.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp312-cp312-macosx_10_9_x86_64.whl (31 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp312-cp312-macosx_10_9_x86_64.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp312-cp312-macosx_10_9_x86_64.whl (29 kB)\n",
      "Downloading yarl-1.9.4-cp312-cp312-macosx_10_9_x86_64.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.6/81.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, dill, attrs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.6.1\n",
      "    Uninstalling fsspec-2024.6.1:\n",
      "      Successfully uninstalled fsspec-2024.6.1\n",
      "\u001b[33m  WARNING: The script datasets-cli is installed in '/Library/Frameworks/Python.framework/Versions/3.12/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed aiohttp-3.9.5 aiosignal-1.3.1 attrs-23.2.0 datasets-2.20.0 dill-0.3.8 frozenlist-1.4.1 fsspec-2024.5.0 multidict-6.0.5 multiprocess-0.70.16 pyarrow-16.1.0 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/apple/Library/Python/3.12/lib/python/site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in /Users/apple/Library/Python/3.12/lib/python/site-packages (from peft) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from peft) (2.2.2)\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from peft) (4.42.3)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from peft) (0.32.1)\n",
      "Requirement already satisfied: safetensors in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from peft) (0.23.4)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers->peft) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: peft\n",
      "Successfully installed peft-0.11.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools\n",
      "  Downloading setuptools-70.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Downloading setuptools-70.3.0-py3-none-any.whl (931 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m931.1/931.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "Successfully installed setuptools-70.3.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m594.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-2.10.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: regex in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sacrebleu) (2024.5.15)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sacrebleu) (1.26.4)\n",
      "Collecting colorama (from sacrebleu)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Downloading lxml-5.2.2-cp312-cp312-macosx_10_9_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading lxml-5.2.2-cp312-cp312-macosx_10_9_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-2.10.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: tabulate, portalocker, lxml, colorama, sacrebleu\n",
      "\u001b[33m  WARNING: The script tabulate is installed in '/Library/Frameworks/Python.framework/Versions/3.12/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script sacrebleu is installed in '/Library/Frameworks/Python.framework/Versions/3.12/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed colorama-0.4.6 lxml-5.2.2 portalocker-2.10.0 sacrebleu-2.4.2 tabulate-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "# import wandb\n",
    "import pandas as pd\n",
    "from sacrebleu import corpus_bleu\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from transformers import BlenderbotForConditionalGeneration, AutoTokenizer, AdamW\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= BlenderbotForConditionalGeneration.from_pretrained('facebook/blenderbot-400M-distill', max_length=128)\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/blenderbot-400M-distill')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "loraConfig = LoraConfig(\n",
    "    r=64,                                # Adjust based on model requirements\n",
    "    lora_alpha=32,                       # Adjust based on model requirements\n",
    "    target_modules=[\n",
    "        \"model.encoder.layers\",           # Encoder layers for question processing\n",
    "        \"model.encoder.self_attn.q_proj\", # Attention projection for question\n",
    "        \"model.encoder.self_attn.v_proj\", # Attention projection for question\n",
    "        \"model.decoder.layers\",           # Decoder layers for follow-up question generation\n",
    "        \"model.decoder.self_attn.q_proj\", # Attention projection for follow-up question\n",
    "        \"model.decoder.self_attn.v_proj\", # Attention projection for follow-up question\n",
    "    ],\n",
    "    lora_dropout=0.05,                   # Dropout rate\n",
    "    bias=\"none\",                         # Bias setting\n",
    "    task_type=TaskType.CAUSAL_LM          # Task type for causal language modeling\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlenderbotConfig {\n",
       "  \"_name_or_path\": \"facebook/blenderbot-400M-distill\",\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"add_bias_logits\": false,\n",
       "  \"add_final_layer_norm\": true,\n",
       "  \"architectures\": [\n",
       "    \"BlenderbotForConditionalGeneration\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"classif_dropout\": 0.0,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_model\": 1280,\n",
       "  \"decoder_attention_heads\": 32,\n",
       "  \"decoder_ffn_dim\": 5120,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 12,\n",
       "  \"decoder_start_token_id\": 1,\n",
       "  \"do_blenderbot_90_layernorm\": true,\n",
       "  \"dropout\": 0.1,\n",
       "  \"encoder_attention_heads\": 32,\n",
       "  \"encoder_ffn_dim\": 5120,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 2,\n",
       "  \"encoder_no_repeat_ngram_size\": 3,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"extra_layer_norm\": false,\n",
       "  \"extra_pos_embeddings\": 0,\n",
       "  \"force_bos_token_to_be_generated\": false,\n",
       "  \"forced_eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\"\n",
       "  },\n",
       "  \"init_std\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2\n",
       "  },\n",
       "  \"layernorm_variant\": \"prelayernorm\",\n",
       "  \"length_penalty\": 0.65,\n",
       "  \"max_length\": 128,\n",
       "  \"max_position_embeddings\": 128,\n",
       "  \"min_length\": 20,\n",
       "  \"model_type\": \"blenderbot\",\n",
       "  \"no_repeat_ngram_size\": 3,\n",
       "  \"normalize_before\": true,\n",
       "  \"normalize_embedding\": false,\n",
       "  \"num_beams\": 10,\n",
       "  \"num_hidden_layers\": 2,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"scale_embedding\": true,\n",
       "  \"static_position_embeddings\": false,\n",
       "  \"transformers_version\": \"4.42.3\",\n",
       "  \"unk_token_id\": 3,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 8008\n",
       "}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.shared.weight\n",
      "model.encoder.embed_positions.weight\n",
      "model.encoder.layers.0.self_attn.k_proj.weight\n",
      "model.encoder.layers.0.self_attn.k_proj.bias\n",
      "model.encoder.layers.0.self_attn.v_proj.weight\n",
      "model.encoder.layers.0.self_attn.v_proj.bias\n",
      "model.encoder.layers.0.self_attn.q_proj.weight\n",
      "model.encoder.layers.0.self_attn.q_proj.bias\n",
      "model.encoder.layers.0.self_attn.out_proj.weight\n",
      "model.encoder.layers.0.self_attn.out_proj.bias\n",
      "model.encoder.layers.0.self_attn_layer_norm.weight\n",
      "model.encoder.layers.0.self_attn_layer_norm.bias\n",
      "model.encoder.layers.0.fc1.weight\n",
      "model.encoder.layers.0.fc1.bias\n",
      "model.encoder.layers.0.fc2.weight\n",
      "model.encoder.layers.0.fc2.bias\n",
      "model.encoder.layers.0.final_layer_norm.weight\n",
      "model.encoder.layers.0.final_layer_norm.bias\n",
      "model.encoder.layers.1.self_attn.k_proj.weight\n",
      "model.encoder.layers.1.self_attn.k_proj.bias\n",
      "model.encoder.layers.1.self_attn.v_proj.weight\n",
      "model.encoder.layers.1.self_attn.v_proj.bias\n",
      "model.encoder.layers.1.self_attn.q_proj.weight\n",
      "model.encoder.layers.1.self_attn.q_proj.bias\n",
      "model.encoder.layers.1.self_attn.out_proj.weight\n",
      "model.encoder.layers.1.self_attn.out_proj.bias\n",
      "model.encoder.layers.1.self_attn_layer_norm.weight\n",
      "model.encoder.layers.1.self_attn_layer_norm.bias\n",
      "model.encoder.layers.1.fc1.weight\n",
      "model.encoder.layers.1.fc1.bias\n",
      "model.encoder.layers.1.fc2.weight\n",
      "model.encoder.layers.1.fc2.bias\n",
      "model.encoder.layers.1.final_layer_norm.weight\n",
      "model.encoder.layers.1.final_layer_norm.bias\n",
      "model.encoder.layer_norm.weight\n",
      "model.encoder.layer_norm.bias\n",
      "model.decoder.embed_positions.weight\n",
      "model.decoder.layers.0.self_attn.k_proj.weight\n",
      "model.decoder.layers.0.self_attn.k_proj.bias\n",
      "model.decoder.layers.0.self_attn.v_proj.weight\n",
      "model.decoder.layers.0.self_attn.v_proj.bias\n",
      "model.decoder.layers.0.self_attn.q_proj.weight\n",
      "model.decoder.layers.0.self_attn.q_proj.bias\n",
      "model.decoder.layers.0.self_attn.out_proj.weight\n",
      "model.decoder.layers.0.self_attn.out_proj.bias\n",
      "model.decoder.layers.0.self_attn_layer_norm.weight\n",
      "model.decoder.layers.0.self_attn_layer_norm.bias\n",
      "model.decoder.layers.0.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.0.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.0.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.0.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.0.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.0.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.0.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.0.fc1.weight\n",
      "model.decoder.layers.0.fc1.bias\n",
      "model.decoder.layers.0.fc2.weight\n",
      "model.decoder.layers.0.fc2.bias\n",
      "model.decoder.layers.0.final_layer_norm.weight\n",
      "model.decoder.layers.0.final_layer_norm.bias\n",
      "model.decoder.layers.1.self_attn.k_proj.weight\n",
      "model.decoder.layers.1.self_attn.k_proj.bias\n",
      "model.decoder.layers.1.self_attn.v_proj.weight\n",
      "model.decoder.layers.1.self_attn.v_proj.bias\n",
      "model.decoder.layers.1.self_attn.q_proj.weight\n",
      "model.decoder.layers.1.self_attn.q_proj.bias\n",
      "model.decoder.layers.1.self_attn.out_proj.weight\n",
      "model.decoder.layers.1.self_attn.out_proj.bias\n",
      "model.decoder.layers.1.self_attn_layer_norm.weight\n",
      "model.decoder.layers.1.self_attn_layer_norm.bias\n",
      "model.decoder.layers.1.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.1.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.1.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.1.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.1.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.1.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.1.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.1.fc1.weight\n",
      "model.decoder.layers.1.fc1.bias\n",
      "model.decoder.layers.1.fc2.weight\n",
      "model.decoder.layers.1.fc2.bias\n",
      "model.decoder.layers.1.final_layer_norm.weight\n",
      "model.decoder.layers.1.final_layer_norm.bias\n",
      "model.decoder.layers.2.self_attn.k_proj.weight\n",
      "model.decoder.layers.2.self_attn.k_proj.bias\n",
      "model.decoder.layers.2.self_attn.v_proj.weight\n",
      "model.decoder.layers.2.self_attn.v_proj.bias\n",
      "model.decoder.layers.2.self_attn.q_proj.weight\n",
      "model.decoder.layers.2.self_attn.q_proj.bias\n",
      "model.decoder.layers.2.self_attn.out_proj.weight\n",
      "model.decoder.layers.2.self_attn.out_proj.bias\n",
      "model.decoder.layers.2.self_attn_layer_norm.weight\n",
      "model.decoder.layers.2.self_attn_layer_norm.bias\n",
      "model.decoder.layers.2.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.2.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.2.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.2.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.2.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.2.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.2.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.2.fc1.weight\n",
      "model.decoder.layers.2.fc1.bias\n",
      "model.decoder.layers.2.fc2.weight\n",
      "model.decoder.layers.2.fc2.bias\n",
      "model.decoder.layers.2.final_layer_norm.weight\n",
      "model.decoder.layers.2.final_layer_norm.bias\n",
      "model.decoder.layers.3.self_attn.k_proj.weight\n",
      "model.decoder.layers.3.self_attn.k_proj.bias\n",
      "model.decoder.layers.3.self_attn.v_proj.weight\n",
      "model.decoder.layers.3.self_attn.v_proj.bias\n",
      "model.decoder.layers.3.self_attn.q_proj.weight\n",
      "model.decoder.layers.3.self_attn.q_proj.bias\n",
      "model.decoder.layers.3.self_attn.out_proj.weight\n",
      "model.decoder.layers.3.self_attn.out_proj.bias\n",
      "model.decoder.layers.3.self_attn_layer_norm.weight\n",
      "model.decoder.layers.3.self_attn_layer_norm.bias\n",
      "model.decoder.layers.3.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.3.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.3.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.3.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.3.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.3.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.3.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.3.fc1.weight\n",
      "model.decoder.layers.3.fc1.bias\n",
      "model.decoder.layers.3.fc2.weight\n",
      "model.decoder.layers.3.fc2.bias\n",
      "model.decoder.layers.3.final_layer_norm.weight\n",
      "model.decoder.layers.3.final_layer_norm.bias\n",
      "model.decoder.layers.4.self_attn.k_proj.weight\n",
      "model.decoder.layers.4.self_attn.k_proj.bias\n",
      "model.decoder.layers.4.self_attn.v_proj.weight\n",
      "model.decoder.layers.4.self_attn.v_proj.bias\n",
      "model.decoder.layers.4.self_attn.q_proj.weight\n",
      "model.decoder.layers.4.self_attn.q_proj.bias\n",
      "model.decoder.layers.4.self_attn.out_proj.weight\n",
      "model.decoder.layers.4.self_attn.out_proj.bias\n",
      "model.decoder.layers.4.self_attn_layer_norm.weight\n",
      "model.decoder.layers.4.self_attn_layer_norm.bias\n",
      "model.decoder.layers.4.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.4.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.4.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.4.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.4.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.4.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.4.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.4.fc1.weight\n",
      "model.decoder.layers.4.fc1.bias\n",
      "model.decoder.layers.4.fc2.weight\n",
      "model.decoder.layers.4.fc2.bias\n",
      "model.decoder.layers.4.final_layer_norm.weight\n",
      "model.decoder.layers.4.final_layer_norm.bias\n",
      "model.decoder.layers.5.self_attn.k_proj.weight\n",
      "model.decoder.layers.5.self_attn.k_proj.bias\n",
      "model.decoder.layers.5.self_attn.v_proj.weight\n",
      "model.decoder.layers.5.self_attn.v_proj.bias\n",
      "model.decoder.layers.5.self_attn.q_proj.weight\n",
      "model.decoder.layers.5.self_attn.q_proj.bias\n",
      "model.decoder.layers.5.self_attn.out_proj.weight\n",
      "model.decoder.layers.5.self_attn.out_proj.bias\n",
      "model.decoder.layers.5.self_attn_layer_norm.weight\n",
      "model.decoder.layers.5.self_attn_layer_norm.bias\n",
      "model.decoder.layers.5.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.5.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.5.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.5.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.5.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.5.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.5.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.5.fc1.weight\n",
      "model.decoder.layers.5.fc1.bias\n",
      "model.decoder.layers.5.fc2.weight\n",
      "model.decoder.layers.5.fc2.bias\n",
      "model.decoder.layers.5.final_layer_norm.weight\n",
      "model.decoder.layers.5.final_layer_norm.bias\n",
      "model.decoder.layers.6.self_attn.k_proj.weight\n",
      "model.decoder.layers.6.self_attn.k_proj.bias\n",
      "model.decoder.layers.6.self_attn.v_proj.weight\n",
      "model.decoder.layers.6.self_attn.v_proj.bias\n",
      "model.decoder.layers.6.self_attn.q_proj.weight\n",
      "model.decoder.layers.6.self_attn.q_proj.bias\n",
      "model.decoder.layers.6.self_attn.out_proj.weight\n",
      "model.decoder.layers.6.self_attn.out_proj.bias\n",
      "model.decoder.layers.6.self_attn_layer_norm.weight\n",
      "model.decoder.layers.6.self_attn_layer_norm.bias\n",
      "model.decoder.layers.6.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.6.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.6.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.6.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.6.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.6.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.6.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.6.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.6.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.6.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.6.fc1.weight\n",
      "model.decoder.layers.6.fc1.bias\n",
      "model.decoder.layers.6.fc2.weight\n",
      "model.decoder.layers.6.fc2.bias\n",
      "model.decoder.layers.6.final_layer_norm.weight\n",
      "model.decoder.layers.6.final_layer_norm.bias\n",
      "model.decoder.layers.7.self_attn.k_proj.weight\n",
      "model.decoder.layers.7.self_attn.k_proj.bias\n",
      "model.decoder.layers.7.self_attn.v_proj.weight\n",
      "model.decoder.layers.7.self_attn.v_proj.bias\n",
      "model.decoder.layers.7.self_attn.q_proj.weight\n",
      "model.decoder.layers.7.self_attn.q_proj.bias\n",
      "model.decoder.layers.7.self_attn.out_proj.weight\n",
      "model.decoder.layers.7.self_attn.out_proj.bias\n",
      "model.decoder.layers.7.self_attn_layer_norm.weight\n",
      "model.decoder.layers.7.self_attn_layer_norm.bias\n",
      "model.decoder.layers.7.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.7.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.7.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.7.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.7.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.7.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.7.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.7.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.7.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.7.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.7.fc1.weight\n",
      "model.decoder.layers.7.fc1.bias\n",
      "model.decoder.layers.7.fc2.weight\n",
      "model.decoder.layers.7.fc2.bias\n",
      "model.decoder.layers.7.final_layer_norm.weight\n",
      "model.decoder.layers.7.final_layer_norm.bias\n",
      "model.decoder.layers.8.self_attn.k_proj.weight\n",
      "model.decoder.layers.8.self_attn.k_proj.bias\n",
      "model.decoder.layers.8.self_attn.v_proj.weight\n",
      "model.decoder.layers.8.self_attn.v_proj.bias\n",
      "model.decoder.layers.8.self_attn.q_proj.weight\n",
      "model.decoder.layers.8.self_attn.q_proj.bias\n",
      "model.decoder.layers.8.self_attn.out_proj.weight\n",
      "model.decoder.layers.8.self_attn.out_proj.bias\n",
      "model.decoder.layers.8.self_attn_layer_norm.weight\n",
      "model.decoder.layers.8.self_attn_layer_norm.bias\n",
      "model.decoder.layers.8.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.8.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.8.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.8.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.8.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.8.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.8.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.8.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.8.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.8.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.8.fc1.weight\n",
      "model.decoder.layers.8.fc1.bias\n",
      "model.decoder.layers.8.fc2.weight\n",
      "model.decoder.layers.8.fc2.bias\n",
      "model.decoder.layers.8.final_layer_norm.weight\n",
      "model.decoder.layers.8.final_layer_norm.bias\n",
      "model.decoder.layers.9.self_attn.k_proj.weight\n",
      "model.decoder.layers.9.self_attn.k_proj.bias\n",
      "model.decoder.layers.9.self_attn.v_proj.weight\n",
      "model.decoder.layers.9.self_attn.v_proj.bias\n",
      "model.decoder.layers.9.self_attn.q_proj.weight\n",
      "model.decoder.layers.9.self_attn.q_proj.bias\n",
      "model.decoder.layers.9.self_attn.out_proj.weight\n",
      "model.decoder.layers.9.self_attn.out_proj.bias\n",
      "model.decoder.layers.9.self_attn_layer_norm.weight\n",
      "model.decoder.layers.9.self_attn_layer_norm.bias\n",
      "model.decoder.layers.9.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.9.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.9.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.9.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.9.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.9.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.9.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.9.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.9.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.9.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.9.fc1.weight\n",
      "model.decoder.layers.9.fc1.bias\n",
      "model.decoder.layers.9.fc2.weight\n",
      "model.decoder.layers.9.fc2.bias\n",
      "model.decoder.layers.9.final_layer_norm.weight\n",
      "model.decoder.layers.9.final_layer_norm.bias\n",
      "model.decoder.layers.10.self_attn.k_proj.weight\n",
      "model.decoder.layers.10.self_attn.k_proj.bias\n",
      "model.decoder.layers.10.self_attn.v_proj.weight\n",
      "model.decoder.layers.10.self_attn.v_proj.bias\n",
      "model.decoder.layers.10.self_attn.q_proj.weight\n",
      "model.decoder.layers.10.self_attn.q_proj.bias\n",
      "model.decoder.layers.10.self_attn.out_proj.weight\n",
      "model.decoder.layers.10.self_attn.out_proj.bias\n",
      "model.decoder.layers.10.self_attn_layer_norm.weight\n",
      "model.decoder.layers.10.self_attn_layer_norm.bias\n",
      "model.decoder.layers.10.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.10.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.10.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.10.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.10.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.10.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.10.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.10.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.10.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.10.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.10.fc1.weight\n",
      "model.decoder.layers.10.fc1.bias\n",
      "model.decoder.layers.10.fc2.weight\n",
      "model.decoder.layers.10.fc2.bias\n",
      "model.decoder.layers.10.final_layer_norm.weight\n",
      "model.decoder.layers.10.final_layer_norm.bias\n",
      "model.decoder.layers.11.self_attn.k_proj.weight\n",
      "model.decoder.layers.11.self_attn.k_proj.bias\n",
      "model.decoder.layers.11.self_attn.v_proj.weight\n",
      "model.decoder.layers.11.self_attn.v_proj.bias\n",
      "model.decoder.layers.11.self_attn.q_proj.weight\n",
      "model.decoder.layers.11.self_attn.q_proj.bias\n",
      "model.decoder.layers.11.self_attn.out_proj.weight\n",
      "model.decoder.layers.11.self_attn.out_proj.bias\n",
      "model.decoder.layers.11.self_attn_layer_norm.weight\n",
      "model.decoder.layers.11.self_attn_layer_norm.bias\n",
      "model.decoder.layers.11.encoder_attn.k_proj.weight\n",
      "model.decoder.layers.11.encoder_attn.k_proj.bias\n",
      "model.decoder.layers.11.encoder_attn.v_proj.weight\n",
      "model.decoder.layers.11.encoder_attn.v_proj.bias\n",
      "model.decoder.layers.11.encoder_attn.q_proj.weight\n",
      "model.decoder.layers.11.encoder_attn.q_proj.bias\n",
      "model.decoder.layers.11.encoder_attn.out_proj.weight\n",
      "model.decoder.layers.11.encoder_attn.out_proj.bias\n",
      "model.decoder.layers.11.encoder_attn_layer_norm.weight\n",
      "model.decoder.layers.11.encoder_attn_layer_norm.bias\n",
      "model.decoder.layers.11.fc1.weight\n",
      "model.decoder.layers.11.fc1.bias\n",
      "model.decoder.layers.11.fc2.weight\n",
      "model.decoder.layers.11.fc2.bias\n",
      "model.decoder.layers.11.final_layer_norm.weight\n",
      "model.decoder.layers.11.final_layer_norm.bias\n",
      "model.decoder.layer_norm.weight\n",
      "model.decoder.layer_norm.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataStufff=pd.read_csv('AngularQuestions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,val=train_test_split(dataStufff,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(data, max=128):\n",
    "    inputs_ids, attention_masks, labels = [], [], []\n",
    "    for response, follow_up_question in zip(data['response'], data['follow_up_question']):\n",
    "        encode_res = tokenizer(\n",
    "            str(response),\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        encode_qeus = tokenizer(\n",
    "            str(follow_up_question),\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        try:\n",
    "            inputs_ids.append(encode_res['input_ids'].squeeze())\n",
    "            attention_masks.append(encode_res['attention_mask'].squeeze())\n",
    "            labels.append(encode_qeus['input_ids'].squeeze())\n",
    "        except IndexError as e:\n",
    "            print(f\"IndexError occurred: {e}\")\n",
    "    return inputs_ids, attention_masks, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "traininp,trainmask,trainlabel=prep(train)\n",
    "valinp,valmask,vallabel=prep(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/lh15p_h5417f4nb9dqtm2fhh0000gq/T/ipykernel_44929/3975725461.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  traininp    =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in traininp], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
      "/var/folders/tf/lh15p_h5417f4nb9dqtm2fhh0000gq/T/ipykernel_44929/3975725461.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  trainmask   =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in trainmask], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
      "/var/folders/tf/lh15p_h5417f4nb9dqtm2fhh0000gq/T/ipykernel_44929/3975725461.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  trainlabel  =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in trainlabel], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
      "/var/folders/tf/lh15p_h5417f4nb9dqtm2fhh0000gq/T/ipykernel_44929/3975725461.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valinp      =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in valinp], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
      "/var/folders/tf/lh15p_h5417f4nb9dqtm2fhh0000gq/T/ipykernel_44929/3975725461.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  valmask     =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in valmask], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
      "/var/folders/tf/lh15p_h5417f4nb9dqtm2fhh0000gq/T/ipykernel_44929/3975725461.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  vallabel    =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in vallabel], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n"
     ]
    }
   ],
   "source": [
    "traininp    =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in traininp], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
    "trainmask   =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in trainmask], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
    "trainlabel  =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in trainlabel], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
    "valinp      =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in valinp], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
    "valmask     =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in valmask], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)\n",
    "vallabel    =   torch.nn.utils.rnn.pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in vallabel], batch_first=True, padding_value=tokenizer.pad_token_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(trainmask.max(),traininp.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max train input ID : 8003, Vocal size: 8008\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max train input ID : {traininp.max().item()}, Vocal size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset=TensorDataset(traininp,trainmask,trainlabel)\n",
    "trainDataloader=DataLoader(trainDataset,batch_size=16,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainDataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "valDataset=TensorDataset(valinp,valmask,vallabel)\n",
    "valDataloader=DataLoader(valDataset,batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 16\n",
    "learningRate = 2e-5\n",
    "epochs = 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learningRate)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, trainDataloader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (input_ids, attention_mask, labels) in enumerate(trainDataloader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = input_ids.long().to(device)\n",
    "        attention_mask = attention_mask.long().to(device)\n",
    "        labels = labels.long().to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "    return total_loss / len(trainDataloader), correct / len(trainDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, criterion, valDataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_sequences = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input_ids, attention_mask, labels) in enumerate(valDataloader):\n",
    "            input_ids = input_ids.long().to(device)\n",
    "            attention_mask = attention_mask.long().to(device)\n",
    "            labels = labels.long().to(device)\n",
    "            input_ids[input_ids >= tokenizer.vocab_size] = tokenizer.pad_token_id\n",
    "            labels[labels >= tokenizer.vocab_size] = tokenizer.pad_token_id\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            \n",
    "            correct_sequences += (predictions == labels).all(dim=1).sum().item()\n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = correct_sequences / len(valDataloader.dataset)\n",
    "    flattened_preds = [pred for seq in all_preds for pred in seq]\n",
    "    flattened_labels = [label for seq in all_labels for label in seq]\n",
    "    precision = precision_score(flattened_labels, flattened_preds, average=\"weighted\", zero_division=0)\n",
    "    recall = recall_score(flattened_labels, flattened_preds, average=\"weighted\", zero_division=0)\n",
    "    decoded_preds = [tokenizer.decode(pred, skip_special_tokens=True) for pred in all_preds]\n",
    "    decoded_labels = [[tokenizer.decode(label, skip_special_tokens=True)] for label in all_labels]\n",
    "\n",
    "    bleu_score = corpus_bleu(decoded_preds, decoded_labels)\n",
    "\n",
    "    return total_loss / len(valDataloader), accuracy, precision, recall, bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch(s):   0%|          | 0/450 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm.trange(epochs,desc='Epoch(s)'):\n",
    "    train_loss,train_acc=train(model,optimizer,criterion,trainDataloader)\n",
    "    val_loss,val_acc,val_prec,val_recall,bleu_score=validate(model,criterion,valDataloader)\n",
    "    dataDict={\n",
    "          \"Epoch\": epoch+1,\n",
    "        \"Train Loss\": train_loss,\n",
    "        \"Train Accuracy\": train_acc,\n",
    "        \"Val Loss\": val_loss,\n",
    "        \"Val Accuracy\": val_acc,\n",
    "        \"Val Precision\": val_prec,\n",
    "        \"Val Recall\": val_recall,\n",
    "        \"BLEU Score\": bleu_score\n",
    "\n",
    "    }\n",
    "    print(dataDict)\n",
    " \n",
    "    model.save_pretrained(\"tunedModels/trainedSmallBlenderBotLoRA - Epoch {}\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
